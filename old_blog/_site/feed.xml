<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-30T22:42:07-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ed Henry’s Blog</title><subtitle>A place for me to keep notes about what I know that hopefully someone else finds useful</subtitle><entry><title type="html">Notes from my NeurIPS 2019 Attendance</title><link href="http://localhost:4000/2019/12/08/NeurIPS-Notes/" rel="alternate" type="text/html" title="Notes from my NeurIPS 2019 Attendance" /><published>2019-12-08T00:00:00-08:00</published><updated>2019-12-08T00:00:00-08:00</updated><id>http://localhost:4000/2019/12/08/NeurIPS-Notes</id><content type="html" xml:base="http://localhost:4000/2019/12/08/NeurIPS-Notes/">&lt;h1 id=&quot;neurips-2019&quot;&gt;NeurIPS 2019&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;DISCLAIMER : THESE ARE RUNNING NOTES FROM MY CONFERENCE ATTENDANCE, I MAY OR MAY NOT COME BACK TO UPDATE THESE NOTES PLEASE USE AT YOUR OWN RISK&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;quantum-black-workshop&quot;&gt;Quantum Black Workshop&lt;/h2&gt;

&lt;h3 id=&quot;reinforcement-learning-in-the-real-world&quot;&gt;Reinforcement learning in the real world&lt;/h3&gt;

&lt;p&gt;The presenter covers the analysis of different Q-learning approaches in the context of their presentation.&lt;/p&gt;

&lt;p&gt;They also cover the importance of evaluating a learned policy and how that can be done.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We need to understand how well out optimcal policy is able to learn an optimal set of decisions&lt;/li&gt;
  &lt;li&gt;We need to propose a set of actions that is realistic for the organization to implement&lt;/li&gt;
  &lt;li&gt;We need to interpret out how our optimcal policy differs from the data generating behavior policy.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These questions that we need to ask, outlined above, help us to evaluate the effectiveness of our approaches in the real world.&lt;/p&gt;

&lt;h4 id=&quot;online-and-offline-policy-evaluation&quot;&gt;Online and offline policy evaluation&lt;/h4&gt;

&lt;p&gt;Defn : Evaluating a learned policy through the simulation of the environment&lt;/p&gt;

&lt;p&gt;Considerations :&lt;/p&gt;

&lt;h5 id=&quot;online-evaluation&quot;&gt;Online Evaluation&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Are we even able to simluate the dynamics of the environment?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;offline-evaluation&quot;&gt;Offline Evaluation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;More easily applied to historical data (we don’t have access to a simluation environment)&lt;/li&gt;
  &lt;li&gt;Important sampling can be used to estimate the expected reward under a new policy&lt;/li&gt;
  &lt;li&gt;Requires estimates of the behavior policy which is usually estimated by separate supervised models&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This might be the only way forward as we don’t have the capability to simulate the dynamics of the envoironment.&lt;/p&gt;

&lt;h4 id=&quot;importance-sampling-for-offline-policy-evaluation&quot;&gt;Importance Sampling for offline policy evaluation&lt;/h4&gt;

&lt;p&gt;Goal of PS : estimate the value of a new policy&lt;/p&gt;

&lt;p&gt;Take the ratio of the optimal bahavoior policy at a given time point and * reward at the time step / number of data points – this generates an estimator for the expected value of importance sampling&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://photos.app.goo.gl/TrATMjMK2DKfJyJS7&quot;&gt;Slide&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&quot;pros-and-cons&quot;&gt;Pros and Cons&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Has high unbounded variance&lt;/li&gt;
  &lt;li&gt;weighted importance sampling has lower variance, but is a biased estimator (because of the weighting)&lt;/li&gt;
  &lt;li&gt;Variance is much higher when our policy drastically differs from true behavior&lt;/li&gt;
  &lt;li&gt;Variance increases with the length of the episode&lt;/li&gt;
  &lt;li&gt;Requires accurate estimate of the behavior policy&lt;/li&gt;
  &lt;li&gt;Newer evaluation methods (MAGIC) use both important sampling and model-based approaches depending on the sparsity if your episode&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In summary, as time progresses the variance of the policy will increase, this seems intuitively correct&lt;/p&gt;

&lt;p&gt;Paper : Evaluating Reinforcement Learning Algorithms in an Oberservational Health Setting&lt;/p&gt;

&lt;h4 id=&quot;practical-considerations&quot;&gt;Practical Considerations&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Certain domains may &lt;strong&gt;Require&lt;/strong&gt; offine evaluation due to ethical or data issues&lt;/li&gt;
  &lt;li&gt;OPE may seem relevant in scenarios where a simulator isn’t available, but &lt;strong&gt;high variance&lt;/strong&gt; makes estimating the value of the optimal policy extremely difficult&lt;/li&gt;
  &lt;li&gt;Investimg time to build a model of the environment is important&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;private-federated-learning&quot;&gt;Private Federated Learning&lt;/h2&gt;

&lt;p&gt;Privacy Principles at Apple for ML&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data Minimization
    &lt;ul&gt;
      &lt;li&gt;Collect only &lt;em&gt;what we need&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;On Device Intelligence
    &lt;ul&gt;
      &lt;li&gt;Process data local to devices - this prevents the uneeded transport that can allow for eyes that shouldn’t see it&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Transparency and Control
    &lt;ul&gt;
      &lt;li&gt;Allow for ‘opt-in’&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Security
    &lt;ul&gt;
      &lt;li&gt;The foundation for all of this&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Threat Model
    &lt;ul&gt;
      &lt;li&gt;Malicious Adversarys
        &lt;ul&gt;
          &lt;li&gt;Perform arbitrary inferences on the learned model to extract data points&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Curious onlooker
        &lt;ul&gt;
          &lt;li&gt;Passively looking at updates&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Central Differential Privacy with small privacy parameters (Epsilon &amp;lt;= 2)
    &lt;ul&gt;
      &lt;li&gt;moment accounting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Local Differential Privacy
    &lt;ul&gt;
      &lt;li&gt;local pertubation on the device modifies the vector into a new vector \(z = M(w)\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Control - allows users to opt into this feature within device settings
    &lt;ul&gt;
      &lt;li&gt;Expose the information that is being sent to apple
        &lt;ul&gt;
          &lt;li&gt;Actual parameters, and many other data points&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Retention
	* Keep as little data as possible for as short a time as possible
	* If user deletes a data source, immediately remove the corresponding training data, as well.&lt;/p&gt;

&lt;h2 id=&quot;crypten-privacy-preserving-machine-learning&quot;&gt;CrypTen (Privacy Preserving Machine Learning)&lt;/h2&gt;

&lt;p&gt;The question being asked “Can data be encypted and still be used to train models”&lt;/p&gt;

&lt;h3 id=&quot;research-in-cryptography-trying-to-solve-this-problem-find-slides&quot;&gt;Research in Cryptography trying to solve this problem (find slides)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Homomorphic encryption
    &lt;ul&gt;
      &lt;li&gt;Data encrypted localled on some device and transmitted back to some central repo&lt;/li&gt;
      &lt;li&gt;Perform some function wrt to data and the function itself can or cannot be encrypted as well&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Secure Multiparty Computation
    &lt;ul&gt;
      &lt;li&gt;Federal Ownership of data
        &lt;ul&gt;
          &lt;li&gt;Multiple parties involved in the encryption scheme&lt;/li&gt;
          &lt;li&gt;We can then evalute functions&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;trusted execution environments
    &lt;ul&gt;
      &lt;li&gt;Much like Enclaves from Intel – thought these were proven to be insecure with the meltdown and spectre attacks&lt;/li&gt;
      &lt;li&gt;attestation - we can attest to the fact that only the desired function was executred&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Differential Privacy
    &lt;ul&gt;
      &lt;li&gt;Execute some function on some data that has had noise added to it
        &lt;ul&gt;
          &lt;li&gt;We have to formally prove that the noise we’ve added still provides some guarantees through the distributional definition?
            &lt;ul&gt;
              &lt;li&gt;Need to understand this more.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Federated Learning
    &lt;ul&gt;
      &lt;li&gt;Additive noise that has interesting properties described in Secure Aggregation (see Secure Aggregation Protocol Paper)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How and why does this matter to PyTorch
    &lt;ul&gt;
      &lt;li&gt;End state of this would be to have a flag in an API where (privacy=True)&lt;/li&gt;
      &lt;li&gt;Far from that.&lt;/li&gt;
      &lt;li&gt;Built a framework called CrypTen &lt;a href=&quot;https://github.com/facebookresearch/CrypTen&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CrypTen Design Principles
    &lt;ul&gt;
      &lt;li&gt;Eager Execution
        &lt;ul&gt;
          &lt;li&gt;Easier troubleshooting and learning curve&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Realistic
        &lt;ul&gt;
          &lt;li&gt;some other OSS projects assumed 2 parties, they wanted to head toward N parties&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Encryption by sharing
    &lt;ul&gt;
      &lt;li&gt;Multiparty computation
        &lt;ul&gt;
          &lt;li&gt;Multiple parties process “part” of the data
            &lt;ul&gt;
              &lt;li&gt;images divded between parties would be done pixel by pixel and this might be uninteresting to any single participant&lt;/li&gt;
              &lt;li&gt;No parties can reconstruct the actual data without collaboration from all parties&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Assume we have an integer representing some information : \(x \in \{0,..,N-1\}\)&lt;/li&gt;
      &lt;li&gt;Choose some random mask in the same interval : r ~&lt;/li&gt;
      &lt;li&gt;Encrypt by subtracting the mask that we’ve samples above&lt;/li&gt;
      &lt;li&gt;(x-r) becomes independent btween participant clients&lt;/li&gt;
      &lt;li&gt;Decryption in this domain is easy, just add all of the shares
        &lt;ul&gt;
          &lt;li&gt;just need agreement from all of the participant parties&lt;/li&gt;
          &lt;li&gt;We can design this “agreement” in many different ways&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Encryption is homomorphic
    &lt;ul&gt;
      &lt;li&gt;adding a public value : \([x] + y = (x^(0) + y)\)&lt;/li&gt;
      &lt;li&gt;Multiplication needs triples of encrypted random numbers with the property that \([a][b]=[c]\)
        &lt;ul&gt;
          &lt;li&gt;once we have these tiples we can then generated a share for \(a\), \(b\), \(c\)
            &lt;ul&gt;
              &lt;li&gt;these tiples are sent the participant parties who then calculate epsilon and deltas&lt;/li&gt;
              &lt;li&gt;contain no information because they’re all encrypted&lt;/li&gt;
              &lt;li&gt;“open epsilon and delta” - leak no information because they’re substracttions from a random number&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Operations for Neural Nets
    &lt;ul&gt;
      &lt;li&gt;Conbvolutions are additions and multiplies&lt;/li&gt;
      &lt;li&gt;divisions are approximated&lt;/li&gt;
      &lt;li&gt;non-linearities that involve exponentation are&lt;/li&gt;
      &lt;li&gt;relu break down into sharing ‘bits’&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;High level architecture &lt;a href=&quot;https://photos.app.goo.gl/vQiojJcbSw9tU5TL6&quot;&gt;slide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Feature List &lt;a href=&quot;https://photos.app.goo.gl/gzLXMuHC6Dnh5TiUA&quot;&gt;slide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Has ONNX integrations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayesian-deep-learning&quot;&gt;Bayesian Deep Learning&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://neurips.cc/Conferences/2019/Schedule?showEvent=13205&quot;&gt;URL&lt;/a&gt;
&lt;a href=&quot;&quot;&gt;Recording&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient Descent with Bayes
    &lt;ul&gt;
      &lt;li&gt;Claim is that we can derive this by choosing Gaussian with fixed covariance&lt;/li&gt;
      &lt;li&gt;Global to local approximation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Newton’s Method from Bayes
    &lt;ul&gt;
      &lt;li&gt;In this case we choose a multivariate Gaussian &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;We can express in terms of gradient of Hessian of the loss
        &lt;ul&gt;
          &lt;li&gt;We can use this expectation parameter and ask questions about higher order information about the loss surface&lt;/li&gt;
          &lt;li&gt;If we’re not sure about a second order method, then principles say that we shouldn’t maybe use these methods&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2 parts
        &lt;ul&gt;
          &lt;li&gt;choose the approximation&lt;/li&gt;
          &lt;li&gt;second is choosing which order of parameters we might want to use&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RMS/Adam from Bayes &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;This has taken the community a long time to figure out but we can see that we can draw lines between the bayeslian learning rule for multivariate Gaussian and RMSprop&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Summary
    &lt;ul&gt;
      &lt;li&gt;If we add momentum to the bayesian objective a lot of these things can be explained using similar prinsiples&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bayes as optimization &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Papers&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;What we can do to derive the bayes rule in this special case
        &lt;ul&gt;
          &lt;li&gt;We define the loss to be the negative log joint (estimate)&lt;/li&gt;
          &lt;li&gt;We can plug this into an objective function over all distributions&lt;/li&gt;
          &lt;li&gt;With no restriction we should arrive at the posterior distribution&lt;/li&gt;
          &lt;li&gt;Entropy is the negative expected value&lt;/li&gt;
          &lt;li&gt;The expectation of the log ratio of q over e^-l becomes 0 (as log(1) = 0)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bayes with Approximate Posterior
    &lt;ul&gt;
      &lt;li&gt;Trying to make a point that using this learning rule, how do we optimize it?
        &lt;ul&gt;
          &lt;li&gt;Optimizing it in the right way allows us to do much more than variational inference, including exact bayesian inference&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Bayesian Principle, rather than variational principle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Conjugate Bayesian Inference from Bayesian Principles &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Computing these messages in forward backward algorithm, we’re finding the expectation of the gradient&lt;/li&gt;
      &lt;li&gt;We can write this loss as two parts
        &lt;ul&gt;
          &lt;li&gt;loss of the joint&lt;/li&gt;
          &lt;li&gt;depends on the data (conjugate really means depends on the data)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Choose a q to match the sufficient statistics&lt;/li&gt;
      &lt;li&gt;We can write this as a combination of a learning term and a quadratic term&lt;/li&gt;
      &lt;li&gt;Compute the expectation fo the loss, we can see that it’s linear in the expectation parameter&lt;/li&gt;
      &lt;li&gt;The expectation of the loss is linear in the expectation parameter
        &lt;ul&gt;
          &lt;li&gt;Need this to compute the squares (see slide)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This is a generalization that applies to things like forward backward, SVI, Variational message passing, etc.
        &lt;ul&gt;
          &lt;li&gt;This is all proved in the paper link above&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Laplace Appriximation &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Run the newton method and eventually it will converge to the laplacian&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;designing-new-deep-learning-algorithms&quot;&gt;Designing New deep-learning algorithms&lt;/h3&gt;
&lt;h4 id=&quot;uncertainty-estimation-with-deep-learning&quot;&gt;Uncertainty Estimation with Deep Learning&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Uncertainty Estimation for Image Segmentation &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;We can see missing pieces of sidewalk, etc. this shows wher&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Some Bayesian Deep Learning Methods &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;One line of work proved popular and just keep running standard DL, and then use some ideas to dropout some weights, and doing this it somehow corresponds to solving this bayesian problem (see paper)
        &lt;ul&gt;
          &lt;li&gt;Pros : Scales well to large problems&lt;/li&gt;
          &lt;li&gt;Cons : Not flexible&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Point is to get the average with the goal of “how do we choose this average”
        &lt;ul&gt;
          &lt;li&gt;Get this model, and perturb and this allows to add some noise and allow us to explore a bit&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The principle of SGD corresponds to a Gaussian with parameters that we cannot really control&lt;/li&gt;
      &lt;li&gt;We can use any parameterization we want&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Scaling up VI to ImageNet &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Taking a sample of the gradients and this helps us to scale it to ImageNet&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Variation Online Gauss-Newton &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Improve RMSprop with Bayesian Touch
        &lt;ul&gt;
          &lt;li&gt;Remove the “local” approximation of the Expectation&lt;/li&gt;
          &lt;li&gt;Add some second order approximation&lt;/li&gt;
          &lt;li&gt;No square root of the scale&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Takes some more computation but it’s worth it in that we’re estimation varaince of the diagonal gaussian then we might want to make that tradeoff&lt;/li&gt;
      &lt;li&gt;Estimating a diagonal gaussian with some variance around it, and the variance scaled&lt;/li&gt;
      &lt;li&gt;We can borrow a lot of tricks from the DL side of the world through the framing of the problem we covered previously&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BDL Methods do not really know that they are performing badly under dataset shift
    &lt;ul&gt;
      &lt;li&gt;This is telling us about uncertainty and about performance
        &lt;ul&gt;
          &lt;li&gt;We are shifting the data slowly and we can see that accuracy goes down&lt;/li&gt;
          &lt;li&gt;If we’re estimating uncertainty it should be reflected in our calibration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Resources for Uncertainty in DL &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Challenges in Uncertainty Estimation
    &lt;ul&gt;
      &lt;li&gt;We can’t just take bayesian principles and apply them to non-convex problems&lt;/li&gt;
      &lt;li&gt;different local minima correcpond to various solutions
        &lt;ul&gt;
          &lt;li&gt;local approximations only capture “local uncertainty” – in the same way that DL only captures a local solution to the functional defn&lt;/li&gt;
          &lt;li&gt;These methods miss a whole lot of the data space&lt;/li&gt;
          &lt;li&gt;This is a very hard problem&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;More flexible approximations really tells us that we need to go beyond second order optimization
        &lt;ul&gt;
          &lt;li&gt;Fundamentally there are tools that are missing for us to do this&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-importance&quot;&gt;Data Importance&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Which examples are more important for a classifier given &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Does our model really “know’ this?&lt;/li&gt;
      &lt;li&gt;Does the model understand why it is the way that it is?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Model View vs Data View &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Bayes automatically defines data-importance&lt;/li&gt;
      &lt;li&gt;Points closer to the boundary are more “important”&lt;/li&gt;
      &lt;li&gt;The data view tells us what makes the model certain&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DNN to Gaussian Processes &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Trained with just a deterministic method (Adam, etc)&lt;/li&gt;
      &lt;li&gt;Can we warp that line to get a distribution?
        &lt;ul&gt;
          &lt;li&gt;Get a gaussian approximation of this red line and it turns out that the GP are posteriors of linear models
            &lt;ul&gt;
              &lt;li&gt;posterior is equal to the posterior approximation&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Find a basis function where this linear approximation and we can convert it to a Gaussian Process&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;These things seem to a dual of eachother&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;“Global” to “Local” &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;This posterior approximations connect “global” parameters (model weights) to “local” parameters (data examples)&lt;/li&gt;
      &lt;li&gt;When we use gaussian approximation, we approximate this loss function&lt;/li&gt;
      &lt;li&gt;Local parameters can be seen as “dual” variables that define the “importance” of the data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Continual Learning &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;We’re not seeing part of the data and when we do this with NN’s we show that if we do this in the naive way then we start forgetting the past&lt;/li&gt;
      &lt;li&gt;There is no mechanism to remember the past, this global thing that I want to remember what I did classify and what mistakes I’d made in the past&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Continrual Learning with Bayes &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Remembers almost everything that happened&lt;/li&gt;
      &lt;li&gt;Computing this posterior is challenging, so we can use posterior approximations&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Some regularization-based continual learning methods &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Functional Regularization of Memorable Past (FROMP)
    &lt;ul&gt;
      &lt;li&gt;Identify, memorize, and regularize the past using Laplace approximation (similar to EWC)
  *&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Challenges in Continual Learning &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Towards Life Long Learning &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;interpretable-comparison-of-distributions-and-models&quot;&gt;Interpretable Comparison of Distributions and Models&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Divergence Measures
    &lt;ul&gt;
      &lt;li&gt;Are P and Q the same?
        &lt;ul&gt;
          &lt;li&gt;We can measure the difference or the ratio of probabilities P - Q or P/Q&lt;/li&gt;
          &lt;li&gt;Divergence measure measuing difference will&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Integral Probability Mertrics
        &lt;ul&gt;
          &lt;li&gt;IPM are looking for a function that is well behaved , meaning smooth
            &lt;ul&gt;
              &lt;li&gt;differnce in distributional expectations&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The MMD: integral probability trick &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;Maximimze the mean discrepancy of the distributions
            &lt;ul&gt;
              &lt;li&gt;smooth function for P vs Q&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Assuming we can axpress our algorothm using dot products, we can take advantage of the analytical form for solving&lt;/li&gt;
          &lt;li&gt;Infinitely many features that allow us to tell what is different when we use MMD
            &lt;ul&gt;
              &lt;li&gt;Feature dictionary allows me to distinguish P and Q, no matter the difference between them&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Expectations of functions are linear combinations of eprected features
            &lt;ul&gt;
              &lt;li&gt;Turns out the expectation of F is a fot product of F and X
                &lt;ul&gt;
                  &lt;li&gt;&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How does the Wassterstein 1 behave?
    &lt;ul&gt;
      &lt;li&gt;Using a wasserstein-1 function that is lipschitz defined&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Phi divergences &lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Taking the ratio of the expectations of the densities&lt;/li&gt;
      &lt;li&gt;Taking the reverse KL&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;two-sample-testing&quot;&gt;Two Sample Testing&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CIFAR 10
    &lt;ul&gt;
      &lt;li&gt;Weird conclusions in the reults of this paper&lt;/li&gt;
      &lt;li&gt;In the testing of CIFAR 10 - given these distributions how can we measure if they’re the same?&lt;/li&gt;
      &lt;li&gt;Remember that MMD(P,Q) =&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Estimating the MMD &lt;a href=&quot;&quot;&gt;Slide 1&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Slide 2&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Differnce between the mean embeddings (difference between these latent representations)&lt;/li&gt;
      &lt;li&gt;Expected features of the same size&lt;/li&gt;
      &lt;li&gt;Differences in the mean of the distributions and across the distributions&lt;/li&gt;
      &lt;li&gt;Take an empirical average and we can measure this&lt;/li&gt;
      &lt;li&gt;With this discrepancy, is this MMD true? Small numner “0.09” is small, but not 0.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Behavior of the MMD &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;P,Q laplace with difference variances in y&lt;/li&gt;
      &lt;li&gt;samples frawn iid from P and Q&lt;/li&gt;
      &lt;li&gt;If we keep drawing on P and Q, we can see that this looks a lot like a normal distribution&lt;/li&gt;
      &lt;li&gt;Asymptotics of the MMD are a normal distribution&lt;/li&gt;
      &lt;li&gt;Central limit theorem results hold&lt;/li&gt;
      &lt;li&gt;Asymptotically normal with a mean at tthe TRUE MMD, and variance sigma^2 of the MMD
        &lt;ul&gt;
          &lt;li&gt;variance decays asymptotically&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;What about when P and Q are the same? &lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;turns out it’s an infinite sum of chi^2 distributions
            &lt;ul&gt;
              &lt;li&gt;this distribution depends on choice of kernel and what thr distribution of the data is&lt;/li&gt;
              &lt;li&gt;We do know that it converges to distribution of &lt;em&gt;something&lt;/em&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;A summary of asymptotics
        &lt;ul&gt;
          &lt;li&gt;
            &lt;ol&gt;
              &lt;li&gt;Distributions are close, they’re normal&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;ol&gt;
              &lt;li&gt;The same and its this weird mixture of chi^2&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Classical statistical tests
        &lt;ul&gt;
          &lt;li&gt;Distance is big, then we can say they’re not the same&lt;/li&gt;
          &lt;li&gt;If the estimate is less than a threshold then maybe they’re the same or we didn’t have enough data to capture the variance&lt;/li&gt;
          &lt;li&gt;We can take the MMD estimator and ask whether our estimator is bigger than a threshold CL &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;under the known process, when P=Q, we want to reject the null at the rate most 0.05&lt;/li&gt;
              &lt;li&gt;Probability of doing that, to be less than L&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;We can shuffle all examples together, which is a random mixture of dogs and fish &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;we can estimate the distance between these new tilde’s and we can estimate what this actually means when P=Q&lt;/li&gt;
              &lt;li&gt;What is the 1 - quantile, and that should be a good estimator&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Given a kernel, we can now run a test
            &lt;ul&gt;
              &lt;li&gt;Choosing a kernel, we can start with exponentiated quadratic
                &lt;ul&gt;
                  &lt;li&gt;Kernel is characteristic no matter what bandwidth we pick&lt;/li&gt;
                  &lt;li&gt;As we see infinitely many examples, all of the maxx escapes to the right
                    &lt;ul&gt;
                      &lt;li&gt;Problem is, we never have infinite samples&lt;/li&gt;
                      &lt;li&gt;In our example, bandwidth choice mastters &lt;em&gt;A LOT&lt;/em&gt;&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;If we choose too smooth of a kernel then we get a witness function that can barely distinguish between the two distributions&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Power will be really low because of rejection bandwidth will be really high
                &lt;ul&gt;
                  &lt;li&gt;In high dimensions, it doesn’t matter what bandwidth we pick because the bandwidth is based on pixel distance between images which breaks down in the curse of dimensionality&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Often helpful to use a relevant representation, by creating a new representation
                &lt;ul&gt;
                  &lt;li&gt;Take some hidden layer near the end of a classifier (reneralizes a little bit better)
                    &lt;ul&gt;
                      &lt;li&gt;Measure MMD between 2000 hidden dimensional representation from a classifer&lt;/li&gt;
                      &lt;li&gt;Turns out KID and FID use MMD and give way better properties&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;Interesting that they use the semgentation mask as the pixel count (linear kernel of counts of pixels)
                    &lt;ul&gt;
                      &lt;li&gt;This seems super informative&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;What about tests for other distances
            &lt;ul&gt;
              &lt;li&gt;Sometimes nice closed forms are useful&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Choosing the best test
            &lt;ul&gt;
              &lt;li&gt;Picking a kernel that’s good for a particular model&lt;/li&gt;
              &lt;li&gt;Power depends on the distributions P and Q (and n)&lt;/li&gt;
              &lt;li&gt;Can maybe pick a good kernel manually for a given problem&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Optmizing MMD for test power &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;As we see more and more data this will converge to Gaussian
            &lt;ul&gt;
              &lt;li&gt;for large n, the second term is negligible&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Our estimator is differentiable in kernel parameters&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data Splitting
        &lt;ul&gt;
          &lt;li&gt;Important we don’t trick ourselves and keep everything statistically bound&lt;/li&gt;
          &lt;li&gt;We need to be looking at the test error here&lt;/li&gt;
          &lt;li&gt;We split part of the data to learn the kernel, and the other part to test that kernel
            &lt;ul&gt;
              &lt;li&gt;This second part is exactly the standard testing framework covered above&lt;/li&gt;
              &lt;li&gt;This is a methodology notion&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Learning a kernel is very helpful &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Alternative Approach
        &lt;ul&gt;
          &lt;li&gt;We can train a classifier to do something like this above&lt;/li&gt;
          &lt;li&gt;We split the data, train a classifier to distinguish X from Y and evaluate it on the other half of the data
            &lt;ul&gt;
              &lt;li&gt;Accuracy 50% = can’t tell, accuracy = 100%, clearly different
                &lt;ul&gt;
                  &lt;li&gt;60%, the fact that we can classify at all tells us the distributions are different&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Classifier as two-sample test &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;almost exactly equivalent&lt;/li&gt;
          &lt;li&gt;0-1 kernel inflates invariance, decreases the test powr&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Interpretability &lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;Can we distinguish two distributions&lt;/li&gt;
          &lt;li&gt;Break up each image into its component pixels and learn a kernel for each pixel
            &lt;ul&gt;
              &lt;li&gt;Using an ARD kernel&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;We can look at where the witness function “cares about the most”
            &lt;ul&gt;
              &lt;li&gt;histogram of  witness function might overlap, as the means are close to eachother&lt;/li&gt;
              &lt;li&gt;the points that have the witness function interprets that it looks the most like a dataset&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Main references and further learning &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;representation-learning-and-fairness&quot;&gt;Representation Learning and Fairness&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This tutorial will outline how representation learning can be used to address fairness problems&lt;/li&gt;
  &lt;li&gt;A Framework for Fair Representation Learning
    &lt;ul&gt;
      &lt;li&gt;Representation as a fairness problem &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
        &lt;ol&gt;
          &lt;li&gt;Creating a data regulator &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;Determines what the fairness criteria are&lt;/li&gt;
              &lt;li&gt;determines data sources&lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;audits results&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;When Training
                &lt;ul&gt;
                  &lt;li&gt;Interacting with all of the stakeholders to understand the fairness criteria
                    &lt;ul&gt;
                      &lt;li&gt;output is the fairness criteria&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;Determinining fairness critera
                    &lt;ul&gt;
                      &lt;li&gt;Algorithmic fairness&lt;/li&gt;
                      &lt;li&gt;Dataset fairness&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Examples for &lt;em&gt;how&lt;/em&gt; to do this
                &lt;ul&gt;
                  &lt;li&gt;Partition the dataset into space of disjoint cells such that similar individuals are in the same cell.&lt;/li&gt;
                  &lt;li&gt;Individuals in the same cell should be treated similarly&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Lipschitz continuity implies individual fairness
                &lt;ul&gt;
                  &lt;li&gt;Good news : One can achieve fairness through Lipshitz regularization.&lt;/li&gt;
                  &lt;li&gt;Bad news : Data is non-Euclidean (eg. images, graphs, etc).
                    &lt;ul&gt;
                      &lt;li&gt;Standard Euclidean distance metrics aren’t a good measure for this&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;Challenge : Can we learn representations of the data such that the l_2 norm is a good metric to compare instances?&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Group Fairness : Similar Classifier Statistics across groups &lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;(im-)possibility result for group-fair classification
                &lt;ul&gt;
                  &lt;li&gt;Classifier statistics are not artbitrarily flexible&lt;/li&gt;
                  &lt;li&gt;eg. Binary classification statistics have two degrees of freesom thus can match two independent statistics across groups&lt;/li&gt;
                  &lt;li&gt;Beyond binary classification, the degrees of freedom grows quadratically with number of classes&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Group Fairness : Advantages and Challenges
                &lt;ul&gt;
                  &lt;li&gt;Advantages
                    &lt;ul&gt;
                      &lt;li&gt;Fairly easy to compute and roughly scales with the number of samples&lt;/li&gt;
                      &lt;li&gt;Often easier to explain to policy-makeers (as in terms of population behavior)&lt;/li&gt;
                      &lt;li&gt;More existing work, strategies already exist for representation learning
  Challenges:&lt;/li&gt;
                      &lt;li&gt;data regulator must determine which classifier statistics to equalize.&lt;/li&gt;
                      &lt;li&gt;fairness of the representation depends on the quality of the fairness metric chosen by the regulator&lt;/li&gt;
                      &lt;li&gt;Group fairness can lead to (more) violated individual fairness, e.g intersectionality can lead to fairness gerrymandering&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ol&gt;

        &lt;ul&gt;
          &lt;li&gt;Metric Elicitation &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;Determine the ideal evaluation metric by interacting with users, and experts&lt;/li&gt;
              &lt;li&gt;Query an oracle for this fairness metrics&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Which statistics should be equalized across groups?&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Commonly used measures are straightforward functions of classifier performance statistics.&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Data Producer
            &lt;ul&gt;
              &lt;li&gt;Computes the fair representation given the data regulator criteria&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Data User
            &lt;ul&gt;
              &lt;li&gt;Computes ML model given sanitized data&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;keynote-1--how-to-know&quot;&gt;Keynote 1 : How To Know&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How can two people living in the same world come to two different conclusions?&lt;/li&gt;
  &lt;li&gt;5 Things Everyone in ML Should know about
    &lt;ol&gt;
      &lt;li&gt;Humans continuously form beliefs
        &lt;ul&gt;
          &lt;li&gt;We don’t set them and we’re done&lt;/li&gt;
          &lt;li&gt;We continuously update our beliefs&lt;/li&gt;
          &lt;li&gt;Every time we encounter an instance of a bowl, we update our beliefs about bowls&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Certainty diminishes interest
        &lt;ul&gt;
          &lt;li&gt;What you think you know is what determines your curiosity&lt;/li&gt;
          &lt;li&gt;People do not have an accurate model of their own uncertainty&lt;/li&gt;
          &lt;li&gt;If you think you know the answer, you won’t check, and if we present the right answer to the person they &lt;em&gt;still&lt;/em&gt; reject it
            &lt;ul&gt;
              &lt;li&gt;Might be why there is confirmation bias&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Certainty is feedback driven
        &lt;ul&gt;
          &lt;li&gt;high level beliefs about concepts
            &lt;ul&gt;
              &lt;li&gt;most useful for the decision making points in our lives
                &lt;ul&gt;
                  &lt;li&gt;we are sometimes certain when we shouldn’t be&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;People learned a novel rule based concept
            &lt;ul&gt;
              &lt;li&gt;boolean logic to determine daxxy-ness&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;In the beginning there is no concept, it could be a property of the system, or not&lt;/li&gt;
          &lt;li&gt;Entropy of an idealized model has little to do with interest and learning
            &lt;ul&gt;
              &lt;li&gt;instead this certainty comes from feedback&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Reasoning about the world
            &lt;ul&gt;
              &lt;li&gt;Flat earthers – if they watch online videos that confirm this it might increase the chance of early adoption of this idea as truth&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Less feedback may encourage overconfidence&lt;/li&gt;
      &lt;li&gt;Humans form beliefs quickly
        &lt;ul&gt;
          &lt;li&gt;Early evidence counts more than later evidence
            &lt;ul&gt;
              &lt;li&gt;Leads to becoming certain and plays down our ability to update our beliefs&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;There is no such thing as a neutral tech platform
    &lt;ul&gt;
      &lt;li&gt;The order in which information is presented makes a huge difference in our understanding of the world&lt;/li&gt;
      &lt;li&gt;This reinforces some of the studies done around the 2016 elections&lt;/li&gt;
      &lt;li&gt;Children are consuming more online data and this is affecting them&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;veridical-data-science&quot;&gt;Veridical Data Science&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Veridical - coinciding with reality&lt;/li&gt;
  &lt;li&gt;PCS Framework for Data Science &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Predictability (P) (From ML)&lt;/li&gt;
      &lt;li&gt;Computability (C) (From ML)&lt;/li&gt;
      &lt;li&gt;Stability (S) (from statistics)&lt;/li&gt;
      &lt;li&gt;Bridges two of Breimann’s cultures
        &lt;ul&gt;
          &lt;li&gt;PCS connects science and engineering
            &lt;ul&gt;
              &lt;li&gt;Predictability and stability embed two scientific principles&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Stability unifies and extends myriad works on perturbation analysis
            &lt;ul&gt;
              &lt;li&gt;It’s a minimum requirement for reproducibility, interpretability, etc.&lt;/li&gt;
              &lt;li&gt;Tests DSLC by shaking every part (I describe this as wiggling all parts of the system to see how it changes the output)&lt;/li&gt;
              &lt;li&gt;There is always something to follow up when building models
                &lt;ul&gt;
                  &lt;li&gt;New users&lt;/li&gt;
                  &lt;li&gt;New patients&lt;/li&gt;
                  &lt;li&gt;New collaborators&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Data Perturbations
            &lt;ul&gt;
              &lt;li&gt;Data modality choices&lt;/li&gt;
              &lt;li&gt;Synthetic data&lt;/li&gt;
              &lt;li&gt;Data under different environments (invariance)&lt;/li&gt;
              &lt;li&gt;Differential privacy (DP)&lt;/li&gt;
              &lt;li&gt;Adversarial attacks to deep learning algorithms&lt;/li&gt;
              &lt;li&gt;Data cleaning also falls into this data perturbation bucket&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Model/algorithm perturbations
            &lt;ul&gt;
              &lt;li&gt;Robust statistics&lt;/li&gt;
              &lt;li&gt;Semi-parametric&lt;/li&gt;
              &lt;li&gt;Lasso and Ridge&lt;/li&gt;
              &lt;li&gt;Modes of non-convex empirical minimization&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Human decision is prevalent in DSCL
            &lt;ul&gt;
              &lt;li&gt;Which problem to work on&lt;/li&gt;
              &lt;li&gt;Which data sets to use&lt;/li&gt;
              &lt;li&gt;How to clean&lt;/li&gt;
              &lt;li&gt;Whats plots&lt;/li&gt;
              &lt;li&gt;What data perturbations, etc.&lt;/li&gt;
              &lt;li&gt;WRITE THIS ALL DOWN (MODEL CARDS FOR MODEL REPORTING)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Reality correspondences &amp;lt;- great description of what we do when we “model” something&lt;/li&gt;
          &lt;li&gt;How do we choose these perturbations?
            &lt;ul&gt;
              &lt;li&gt;One can never consider &lt;em&gt;all&lt;/em&gt; perturbations&lt;/li&gt;
              &lt;li&gt;A pledge to the stability principle in PCS would lead to null results if too many perturbations were considered&lt;/li&gt;
              &lt;li&gt;PCS requires documentations on the appropriateness of all perturbations&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Expanding statistical inference under PCS
            &lt;ul&gt;
              &lt;li&gt;Modern goal of statistics is to provide one source of truth&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Critical examination of probabilistic statements in statistical inference
            &lt;ul&gt;
              &lt;li&gt;Viewing data as a realization of a random process is an ASSUMPTION unless randomization is explicit
                &lt;ul&gt;
                  &lt;li&gt;THIS DATA COULD HAVE BEEN GENERATED NON-RANDOMLY&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;When not, using an r.v. actually implicitly assumes “stability”&lt;/li&gt;
              &lt;li&gt;Use “approximate” and “postulated” models&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Inference beyond probabilistic models
            &lt;ul&gt;
              &lt;li&gt;We need to have a way to bring PDE models in with things like synthetic data&lt;/li&gt;
              &lt;li&gt;Proposed PCS framework
                &lt;ul&gt;
                  &lt;li&gt;Problem formulation - translate the domain question to be answered by a model/algorithm (or multiple of them and seek stability)&lt;/li&gt;
                  &lt;li&gt;Prediction Screening for reality check : filter models/algorithms based on prediction accuracy on held out test data&lt;/li&gt;
                  &lt;li&gt;Target value perturbation distribution - Evaluate the target of interest across “appropriate” data and model pertubations&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Making Random Forests more interpretable using stability&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;uniform-convergence-may-be-unabe-to-explain-generaliation-in-deep-learning&quot;&gt;Uniform Convergence may be unabe to explain generaliation in deep learning&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~vaishnan/talks/neurips19_uc_slides.pdf&quot;&gt;Slides&lt;/a&gt; 
&lt;a href=&quot;http://www.cs.cmu.edu/~vaishnan/talks/neurips19_uc_poster.pdf&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tightest uniform convergence bound that eventually shows it is vacuous&lt;/li&gt;
  &lt;li&gt;Given a training set $S$, algorithm $h$ in $\mathbb{H}$, then [Sl]&lt;/li&gt;
  &lt;li&gt;In what setting do we show this bounds failure/
    &lt;ul&gt;
      &lt;li&gt;Separating an nested hyperspheres, with no hidden noise, and completely separable&lt;/li&gt;
      &lt;li&gt;Observe that as we increase number of training data point, the loss follows as expected&lt;/li&gt;
      &lt;li&gt;As we change the label of the datapoints between the hyperspheres, we take the set of all data points and show that s’ is completely mis-classified even though it is a completely valid member of the training dataset.
        &lt;ul&gt;
          &lt;li&gt;intuitively this can happen only if the boundary we have learned has “Skews” at each training point
            &lt;ul&gt;
              &lt;li&gt;What this means is the learn decision boundary is quite complex&lt;/li&gt;
              &lt;li&gt;This complexity that even the most refined hypotehsis class is quite complex&lt;/li&gt;
              &lt;li&gt;This proves the bounds are vacuous&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;This overparameterzed deep network can&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Looking aheead it’s important to understand the complexities contained within the decision boundaries and derive new tools as a test case&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;on-exact-computation-with-an-infinitely-wide-neural-network-slides-poster&quot;&gt;On Exact computation with an infinitely wide neural network &lt;a href=&quot;https://neurips.cc/media/Slides/nips/2019/westexhibitionhallc+b3(10-10-05)-10-10-20-15845-on_exact_comput.pdf&quot;&gt;Slides&lt;/a&gt; &lt;a href=&quot;http://www.cs.cmu.edu/~ruosongw/poster_cntk.pdf&quot;&gt;Poster&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Neural Tangent Kernel’s (NTK’s)&lt;/li&gt;
  &lt;li&gt;Theoretical contribution
    &lt;ul&gt;
      &lt;li&gt;When width is sufficiently large (polynomial in number of data, depth and inverse of target accuracy) the predictor learned by applying gradient descent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Empirical contribution
    &lt;ul&gt;
      &lt;li&gt;Dynamic programming techniques for calculating NTK’s for CNN’s + efficient GPU implementations&lt;/li&gt;
      &lt;li&gt;There is still a gap between the performance of CNN’s and that of the NTK’s
        &lt;ul&gt;
          &lt;li&gt;This means that the success of deep learning cannot be fully explained by NTK’s&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Future directions
        &lt;ul&gt;
          &lt;li&gt;Understand neural net architectures and common techniquest from the lends of NTK’s&lt;/li&gt;
          &lt;li&gt;Combine NTK with other techniques in kernel methods&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generalization-bounds-of-stochastic-gradient-descent&quot;&gt;Generalization Bounds of Stochastic Gradient Descent&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://neurips.cc/media/Slides/nips/2019/westexhibitionhallc+b3(10-10-05)-10-10-25-15846-generalization_.pdf&quot;&gt;Slides&lt;/a&gt; 
&lt;a href=&quot;https://drive.google.com/drive/folders/1dHLGUG78Uei4c8YEVfv2qFSVO8MGfDy5?usp=sharing&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Learning large overparameterized DNN’s, the empirical observation don extremely wide networks shows that generalization error tends to vary&lt;/li&gt;
  &lt;li&gt;Deep RELU networks are almost linear in terms of their parameters on small neighborhoods around random initialization&lt;/li&gt;
  &lt;li&gt;Applicable to general loss functions&lt;/li&gt;
  &lt;li&gt;Generalization bounds for wide and DNN’s that do not increase in network width&lt;/li&gt;
  &lt;li&gt;Random feature model (NTRF) that naturally connects over-parameterized DNNs with NTK&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;efficient-and-accuract-estimation-of-lipschitz-constands-for-dnns&quot;&gt;Efficient and Accuract estimation of lipschitz constands for DNN’s&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://neurips.cc/media/Slides/nips/2019/westexhibitionhallc+b3(10-10-05)-10-10-30-15847-efficient_and_a.pdf&quot;&gt;Slides&lt;/a&gt; 
&lt;a href=&quot;https://www.seas.upenn.edu/~mahyarfa/files/Slides_NeurIPS_2019.pdf&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lipschitz constant means with 2 points X and Y, they’ll be close before and after being passed through the neural network
    &lt;ul&gt;
      &lt;li&gt;generalization bounds and robust classification lean on this&lt;/li&gt;
      &lt;li&gt;This problem of computing Lipschitz constants is NP hard so we try to find tight bounds around this&lt;/li&gt;
      &lt;li&gt;Say we have an accurate upper bound of a model
        &lt;ul&gt;
          &lt;li&gt;We can take a point f(x), and we can measure \delta of mis-classification and input that back into the network
            &lt;ul&gt;
              &lt;li&gt;We can certify that if we perturb X in a small ball drawn around this delta, it odesn’t change the classification&lt;/li&gt;
              &lt;li&gt;If we can find this small lipschitz constanc we might be able to prove that this network has a form of robustness&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;HOw do we do this?
            &lt;ul&gt;
              &lt;li&gt;Product of the norm of the matrices
                &lt;ul&gt;
                  &lt;li&gt;Simple methods like this give upper nounds to the lipschitz constant that are conservative. Can we do anything more accurate?&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;We cna frame up finding this Lipschitz constant as a non-convex optimization problem
                &lt;ul&gt;
                  &lt;li&gt;Over approximate the hidden layers via incremental qudratic constaints
                    &lt;ul&gt;
                      &lt;li&gt;Give rise to a semi-definite program giving us this tight upper bound that we’re looking for&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;We can trade off scalability with accuracy of the upper bound&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;How does this bound we get compare to others?
            &lt;ul&gt;
              &lt;li&gt;We show that in general our bound is much tighter than other bounds&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Adversarial robustness
        &lt;ul&gt;
          &lt;li&gt;Hypothesis trained using adversarial optimizers
            &lt;ul&gt;
              &lt;li&gt;Emperitically when we evaluate this lipschitz constant these networks have much lower&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Accurate and scalable way of calculating Lipschitz constants in Neural Networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;regularization-effect-of-a-large-initial-learning-rate&quot;&gt;Regularization Effect of a large initial learning rate&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://neurips.cc/media/Slides/nips/2019/westexhibitionhallc+b3(10-10-05)-10-10-35-15848-towards_explain.pdf&quot;&gt;Slides&lt;/a&gt; 
&lt;a href=&quot;https://drive.google.com/file/d/1lg8hg-1QMFUDvYzZWg83DF7X3yXSl9kw/view?usp=sharing&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Large initial learning rates are crucial for generalization&lt;/li&gt;
  &lt;li&gt;Scaling back by a certain factor at certain epochs
    &lt;ul&gt;
      &lt;li&gt;small learning rates early on lead to better train and test performance?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Learning rate schedule changes the order of patterns in the data whcih influence the network
    &lt;ul&gt;
      &lt;li&gt;class signitures in the data that admit what the class is, but it will ignore other patterns in the data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Large learning rates initially learn easy patterns but hard-to-fit patterns after annealing&lt;/li&gt;
  &lt;li&gt;Non-convexity is crucial because different learning rate schedules will find different solutions&lt;/li&gt;
  &lt;li&gt;Artificially modify CIFAR 10 to exhibit specific pattern types
    &lt;ul&gt;
      &lt;li&gt;20% are hard to generalize - because of variations in the image&lt;/li&gt;
      &lt;li&gt;Easier to fit in the second set 20%, easy to generalize but hard to fit – this is by construction&lt;/li&gt;
      &lt;li&gt;Path that imitates what the class is&lt;/li&gt;
      &lt;li&gt;60% of examples overlay a patch on the image and the memorization of the patch early on shows this method fits early and doesn’t generalize well&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-dependent-sample-complexities&quot;&gt;Data-Dependent Sample Complexities&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://neurips.cc/media/Slides/nips/2019/westexhibitionhallc+b3(10-10-05)-10-10-40-15849-data-dependent_.pdf&quot;&gt;Slides&lt;/a&gt; 
&lt;a href=&quot;https://drive.google.com/file/d/1E5SV6Mx_YDCPqnE5aAISSTk09mUkNu6L/view?usp=sharing&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How do we design principle regularizers for DNN’s
    &lt;ul&gt;
      &lt;li&gt;Current technqiues are designed ad-hoc
        &lt;ul&gt;
          &lt;li&gt;Batch-norm and dropout - we know they work, but noy why&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Can we prove a theoretically upper bound on the generalization and hope it improves performance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bottle-neck prior
    &lt;ul&gt;
      &lt;li&gt;most priors only ocnsider the norms of weight matrices and because of this they get pessimistic bounds that are exponential in depth&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bounds that depends more on data dependent properties
    &lt;ul&gt;
      &lt;li&gt;upperbounded by the weights and training data&lt;/li&gt;
      &lt;li&gt;informal theory is that this can be upper bounded by (see slides)&lt;/li&gt;
      &lt;li&gt;Jacobian norm isthe max norm of the jacobian of the model on the hidden layers&lt;/li&gt;
      &lt;li&gt;margin is the largest logit of the output, minus the second largest&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;INterpretation of this bound is it measures the ‘Lipschitzness” of the network around training examples&lt;/li&gt;
  &lt;li&gt;Noise stability is small in practice with looser bounds (see slides)&lt;/li&gt;
  &lt;li&gt;Regularize the bound
    &lt;ul&gt;
      &lt;li&gt;penalize the square jacobian norm in the loss&lt;/li&gt;
      &lt;li&gt;Normalzation layers such as batch norm and layer norm
        &lt;ul&gt;
          &lt;li&gt;Helps in a lot of settings&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Check the bounds correlate with the test error and we found that our bound correlates well with test error&lt;/li&gt;
  &lt;li&gt;COnclusions
    &lt;ul&gt;
      &lt;li&gt;Tighter data dependent properties&lt;/li&gt;
      &lt;li&gt;Bound will avoid the exponential dependency on th depth of the network and optimizing this bound helps to improve performance&lt;/li&gt;
      &lt;li&gt;Follow up work : tigher bounds and empirical improvement over strong baselines&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;machine-learning-meets-single-cell-biology--insights-and-challenges&quot;&gt;Machine Learning Meets Single Cell Biology : Insights and Challenges&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Address something asked by DaVinci - How are we made?
    &lt;ul&gt;
      &lt;li&gt;We’re created from a single cell and it eentually creates every cell in our body.&lt;/li&gt;
      &lt;li&gt;How does this process happen?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cells are like tiny computers, taking input and output through things like proliferation, differentiation, and activation&lt;/li&gt;
  &lt;li&gt;ALl cells have the same genetic code – 3 billion letters
    &lt;ul&gt;
      &lt;li&gt;How our genome is the instruction set for assembling the different cells&lt;/li&gt;
      &lt;li&gt;Telling eachother how to behave&lt;/li&gt;
      &lt;li&gt;We have 100’s of cells&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Single cell RNA-sequencing in droplet micro-fluids
    &lt;ul&gt;
      &lt;li&gt;Measures for every single gene and cell for what gene it is and what cell it came from&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The data matric for one sample ~ 250 million
    &lt;ul&gt;
      &lt;li&gt;Gene by cell matrix that is rife with errors and artifacts from measurement&lt;/li&gt;
      &lt;li&gt;We only capture about 5% of the transcripts, or what the humans are expressing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In the field, zero-inflation has taken root
    &lt;ul&gt;
      &lt;li&gt;It’s wrong&lt;/li&gt;
      &lt;li&gt;“Drop out” – this is uniform sampling and it sometimes leaves us to capture no gene or transcription gene
        &lt;ul&gt;
          &lt;li&gt;every sample is affected by this&lt;/li&gt;
          &lt;li&gt;No value is at it’s actual value&lt;/li&gt;
          &lt;li&gt;This should be modeled properly and not with 0 inflation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;How do we handle all of this data
        &lt;ul&gt;
          &lt;li&gt;We like to visualize into 2 and 3 dimensions&lt;/li&gt;
          &lt;li&gt;PCA failed this data type and we couldn’t visualize it very well&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Following a Keynote at NeurIPS, someone presented T-SNE and it seems to fit the data well and we get good cell level separation&lt;/li&gt;
      &lt;li&gt;While we might have a matrix of 20000 genes x 100000 cells – T-SNE and UMAP seem to capture this non-linearity well&lt;/li&gt;
      &lt;li&gt;We have this manifold because cell phenotypes are highly regulated
        &lt;ul&gt;
          &lt;li&gt;We can see in 3D the nicely shaped non-convex shape&lt;/li&gt;
          &lt;li&gt;Similar shapes in families because few regulators drive cell shape&lt;/li&gt;
          &lt;li&gt;Lots of feedback loops and interactions between these genes, which limits and constricts the phenotypes a cell can be in&lt;/li&gt;
          &lt;li&gt;Still have challenges in visualization
            &lt;ul&gt;
              &lt;li&gt;Build better vis for this data as it’s non-uniform and 5 orders of different density
                &lt;ul&gt;
                  &lt;li&gt;Challenge is to handle this data with such different densities, it trips up many of the approaches we have today&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Common way to viz beyond 2 or 3 dimensions using nearest neighbor graphs
            &lt;ul&gt;
              &lt;li&gt;We connect a cell to cells nearest that cell
                &lt;ul&gt;
                  &lt;li&gt;This is dependent on probability distributions which help to define this similarity metric&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;The idea is one we have this graph we can really retain the manifold and use things like geodesic differences
            &lt;ul&gt;
              &lt;li&gt;Each tiny differnce in this graph can represent small differences between cells
                &lt;ul&gt;
                  &lt;li&gt;We can do distances and walks in these grpahs that allow us to measure the distance between cells&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Data is extreme structures and there are communities
            &lt;ul&gt;
              &lt;li&gt;Social media community detection approaches find cell states and cell densities that are captures as cliques in the graph&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Nice thing is that these graphs are connected
            &lt;ul&gt;
              &lt;li&gt;They share connectivity which allows us to cpature cell type transitions
                &lt;ul&gt;
                  &lt;li&gt;These transitions are very sparse relative to the cell type&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Using 100 ro 200 examples over 10000 entities
            &lt;ul&gt;
              &lt;li&gt;This isn’t regular science and this works because biology has lots of structure and isn’t adversarial in that respect&lt;/li&gt;
              &lt;li&gt;100000 or 1000000 cellshave awesome things – treating each cell as a computer we can assume that the mollecrular influences create statistical dependencies in the data&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Out of the box algorithm gets us a correct reconstruction with no prior information of TCell networks&lt;/li&gt;
          &lt;li&gt;Thisallows us to do disease regulatory networks and helps us to understand what is wrong in this specific cancer patient&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Asynchronous nature of the data
        &lt;ul&gt;
          &lt;li&gt;All of our immune cells are in our bone marrow and these cells are able to generate all varities of immune cells within our bodies&lt;/li&gt;
          &lt;li&gt;Asynchrony enables the inference of temporal pgoression&lt;/li&gt;
          &lt;li&gt;From a single time point we can capture all of the dynamics of the process&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Pesudo-time
        &lt;ul&gt;
          &lt;li&gt;Reconstructing developement which allows us to reconstruct order grom a single time point&lt;/li&gt;
          &lt;li&gt;THis process is highly non-linear we can order cells by chronology and the assumption is cell phenotypes change gradually
  `	* Cannot be treated as absolute values as we know this data is incredinly noisey&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Wanderlust
        &lt;ul&gt;
          &lt;li&gt;We are able to reconstruct accurate progressions and discover order and timing of key events along differentiation&lt;/li&gt;
          &lt;li&gt;This checkpoint of DNS recombinations inside of a cell, we wanted to understand if it were OK
            &lt;ul&gt;
              &lt;li&gt;pediatric cancer is caused by understanding this checkpoint&lt;/li&gt;
              &lt;li&gt;This wasn’t known until we could find this tiny new cell population and it’s novel regulation&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data is structured
        &lt;ul&gt;
          &lt;li&gt;bifurcations through use of walks and waypooints
            &lt;ul&gt;
              &lt;li&gt;the direct route between two cells along the same path should be more direct than non-immediate connections&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;These waypoints help to resolve structure
            &lt;ul&gt;
              &lt;li&gt;We find these using spectral clustering&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Mapping development
    &lt;ul&gt;
      &lt;li&gt;We want to order these cells on their manifold and understand how they bifurcate&lt;/li&gt;
      &lt;li&gt;What decision making is going on and what is their possible future cell types and propensity to turn into these cell types&lt;/li&gt;
      &lt;li&gt;Palantir : Building a Markiv Chain out of this graph allows us to find time ordering in our neighbor grpahs
        &lt;ul&gt;
          &lt;li&gt;strong assumption that development goes forward and not back&lt;/li&gt;
          &lt;li&gt;broken in processes such as cancer
            &lt;ul&gt;
              &lt;li&gt;build a directed graph from this&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;we can look at the extrema states and we find ourselves with an absorbing markov chain&lt;/li&gt;
          &lt;li&gt;This allows us to compute the end states of all of our cells and we can roll out the fate for each cell
            &lt;ul&gt;
              &lt;li&gt;entropy of these probabiities for all cells&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;The proof is in the pudding – applied to early mouse developemnt (endoderm (all internal organs are made of this))&lt;/li&gt;
          &lt;li&gt;Data organized nicely along these dimensions
            &lt;ul&gt;
              &lt;li&gt;cells aligned along temporal orders&lt;/li&gt;
              &lt;li&gt;approximal distral organizations&lt;/li&gt;
              &lt;li&gt;These organizations happen head to tail&lt;/li&gt;
              &lt;li&gt;A smooth gut tube, even though we can’t see anything that accounts for this organization, we can see the primodal organs jutting out from this tube&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;We can transcriptionally see where cells are headed a full day before they progress in that way
            &lt;ul&gt;
              &lt;li&gt;We go into the early days of the first decisions of the cells
                &lt;ul&gt;
                  &lt;li&gt;cell can become one of many classes&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;We can take spatio-temporal maps of the mamaallian endoderm
            &lt;ul&gt;
              &lt;li&gt;We see when FGR1 and FGR2 are both high, they’ll be primitive endoderm&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Very high entropy &lt;em&gt;Right&lt;/em&gt; before this deicsion is made and entropy drops immedaitely after
            &lt;ul&gt;
              &lt;li&gt;analysis shows that biologist saw that these cells are plastiq – they can change by jumping out of that area and into the emryonic layer and assume the nature of the other cells&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Plasticity was predicted computationally, and we were then able to verify empirically&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Human Cell Atlas
    &lt;ul&gt;
      &lt;li&gt;Cells in our body, relationships between then, and transitions that happen within the human cellular system&lt;/li&gt;
      &lt;li&gt;Most of the data is still single cell genomics
        &lt;ul&gt;
          &lt;li&gt;This atlas will have single cell genomics and spacial information of these cells&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This will require tons of computation
        &lt;ul&gt;
          &lt;li&gt;global and open community that anyone can join&lt;/li&gt;
          &lt;li&gt;public data of 10 billion cell playground&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Human cell atlas will serve as a healthy reference and ground truth for disease
        &lt;ul&gt;
          &lt;li&gt;The methods we have now don’t scale&lt;/li&gt;
          &lt;li&gt;Data harmonization
            &lt;ul&gt;
              &lt;li&gt;data from multiple samples that might be diseased
                &lt;ul&gt;
                  &lt;li&gt;our methods mistake disease for biological differnce&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Factor analysis for good gene programs
            &lt;ul&gt;
              &lt;li&gt;How this data factors betwen cells and genes&lt;/li&gt;
              &lt;li&gt;Simply comparing disease to normal&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Latent sapces : Deep Learning in scRNA-seq
    &lt;ul&gt;
      &lt;li&gt;count basis projected into latent space
        &lt;ul&gt;
          &lt;li&gt;Data denoising and integration&lt;/li&gt;
          &lt;li&gt;low dimensional embeddings&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Interpretation of latent factors is still lacking&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Our goal is not to predict, but to understand
    &lt;ul&gt;
      &lt;li&gt;Often the outlier is the &lt;em&gt;most&lt;/em&gt; important&lt;/li&gt;
      &lt;li&gt;machine learning is all about the common mechanism and not the outlier, whereas biology &lt;em&gt;wants&lt;/em&gt; to know those outliers&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Keep our eye on the goal in biology and understanding that something rate&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Dendritic cells are rare
        &lt;ul&gt;
          &lt;li&gt;These cells split into different&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Cell types aren’t necessarily clusters
        &lt;ul&gt;
          &lt;li&gt;Though clusters still have their own version of structure to them&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The more we zoom in, the more we find structure in this data and we see that meta-cells have real peaks in their density
        &lt;ul&gt;
          &lt;li&gt;These meta-cells are defined by different programs and different covariances&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Acute myioloid lukemia is accute cancer gone awry
    &lt;ul&gt;
      &lt;li&gt;Normal immune cells seem to overlap&lt;/li&gt;
      &lt;li&gt;These are early projectors of cancer cells – before they go awry and crazy&lt;/li&gt;
      &lt;li&gt;We want to know what happens that normal &amp;lt;&amp;gt; breaks, and cancer forms&lt;/li&gt;
      &lt;li&gt;When we look at classicial methods, these diseases don’t connect
        &lt;ul&gt;
          &lt;li&gt;We believe in covariation and find a manifold that is driven by covariation and not just normal distributions&lt;/li&gt;
          &lt;li&gt;Covariation in much lower dimensional space is much more computationally efficient&lt;/li&gt;
          &lt;li&gt;The regulatory systems that go awry
            &lt;ul&gt;
              &lt;li&gt;When we run these methods, we can see exactly where the cancer breaks off and becomes cancer&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Response to therapy
    &lt;ul&gt;
      &lt;li&gt;Bone marrow transplant patients who relapse and understanding how that relapse happens&lt;/li&gt;
      &lt;li&gt;Understand the immune populations that differ between them, and using these dynamics we can see cell populations that really follow and raise up as the tumor burden rises and falls&lt;/li&gt;
      &lt;li&gt;These are very tiny populations, so one has to be very careful in computation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Epigenetic data
    &lt;ul&gt;
      &lt;li&gt;What potential regulators that can be regulating these systems&lt;/li&gt;
      &lt;li&gt;We can build generative processes, and using these latent variables we can understand different properties of these biological systems
        &lt;ul&gt;
          &lt;li&gt;What is the covariate nature&lt;/li&gt;
          &lt;li&gt;We can understand inter-variable influence&lt;/li&gt;
          &lt;li&gt;What factors combine to what targets through their regulators&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Most cells in a tumor in solid tumors are not cancer
    &lt;ul&gt;
      &lt;li&gt;immune cells and supportive tissue make up 90%&lt;/li&gt;
      &lt;li&gt;using factor analysis we can see cancer highjacks early development of these processes
        &lt;ul&gt;
          &lt;li&gt;using a program that the embryo knows to metasticize a new organ in another part of the body
            &lt;ul&gt;
              &lt;li&gt;understanding how they survive in the brain&lt;/li&gt;
              &lt;li&gt;Identify that all cancers, both breast and lung, have the same gene that created their ability to survive there&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Cancer uses regenerative mechanisms for it’s evil deeds
        &lt;ul&gt;
          &lt;li&gt;1 change in 6 billion base pairs can make it go different under injury&lt;/li&gt;
          &lt;li&gt;The reason that this is is because there is enormous cross talk and remodeling between the eputhelial systems and the cancer&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Spacial techniques are critically important
        &lt;ul&gt;
          &lt;li&gt;Rapid autopsy programs allow us to collect samples&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;test-of-time-award--dual-averaging-method-for-regularized-stochastic-and-online-optimization&quot;&gt;Test of time award : Dual Averaging Method for Regularized Stochastic and Online Optimization&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stochastic optimization and empirical risk minimization&lt;/li&gt;
  &lt;li&gt;We want to minimize the empirical risk of a very large sample
    &lt;ul&gt;
      &lt;li&gt;Convergence theory
        &lt;ul&gt;
          &lt;li&gt;Depending on loss function’s convexity or strong convexity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Online Convex optimization
        &lt;ul&gt;
          &lt;li&gt;Here we consider an online game where each player predicts t+1
            &lt;ul&gt;
              &lt;li&gt;suffers a loss $f_t(w_t)$&lt;/li&gt;
              &lt;li&gt;loss measures total loss of a fixed $w$ from hindsight&lt;/li&gt;
              &lt;li&gt;very similar to SGD&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Compressed sensing / sparse optimization
        &lt;ul&gt;
          &lt;li&gt;LASSO
            &lt;ul&gt;
              &lt;li&gt;minimize quadratic function with a constraint in the $l_1$ norm&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Proximal gradient methods
        &lt;ul&gt;
          &lt;li&gt;Adding up of convex&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;causal-confusion-in-imitation-learning&quot;&gt;Causal Confusion in Imitation Learning&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Imitation learning is a powerful method for learning complex behaviors
    &lt;ul&gt;
      &lt;li&gt;driving cars, flying drones, and grasp and pitch&lt;/li&gt;
      &lt;li&gt;Behavioral cloning&lt;/li&gt;
      &lt;li&gt;Supervised learning through observations of experts&lt;/li&gt;
      &lt;li&gt;Not perfect
        &lt;ul&gt;
          &lt;li&gt;Expert state and we roll out these states we get errors of the imitator acculator that show up in other parts of the state space&lt;/li&gt;
          &lt;li&gt;distributional shift that arises due to this causality&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Does more information lead to better performance?
        &lt;ul&gt;
          &lt;li&gt;What happens under distribution shift?&lt;/li&gt;
          &lt;li&gt;Turns out that a given model learns to pay attention to the road and brakes when someone is in the road&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;These fail because the model cannot infer causality&lt;/li&gt;
      &lt;li&gt;Can we predict the expert’s next action
        &lt;ul&gt;
          &lt;li&gt;This is the only cause&lt;/li&gt;
          &lt;li&gt;The expert ignore it and its nuisance variable&lt;/li&gt;
          &lt;li&gt;End state variables
            &lt;ul&gt;
              &lt;li&gt;If we learn 1 imitator that watches the road&lt;/li&gt;
              &lt;li&gt;We can learn another imitator that wrongly treats both variables as a cause&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;IN general if we have 2^N possible causal graphs&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Existence of causal confusion
        &lt;ul&gt;
          &lt;li&gt;Consider 2 examples
            &lt;ul&gt;
              &lt;li&gt;learns actions through history and one that doesn’t&lt;/li&gt;
              &lt;li&gt;validation score on held out data history plays a role in working well with history but in test it causes confusion&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;How do we demonstrate this
            &lt;ul&gt;
              &lt;li&gt;We add to the original state and use this information to create confounded states&lt;/li&gt;
              &lt;li&gt;This corresponds to having just the causal&lt;/li&gt;
              &lt;li&gt;Use a VAE and treat the dimensions of the latent variables as potential causes
                &lt;ul&gt;
                  &lt;li&gt;Using behavioral cloning on the original state we get expert like rewards&lt;/li&gt;
                  &lt;li&gt;On confouded states, we do much worse indicating causal confusion&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;What we need is to have a causal graph that indicates the random variables that the expertt pays attention to&lt;/li&gt;
              &lt;li&gt;In the first phease we learn from all possible causal graphs
                &lt;ul&gt;
                  &lt;li&gt;Binary vectors 1 - cause, 2 - nuisance&lt;/li&gt;
                  &lt;li&gt;randomly sample a causal graph and mask out the nuisance part of the state&lt;/li&gt;
                  &lt;li&gt;we concatenate the graph and feed it to into a NN and it predicts an action
                    &lt;ul&gt;
                      &lt;li&gt;behavioral cloning loss&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;In the second phase we infer the correct causal graph
                &lt;ul&gt;
                  &lt;li&gt;intervention changes th distribution of the state&lt;/li&gt;
                  &lt;li&gt;we score all possible graphs on additional information
                    &lt;ul&gt;
                      &lt;li&gt;Mode 1 : query reward&lt;/li&gt;
                      &lt;li&gt;Mode 2 :&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Collect trjectories as policies&lt;/li&gt;
              &lt;li&gt;Query expert on states&lt;/li&gt;
              &lt;li&gt;Pick graph most in agreement with experts&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;DAGGer baseline performs significantly worse&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Learned graph visualization
        &lt;ul&gt;
          &lt;li&gt;learned causal graph can ignore nuisance variables&lt;/li&gt;
          &lt;li&gt;More information can hurt performance without this effort&lt;/li&gt;
          &lt;li&gt;How to scale this up to more complicated tasks&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;imitation-learning-from-observations-by-minimizing-inverse-dynamics-disagreement&quot;&gt;Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MDP formulation&lt;/li&gt;
  &lt;li&gt;Divergence minimization perspective on inverse learning
    &lt;ul&gt;
      &lt;li&gt;GAIL or AIRL
        &lt;ul&gt;
          &lt;li&gt;KL and JS divergences could be used&lt;/li&gt;
          &lt;li&gt;Adversarial training for divergence minimization&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;structure-prediction-approach-for-generalization-in-cooperative-multi-agent-rl&quot;&gt;Structure Prediction approach for generalization in cooperative multi-agent RL&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;guided-metapolicy-policy-search&quot;&gt;Guided Metapolicy policy Search&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt; 
&lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;using-logarithmic-mapping-to-enable-lower-discount-factors-in-reinforcement-learning&quot;&gt;Using logarithmic Mapping to Enable Lower Discount Factors in Reinforcement Learning&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Standard RL Setting
    &lt;ul&gt;
      &lt;li&gt;Discount factor in play here&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;This can be modeled as an MDP&lt;/li&gt;
  &lt;li&gt;Goal : find an optimal policy to maximize reward which is some long term objective&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;weight-agnostic-neural-networks&quot;&gt;Weight Agnostic Neural Networks&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Innate abilities in animals
    &lt;ul&gt;
      &lt;li&gt;we’re beginning to understand that ML architectures seem to have innateness&lt;/li&gt;
      &lt;li&gt;CNN’s are so well suited to image processing that they can do many tasks in that area&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How far can we push this innateness idea
    &lt;ul&gt;
      &lt;li&gt;To what extent can NN architectures along encode solutions to tasks?&lt;/li&gt;
      &lt;li&gt;Different kind of NAS
        &lt;ul&gt;
          &lt;li&gt;WE’re looking for NAS’ that perform without any training at all&lt;/li&gt;
          &lt;li&gt;Judged on 0-shot performance&lt;/li&gt;
          &lt;li&gt;Because of the large weight space
            &lt;ul&gt;
              &lt;li&gt;Use a single value for our weight space&lt;/li&gt;
              &lt;li&gt;Judge how well the network works by doing several roll out with different values&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Create a population of minimal networks
            &lt;ul&gt;
              &lt;li&gt;These have inputs with no hidden nodes, connected to some outputs&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Performance of the network is averaged over rollouts and then ranked
            &lt;ul&gt;
              &lt;li&gt;vary the networks to create new populations and continue the process&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;We can vary in one of 3 ways
            &lt;ul&gt;
              &lt;li&gt;Inset node&lt;/li&gt;
              &lt;li&gt;Add hidden connection&lt;/li&gt;
              &lt;li&gt;Change the activation function
                &lt;ul&gt;
                  &lt;li&gt;Gauss&lt;/li&gt;
                  &lt;li&gt;ReLU&lt;/li&gt;
                  &lt;li&gt;Sigmoid&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Tested on 3 RL tasks
        &lt;ul&gt;
          &lt;li&gt;cart-pole&lt;/li&gt;
          &lt;li&gt;bi-ped&lt;/li&gt;
          &lt;li&gt;car racing&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Compare these WAN found topologies
        &lt;ul&gt;
          &lt;li&gt;when trained can reach SoTA&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Randomize the weights they don’t perform well&lt;/li&gt;
      &lt;li&gt;Shared weights produce pretty good behaviors&lt;/li&gt;
      &lt;li&gt;If we tune the weights, they perform the same kind of SoTA performance as general purpose networks
        &lt;ul&gt;
          &lt;li&gt;Able to do this with much smaller networks, sometimes orders of magnitudes&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;For fun we tested this on MNIST
        &lt;ul&gt;
          &lt;li&gt;Here we use a random weight – we get an expected accuracy of 82%, best single weight is 92% – little better than linear regression&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Searching for building blocks toward a differnt kind of neural architecture search
        &lt;ul&gt;
          &lt;li&gt;architectures that have innate biases and priors&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;social-intelligence&quot;&gt;Social Intelligence&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What has changed since Rosenblat started playing with NN’s?
    &lt;ul&gt;
      &lt;li&gt;Compute power&lt;/li&gt;
      &lt;li&gt;Data&lt;/li&gt;
      &lt;li&gt;This gave Dean the idea to found Google Brain
        &lt;ul&gt;
          &lt;li&gt;Early 2010’s&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Edge TPU - 2 watts and 4 TOPS
        &lt;ul&gt;
          &lt;li&gt;Mobile-net-v2 @ 400FPS&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Coral.ai prototyping boards&lt;/li&gt;
      &lt;li&gt;Running workloads locally is important, BUT NOT SUFFICIENT, tool for implementing and reasoning about privacy&lt;/li&gt;
      &lt;li&gt;Have to be “smart” about what data is thrown off of a device using ML&lt;/li&gt;
      &lt;li&gt;Sanity wrt energy consumption and other natural resources
        &lt;ul&gt;
          &lt;li&gt;moving data is what costs energy&lt;/li&gt;
          &lt;li&gt;once the data is in a register and we want to operate over it, it’s relatively free
            &lt;ul&gt;
              &lt;li&gt;moving it is what costs energy&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How do we make these giant distributed frameworks run efficiently, effectively, and privately?
    &lt;ul&gt;
      &lt;li&gt;Federated learning allows centralized inference but localized training&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Scale?
    &lt;ul&gt;
      &lt;li&gt;100’s of millions of android phones have machine learning running on them&lt;/li&gt;
      &lt;li&gt;Scale story is more complex
        &lt;ul&gt;
          &lt;li&gt;data are both abundant and rare / precious
            &lt;ul&gt;
              &lt;li&gt;we don’t always have access to the data&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;compute is both massive and limited/precious
            &lt;ul&gt;
              &lt;li&gt;don’t effect UX&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Premium on quick covergence, ie/ &amp;lt; 1 pass over the data&lt;/li&gt;
          &lt;li&gt;FL both enabled ML fairness and can be in tension with it
            &lt;ul&gt;
              &lt;li&gt;long tail and rare event learning can endanger some of the privacy aspects&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Generative models are really important in the federalted setting – and it’s not just about making pretty pictures…
        &lt;ul&gt;
          &lt;li&gt;Capturing this underlying data generating distribution is key&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Open problems
    &lt;ul&gt;
      &lt;li&gt;tightening bounds, extending domains, handling infrastructure&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Where is all of this AI stuff going anyway?
    &lt;ul&gt;
      &lt;li&gt;ML / Data Science
        &lt;ul&gt;
          &lt;li&gt;Conflicting narratives&lt;/li&gt;
          &lt;li&gt;generally discussing regression problems&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;AI
        &lt;ul&gt;
          &lt;li&gt;Passing a test or winning a game&lt;/li&gt;
          &lt;li&gt;Super human performance given
            &lt;ul&gt;
              &lt;li&gt;A well defined problem&lt;/li&gt;
              &lt;li&gt;A loss function&lt;/li&gt;
              &lt;li&gt;enough data&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Just how remarkable territory this actually covers&lt;/li&gt;
          &lt;li&gt;What’s the loss function for more profound things like
            &lt;ul&gt;
              &lt;li&gt;criminal justice&lt;/li&gt;
              &lt;li&gt;couples therapy&lt;/li&gt;
              &lt;li&gt;Art&lt;/li&gt;
              &lt;li&gt;optimal hiring&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This is &lt;em&gt;not&lt;/em&gt; just a human issue
        &lt;ul&gt;
          &lt;li&gt;Neurophilospher
            &lt;ul&gt;
              &lt;li&gt;Success of ANN’s, notwithstanding, is a far cry from what intelligent bodies on this planet can do&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Motivational tribes are messy - paper in 2016 &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ecoli
    &lt;ul&gt;
      &lt;li&gt;bacteria have a 1 bit output
        &lt;ul&gt;
          &lt;li&gt;can go forward / back / turn like an RC car&lt;/li&gt;
          &lt;li&gt;trjectory os ecoli looks (see slides)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Energy is a function of their consumption and subsequent output&lt;/li&gt;
      &lt;li&gt;Is this consumption methodology optimal?
        &lt;ul&gt;
          &lt;li&gt;What actually has been optimized by evolution in this process?&lt;/li&gt;
          &lt;li&gt;Inverse Reinforcement Learning
            &lt;ul&gt;
              &lt;li&gt;well studied but ill-conditioned&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Modeling a signalling and sensoring function of the bacteria&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Genome is the reward map here
        &lt;ul&gt;
          &lt;li&gt;through this evolutionary approach we can see chemotaxis(SP?)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The error bars on this example are relaly big
        &lt;ul&gt;
          &lt;li&gt;colonies have lots of reward maps&lt;/li&gt;
          &lt;li&gt;huge variety of reward maps that do work (see slides)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;What persists, exists&lt;/li&gt;
      &lt;li&gt;evolution decides on what is good or bad&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;this is not exactly optimization**..&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Simple GAN 
  &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;All points are stable in wasserstein gan’s&lt;/li&gt;
          &lt;li&gt;The combined GAN is not doing gradient descent, locally each actor here is going gradient descent of its own well-defined cost function.
            &lt;ul&gt;
              &lt;li&gt;Put together, the combined system&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Loss functions and gradient wrt special and general relativity
        &lt;ul&gt;
          &lt;li&gt;Every actor is curving the space and this leads to general relativity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Many “solutions” in this bacteria case
        &lt;ul&gt;
          &lt;li&gt;signally begets collectivity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Optimization is not really how life works
        &lt;ul&gt;
          &lt;li&gt;it’s also not how brains work&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Backprop
    &lt;ul&gt;
      &lt;li&gt;Looking at real neurons are a hell of  alot more complicated&lt;/li&gt;
      &lt;li&gt;Brains don’t just evaluate a function
        &lt;ul&gt;
          &lt;li&gt;They develop&lt;/li&gt;
          &lt;li&gt;imprint&lt;/li&gt;
          &lt;li&gt;pre-programmed tasks&lt;/li&gt;
          &lt;li&gt;self-modifying
            &lt;ul&gt;
              &lt;li&gt;Looking at learning in ML, we’re trying to minimize a loss by picking a particular set of weights&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Chain rule for all of this stuff
            &lt;ul&gt;
              &lt;li&gt;backprop through a linear layer, we can see that these backprop equations look very similar to forward prop
                &lt;ul&gt;
                  &lt;li&gt;there’s a symmetry here&lt;/li&gt;
                  &lt;li&gt;Also this weight update equation looks kind of Hebbian&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;ANN’s generally only implement the top part of the equation&lt;/li&gt;
              &lt;li&gt;If we didn’t do the bottom parts of the equation, it wouldn’t be doing much&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The learning part of ML is a lot more complex than the feedforward linear layers in RELU
        &lt;ul&gt;
          &lt;li&gt;There’s always feedback&lt;/li&gt;
          &lt;li&gt;There’s always temporal dynamics&lt;/li&gt;
          &lt;li&gt;Also
            &lt;ul&gt;
              &lt;li&gt;momentum&lt;/li&gt;
              &lt;li&gt;mini-batch&lt;/li&gt;
              &lt;li&gt;adam&lt;/li&gt;
              &lt;li&gt;structured ranom init&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Neurons have all the building blocks
        &lt;ul&gt;
          &lt;li&gt;Per-cell state&lt;/li&gt;
          &lt;li&gt;Per-synapse state&lt;/li&gt;
          &lt;li&gt;Temporal averaging&lt;/li&gt;
          &lt;li&gt;Random number sources&lt;/li&gt;
          &lt;li&gt;multiple timescales&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Can we learn to learn with these building blocks?&lt;/li&gt;
      &lt;li&gt;A more general, biological symapse update rule that doesn’t require gradient descent
        &lt;ul&gt;
          &lt;li&gt;LSTM at every synapse&lt;/li&gt;
          &lt;li&gt;Shared weights, but individual state&lt;/li&gt;
          &lt;li&gt;Noise gate g&lt;/li&gt;
          &lt;li&gt;(Anti-)Hebbian&lt;/li&gt;
          &lt;li&gt;Neurons can behave the same way
            &lt;ul&gt;
              &lt;li&gt;Per cell state and learned behaviour for how to propagate&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Equations are factorial and not scalary
            &lt;ul&gt;
              &lt;li&gt;Chemical activity&lt;/li&gt;
              &lt;li&gt;allows multiple timescales&lt;/li&gt;
              &lt;li&gt;mu parameters allow mixing at different time scales&lt;/li&gt;
              &lt;li&gt;Slow timescales needed for learning, but also useful for time- qquestions&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Weights (or connectum)
            &lt;ul&gt;
              &lt;li&gt;learning&lt;/li&gt;
              &lt;li&gt;Development&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;LSTM parameters&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;In supervised learning paradigm:
        &lt;ul&gt;
          &lt;li&gt;short brain lifetimes&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Self-organizing neural cellular automata
    &lt;ul&gt;
      &lt;li&gt;Self-training NN’s that are training each cell
        &lt;ul&gt;
          &lt;li&gt;reproduces a pattern&lt;/li&gt;
          &lt;li&gt;learns how to do this via purely local interactions&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;These kinds of fundamentally social concepts and ensembles of “things” come together and create the systems we have today
    &lt;ul&gt;
      &lt;li&gt;how we find this dance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Grand Challenges
    &lt;ul&gt;
      &lt;li&gt;Brains with fully evolved architectures&lt;/li&gt;
      &lt;li&gt;Understanding and characterizing evolved systems
        &lt;ul&gt;
          &lt;li&gt;realm of anthropology and sociology&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Problem solving by artificial societies&lt;/li&gt;
      &lt;li&gt;Large-scale meta learning in the Federated setting&lt;/li&gt;
      &lt;li&gt;Purposive “artificial ecology” engineering&lt;/li&gt;
      &lt;li&gt;Dynamical systems theory for neural ensembles&lt;/li&gt;
      &lt;li&gt;Can we define quantitative “SOTAs” for sociality?&lt;/li&gt;
      &lt;li&gt;Can we think about what it would mean to approach this kind of “curved space” AI ethics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Artificial Life approaches?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dualdice&quot;&gt;DualDICE&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;
&lt;a href=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;from-system-1-deep-learning-to-system-2-deep-learning&quot;&gt;From System 1 Deep Learning to System 2 Deep Learning&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;These things are linked together in really interesting ways and he’s going to convince us of this&lt;/li&gt;
  &lt;li&gt;Connected to the notion of agency&lt;/li&gt;
  &lt;li&gt;Some people think that it might be enough to take what we have and grow our datasets and computer speed and all of a sudden we have intelligence
    &lt;ul&gt;
      &lt;li&gt;Narrow AI - machines need much more data to learn a new task&lt;/li&gt;
      &lt;li&gt;Sample efficiency&lt;/li&gt;
      &lt;li&gt;Human provided labels
        &lt;ul&gt;
          &lt;li&gt;These dont catch changes in distribution, etc.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Next step completely different from deep learning?
        &lt;ul&gt;
          &lt;li&gt;Do we need to take a step back to classical eras?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Thinking fast and slow
    &lt;ul&gt;
      &lt;li&gt;2 tasks
        &lt;ol&gt;
          &lt;li&gt;kinds of things we do inuitively and consciously and we can’t explain verbally
            &lt;ul&gt;
              &lt;li&gt;This is currently what DL is good at&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Slow and logical, sequential, conscious, linguistic, planning, reasoning
            &lt;ul&gt;
              &lt;li&gt;Future DL&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;We’re generalizing in a more powerful and conscious way in a way that we can explain
        &lt;ul&gt;
          &lt;li&gt;The kinds of things we do with system programming&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Missing to extend DL to reach human level AI
    &lt;ul&gt;
      &lt;li&gt;out of distribution generalization and transfer&lt;/li&gt;
      &lt;li&gt;Higher level cognitive system&lt;/li&gt;
      &lt;li&gt;High level semantic representations
      * corresponding to the kinds of concepts we link back to language&lt;/li&gt;
      &lt;li&gt;Causality
        &lt;ul&gt;
          &lt;li&gt;Many of these things tend ot be causal in effect&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Agent perspective
        &lt;ul&gt;
          &lt;li&gt;Better world models&lt;/li&gt;
          &lt;li&gt;Causality&lt;/li&gt;
          &lt;li&gt;Knowledge-seeking&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;There are questions between all of these 3 things listed above
        &lt;ul&gt;
          &lt;li&gt;If we make progress in one, we can make progress in another&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Consciousness
    &lt;ul&gt;
      &lt;li&gt;Roadmap for priors for empowering system 2&lt;/li&gt;
      &lt;li&gt;ML Goals : handle changes in dsistribution&lt;/li&gt;
      &lt;li&gt;System 2 basics : attention &amp;amp; consciousness
        &lt;ul&gt;
          &lt;li&gt;Cognitive neurscience to understand the human side of the consciousness&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Consciousness Prioer : sparse factor graphs
        &lt;ul&gt;
          &lt;li&gt;We can think of these things as assumptions of the world
            &lt;ul&gt;
              &lt;li&gt;The joint distribution betwen these high level concepts can be thought of as a factor graph&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Theoretical framework
        &lt;ul&gt;
          &lt;li&gt;meta-learning&lt;/li&gt;
          &lt;li&gt;localized changes hypothesis -&amp;gt; causal discovery
            &lt;ul&gt;
              &lt;li&gt;Localized in some abstract space&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Compositional DL architectures
        &lt;ul&gt;
          &lt;li&gt;Architectures we should explore to introduce the compositionality that we’ll need to explore
            &lt;ul&gt;
              &lt;li&gt;NN’s that operate on sets of objects, and not just vectors&lt;/li&gt;
              &lt;li&gt;Dynamical recombination&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Changes in distribution (from IID to OOD)
    &lt;ul&gt;
      &lt;li&gt;Artifically shuffle the data the achieve that?
        &lt;ul&gt;
          &lt;li&gt;Natures does not shuffle the data, we shouldn’t
            &lt;ul&gt;
              &lt;li&gt;IRM paper from Bottou&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Out of distribution generalization and transfer
        &lt;ul&gt;
          &lt;li&gt;No free lunch : need new assumptions to change this IID assumption&lt;/li&gt;
          &lt;li&gt;If we discard this IID assumption, we need to replace it by something else&lt;/li&gt;
          &lt;li&gt;Bengio posits priors might be the way to do this.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OOD Generalization
    &lt;ul&gt;
      &lt;li&gt;The phenomenon of learner being able to genearlaize in some way to a different distribution
        &lt;ul&gt;
          &lt;li&gt;If we are a learning agent (agent = actions)
            &lt;ul&gt;
              &lt;li&gt;we almost always face non-stationarities
                &lt;ul&gt;
                  &lt;li&gt;Due to actions of self (agent)&lt;/li&gt;
                  &lt;li&gt;actions of other agents&lt;/li&gt;
                  &lt;li&gt;movement through time and space&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Once we start looking at multi-agent systems, it gets even more complicated&lt;/li&gt;
          &lt;li&gt;THERE IS NO STATIONARITY IN OUR ABILITY TO SAMPLE REALITY IN THE WAY THAT WE DO&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Compositionality helps IID and OOD to generalize
    &lt;ul&gt;
      &lt;li&gt;Introducting more forms of compositionality allows us to learn from some finite set of combinations about a much larger set of combinations that are NOT in the set of the data that we have today&lt;/li&gt;
      &lt;li&gt;Distributed representations
        &lt;ul&gt;
          &lt;li&gt;Helps us see why we get an exponential advantage
            &lt;ul&gt;
              &lt;li&gt;If we make the right assumptions, these things can be explained by variables and factors, and once we train a bunch of eatures we can generalize to new combinations of these features&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Each layer is composed for the next one, and this gives us another exponential advantage
            &lt;ul&gt;
              &lt;li&gt;The one we know best we find in language
                &lt;ul&gt;
                  &lt;li&gt;We call this systemasticity&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This opens the door to better powers of analogies and abstract reasoning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Systematic generalization
    &lt;ul&gt;
      &lt;li&gt;Dynamically recombining existing concepts into new concepts&lt;/li&gt;
      &lt;li&gt;Even when new combinations have 0 probability under training distributions
        &lt;ul&gt;
          &lt;li&gt;eg. science fiction scenarios&lt;/li&gt;
          &lt;li&gt;eg. Driving in an unknown city&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Not very successful with the use of DL systems
        &lt;ul&gt;
          &lt;li&gt;Current methods when asking models to answer questions not in the distribution they do not know how to answer them&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Constrast with Symbolic AI Programs
    &lt;ul&gt;
      &lt;li&gt;Avoiding the pitfalls of classical AI rule-based symbol-manipulation&lt;/li&gt;
      &lt;li&gt;Need efficient large scale learning&lt;/li&gt;
      &lt;li&gt;need semantic grounding&lt;/li&gt;
      &lt;li&gt;need distributed representations for generalization&lt;/li&gt;
      &lt;li&gt;efficient = trained search (also system 1)&lt;/li&gt;
      &lt;li&gt;Need uncertainty handling&lt;/li&gt;
      &lt;li&gt;But want
        &lt;ul&gt;
          &lt;li&gt;systematic generalization&lt;/li&gt;
          &lt;li&gt;factorizing knowledge into small exchangable pieces&lt;/li&gt;
          &lt;li&gt;manipulating variables, instances, references &amp;amp; indirection&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;System 2
    &lt;ul&gt;
      &lt;li&gt;Consciousness and attention
        &lt;ul&gt;
          &lt;li&gt;Focus on one or a few elements at a time
            &lt;ul&gt;
              &lt;li&gt;when translating we focus on a specific word to do the translation&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Content-based soft attnetion is convenient, can backprop to &lt;em&gt;learn where to attend&lt;/em&gt;
            &lt;ul&gt;
              &lt;li&gt;Soft-max that conditions on each of the elements and we can see how well we match on context&lt;/li&gt;
              &lt;li&gt;Attention is parallel in that we compute a score for each and decide which ones where we want to put attnetion&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Attention should be thought of as the internal action
            &lt;ul&gt;
              &lt;li&gt;needs a &lt;strong&gt;learned attention policy&lt;/strong&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;SoTA language models all rely on attention
        &lt;ul&gt;
          &lt;li&gt;How attention, connected to memory, can also unlock the problem of vanishing gradients&lt;/li&gt;
          &lt;li&gt;Operating on unbounded sets of key value pairs&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;We can think of attention as creating a dynamic connection between layers
        &lt;ul&gt;
          &lt;li&gt;as opposed to being hard coded today&lt;/li&gt;
          &lt;li&gt;This is great, but from the point of view of the receiving model, it receives a value but it has no idea of where it’s coming from
            &lt;ul&gt;
              &lt;li&gt;We condition to the value, we have the concept of a key, an identifier for where this value came from
                &lt;ul&gt;
                  &lt;li&gt;We use this as a routing mechanism&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Downstream computation can know what the value it’s receiving and where it’s coming from
            &lt;ul&gt;
              &lt;li&gt;Creating a name for these objects through a form of indirection&lt;/li&gt;
              &lt;li&gt;we have systems of operating on sets&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;From &lt;strong&gt;attention&lt;/strong&gt; to &lt;strong&gt;consciouness&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;C-word is a bit taboo – but maybe not anymore&lt;/li&gt;
      &lt;li&gt;number of theories are related to the global workspace theory
        &lt;ul&gt;
          &lt;li&gt;This theory says that what is going on with consciousness, there is a bottleneck of information in that some elements of what is computed in your brain is selected and then broadcast to the rest of the brain and influencing it&lt;/li&gt;
          &lt;li&gt;Conditions heavily on perception and action
            &lt;ul&gt;
              &lt;li&gt;Also gives rise naturally to the system 2 abilities above&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Relation to ML?
    &lt;ul&gt;
      &lt;li&gt;ML can be used to help brain scientist understand consciouness&lt;/li&gt;
      &lt;li&gt;Work in neuroscience is based on fairly qualitative defns
        &lt;ul&gt;
          &lt;li&gt;ML can help us to quantify what this actually means&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Feedback loops help provide specific tests that we can use to measure these concepts&lt;/li&gt;
      &lt;li&gt;One of these motivations it to get rid of fuzziness and magic that surrounds consciousness&lt;/li&gt;
      &lt;li&gt;Provide advantages to these particular form of agents&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Thoughts, Consciousness, Language
    &lt;ul&gt;
      &lt;li&gt;There is as trong ling between thoughts and language, in that one can be translated between mediums farily easily though a lot of information si dropped on the floor during decoding&lt;/li&gt;
      &lt;li&gt;We want to explore things like Grounded Language Learning, by learning through environment interaction and perception
        &lt;ul&gt;
          &lt;li&gt;Allows a learning to get to patterns through to it’s understanding of how the world works&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The consciousness prior : sparse factor graphs
    &lt;ul&gt;
      &lt;li&gt;We can use these systems to encourage our learning systems to do a good job at out of distribution reasoning&lt;/li&gt;
      &lt;li&gt;Sparse factor graph
        &lt;ul&gt;
          &lt;li&gt;attention : to form conscious state, thought&lt;/li&gt;
          &lt;li&gt;A thought is low dimensional object
            &lt;ul&gt;
              &lt;li&gt;We sample these from a larger higher dimensional conscious state&lt;/li&gt;
              &lt;li&gt;The conscious states that we sample&lt;/li&gt;
              &lt;li&gt;The thoughts we consciously have are pushed through this consciousness bottleneck&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;What do these computations mean
        &lt;ul&gt;
          &lt;li&gt;Some kind of inference is required&lt;/li&gt;
          &lt;li&gt;What kind of joint distribution of high level concepts are we reasoning about&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Think about the kind of statements we make with natural language
        &lt;ul&gt;
          &lt;li&gt;“If I drop the ball, it will fall on the ground”
            &lt;ul&gt;
              &lt;li&gt;true but involved very few variables in that the statement only contains a finite number of words&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;The relationship that I need to descibe can tightly capture the elements of this joint probability through very few variables&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Disentangled factors != marginally independent, eg. hand &amp;amp; ball
        &lt;ul&gt;
          &lt;li&gt;We think of these as having this very structured joint distribution&lt;/li&gt;
          &lt;li&gt;They come with very strong and powerful relationships&lt;/li&gt;
          &lt;li&gt;Instead of imposing a very strong prior of complete margin independence we can find some prior that finds a joint distribution between these high level variables&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Meta-Learning : End to end
    &lt;ul&gt;
      &lt;li&gt;Meta-learning is learning to learn
        &lt;ul&gt;
          &lt;li&gt;Backprop through inner loop&lt;/li&gt;
          &lt;li&gt;Having multiple timescales of learning
            &lt;ul&gt;
              &lt;li&gt;iterative optimization like computation&lt;/li&gt;
              &lt;li&gt;out of loop evolution&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;In this way we can talk about evolution algorithms, etc. and when we talk about this in the life of an individual
            &lt;ul&gt;
              &lt;li&gt;lifetime learning is the outer loop and local interaction through time is the inner loop&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;We can train it’s slow timescale meta parameters to generalize to new environments&lt;/li&gt;
      &lt;li&gt;What kind of hypothesis can we make?
        &lt;ul&gt;
          &lt;li&gt;becaue these actions are localized in space and time, because these things are locallly temporal then we can try to understand&lt;/li&gt;
          &lt;li&gt;Independent of cause and mechainsim – from an information perspective
            &lt;ul&gt;
              &lt;li&gt;learning from one mechanism tells you nothing of the others&lt;/li&gt;
              &lt;li&gt;if something like this changes due to an intervention then ew only need to adapt the portion of the model that has to deal with that part of the distribution&lt;/li&gt;
              &lt;li&gt;It can be explained by a tiny change&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Good representations of variables and mechanisms + localized change hypothesis
        &lt;ul&gt;
          &lt;li&gt;few bits needed to adapt to what has happened&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How to factorize a joint distribution in this way?
    &lt;ul&gt;
      &lt;li&gt;Learning whether A causes B
        &lt;ul&gt;
          &lt;li&gt;Learner doesn’t know but we might observe just X and Y&lt;/li&gt;
          &lt;li&gt;Turns out, if we have the right composition then we can use this to learn about how to map X to Y, such as things like pixels that don’t have causal structure in that image itself&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The assumption that these high level variables are causal doesn’t work on pixels
        &lt;ul&gt;
          &lt;li&gt;We cna’t find a pixel that causes another pixel&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Learning neural causal models
        &lt;ul&gt;
          &lt;li&gt;we can avoid the exponential number of grpahs that need to be considered through this&lt;/li&gt;
          &lt;li&gt;ONe of the things found was that in order ot facilitate the causal structure the learner should try to infer the intervention on which variable it was performed&lt;/li&gt;
          &lt;li&gt;most of the time our brain is trying to figure out “What caused the changes that I am seeing?”&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Able to find these commonly used causal induction methods
        &lt;ul&gt;
          &lt;li&gt;Attacking this problem in a deep learning friendly way
            &lt;ul&gt;
              &lt;li&gt;defined obejective with some regularization&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Operating on sets of objects
    &lt;ul&gt;
      &lt;li&gt;Using dynamically recombinations of objects&lt;/li&gt;
      &lt;li&gt;Recurrent Independent Mechanisms
        &lt;ul&gt;
          &lt;li&gt;operating on sets of these objects&lt;/li&gt;
          &lt;li&gt;applied to recurrentness
            &lt;ul&gt;
              &lt;li&gt;state is broken into pieces&lt;/li&gt;
              &lt;li&gt;constaining the way these networks are talking to eachother in that they done in sparse and dynamic ways&lt;/li&gt;
              &lt;li&gt;vectors aren’t the standard vectors but rather sets of pairs
                &lt;ul&gt;
                  &lt;li&gt;networks are exchanging variables along with their type (key, value) pairs
                    &lt;ul&gt;
                      &lt;li&gt;leads to better out of distribution generalization than those that don’t use these structures&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Tested in reinforcement learning
        &lt;ul&gt;
          &lt;li&gt;found it helped in atari games&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Recap
    &lt;ul&gt;
      &lt;li&gt;Conscious processing by agents, systematic generalization
        &lt;ul&gt;
          &lt;li&gt;Sparse factor graphs in space of high-level semantic variables&lt;/li&gt;
          &lt;li&gt;Semantic variables are causal : agents, intentios, controllable objects&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Shares “rules” or modules that are reusable across tuples
        &lt;ul&gt;
          &lt;li&gt;A particular subnetwork recieves input that is different dependent on context
            &lt;ul&gt;
              &lt;li&gt;This can be applied to different instances in that it’s much more like a bayes net but the same parameters can be used in many spaces&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;another really important hypothesis is that the changes in dsitribution are mostly localized if we’re presented information&lt;/li&gt;
      &lt;li&gt;Things preserved across changes in distribution have to be grounded in that they’re stable and robust to stationarity&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mapping-emotions-discovering-structure-in-mesoscale-electrical-brain-recordings&quot;&gt;Mapping Emotions: Discovering Structure in Mesoscale Electrical Brain Recordings&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Brain is an organize that integrated bio-information with electricity
    &lt;ul&gt;
      &lt;li&gt;working on integrating across discplines to get better models of brain functions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Causality???
    &lt;ul&gt;
      &lt;li&gt;If we understand how the brain does what it does, we can reverse engineer it and use that to understand it better&lt;/li&gt;
      &lt;li&gt;Can we turn on and off other areas of the brain&lt;/li&gt;
      &lt;li&gt;We come to this conclusion around causality because human beings have observed the earht other and over again in many contexts and test these assumptions using models and test these assumptions and map them back to our models
        &lt;ul&gt;
          &lt;li&gt;This is important for neuroscience
            &lt;ul&gt;
              &lt;li&gt;Many of the manipulations of the brain cause it to not function how it does naturally
                &lt;ul&gt;
                  &lt;li&gt;It might make more sense to observe the system over and over again&lt;/li&gt;
                  &lt;li&gt;We can test these models
                    &lt;ul&gt;
                      &lt;li&gt;If that’s the case, the human body is 98 degrees farenheit&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Depression (DSM)
        &lt;ul&gt;
          &lt;li&gt;depressed mood&lt;/li&gt;
          &lt;li&gt;diminished interest&lt;/li&gt;
          &lt;li&gt;increase or decrease in appetite&lt;/li&gt;
          &lt;li&gt;hypersomnia or insomnia&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Is MDD prevention a viable therapeutic strategy?
        &lt;ul&gt;
          &lt;li&gt;Imagine a disease case where someone has a heart attack of failure
            &lt;ul&gt;
              &lt;li&gt;make that heart pump more normally&lt;/li&gt;
              &lt;li&gt;Idea is to make a diseased heart and make it function more normally&lt;/li&gt;
              &lt;li&gt;One of the things that has the greatest impact on the system of the heart was aging
                &lt;ul&gt;
                  &lt;li&gt;measured variables in lifestyle that might help predict heart attack later on in life&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Emotions at latent networks
        &lt;ul&gt;
          &lt;li&gt;The idea is that we use fMRI to look at changes in bloodflow in the brain
            &lt;ul&gt;
              &lt;li&gt;Using these changes as a proxy for brain activation&lt;/li&gt;
              &lt;li&gt;Taking healthy controls, or students&lt;/li&gt;
              &lt;li&gt;Put them in a scanner and let them watch movies while inducing emotions
                &lt;ul&gt;
                  &lt;li&gt;Use ML to see what emotional patterns were induced&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;After about 20 mins they tap the students and ask how they were feeling&lt;/li&gt;
              &lt;li&gt;This suggests we’re able to liberate the emotion from the patients’ brain without self-reporting&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Assumptions
    &lt;ul&gt;
      &lt;li&gt;Assumption 1: Emotional encoding at the second timescale
        &lt;ul&gt;
          &lt;li&gt;This is important because people have classically thought about controlling variables and repeatedly observe a system&lt;/li&gt;
          &lt;li&gt;Useful for studying vision, motor function, sensory systems, etc.
            &lt;ul&gt;
              &lt;li&gt;This system might be built to do something &lt;em&gt;very&lt;/em&gt; different than emotional systems&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;When we have a system to process emotions, we want something that has information resonance at a slower timescale than moving arms, and legs, etc.&lt;/li&gt;
          &lt;li&gt;Emotions are encoded at the timescale of seconds&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Assmption 2 : Emergent Properties
        &lt;ul&gt;
          &lt;li&gt;We have a cell property and it traverses a neuron and checmical information is sent down the axxon
            &lt;ul&gt;
              &lt;li&gt;hard to think about emergent properties of these systems&lt;/li&gt;
              &lt;li&gt;a seizure is an emergent property of the brain
                &lt;ul&gt;
                  &lt;li&gt;wouldn’t generate this phenomenon without more than 4 cells&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;The system is working together in an integration fashion to create these properties&lt;/li&gt;
          &lt;li&gt;THINK SLEEP&lt;/li&gt;
          &lt;li&gt;LOcal field potentials can be used to measure certain properties of the system&lt;/li&gt;
          &lt;li&gt;LFP coherence (functional connectivity)&lt;/li&gt;
          &lt;li&gt;sycnhrony or coherence
            &lt;ul&gt;
              &lt;li&gt;we can infer directionality in a circuit&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Coupling between cell firing and LFP activity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Assumption 3 : Local Field Potentials reflects the activity of populations of neurons (emergent features)
        &lt;ul&gt;
          &lt;li&gt;Trying to find things that generalize across brains, species, and inviduals&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Latent Network Model
        &lt;ul&gt;
          &lt;li&gt;Each layer is useful for one of things we wanted to do
            &lt;ul&gt;
              &lt;li&gt;Each of us had to believe one layer of this model&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Information across frequency and information that is leading or lagging&lt;/li&gt;
          &lt;li&gt;6000 things that we could measure and quantify in an animals brains&lt;/li&gt;
          &lt;li&gt;Phase offset&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Acquiring brain network behavior&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;agency-and-automation&quot;&gt;Agency and Automation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hype and sensationalism drive some of the interest but there is a substory there around automation
    &lt;ul&gt;
      &lt;li&gt;Fei Fei Li - write in NYT that enthusiasm for AI is preventing us from reckoning our immersion into it…&lt;/li&gt;
      &lt;li&gt;Michael Jordan
        &lt;ul&gt;
          &lt;li&gt;Need well thought out interactions with humans and computers&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;These are not new&lt;/li&gt;
  &lt;li&gt;We have a 60 year old design challenge to find an optmiality between divisions of labor and automation
    &lt;ul&gt;
      &lt;li&gt;Automation and user control
        &lt;ul&gt;
          &lt;li&gt;Waht si the appropriate balance here?&lt;/li&gt;
          &lt;li&gt;Challenges of automation
            &lt;ul&gt;
              &lt;li&gt;Automated methods may be biased or innacurate&lt;/li&gt;
              &lt;li&gt;These concequences can be quite damanging in the real world&lt;/li&gt;
              &lt;li&gt;Loss of critical engagement and domain expertise&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;We lack a global view as humans and over-weight local information&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Balancing automation and control can be done through building models of capabilites, actions, and controls around the tasks that we perform&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;3 Examples
    &lt;ol&gt;
      &lt;li&gt;Exploratory Data Visualization
        &lt;ul&gt;
          &lt;li&gt;incorporate tasks that the user is trying to achieve into the design of the visualization of the data&lt;/li&gt;
          &lt;li&gt;See slides for multi-verse analysis of the topics that might be present in these documents&lt;/li&gt;
          &lt;li&gt;What makes a visualization good?
            &lt;ul&gt;
              &lt;li&gt;Task specific and subjective references&lt;/li&gt;
              &lt;li&gt;Foundational issues in perception that we can build upon&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Shows the long standing results in psychophysics in how our perceptual system can quickly decode visual types of information&lt;/li&gt;
          &lt;li&gt;Common exploration pitfalls
            &lt;ul&gt;
              &lt;li&gt;Overlooking data quality issues&lt;/li&gt;
              &lt;li&gt;Fixating on specific relationships&lt;/li&gt;
              &lt;li&gt;Many other biases…
 *Data Voyager&lt;/li&gt;
              &lt;li&gt;examples in slides&lt;/li&gt;
              &lt;li&gt;We want to suppoer systematic considerations of the data&lt;/li&gt;
              &lt;li&gt;Model user’s search frontier, optimize for related chart specification, seeded by the user’s current docus&lt;/li&gt;
              &lt;li&gt;Candidate charts pruned and ranked using a formal model of design constraints&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayesian-deep-learning-workshop&quot;&gt;Bayesian Deep Learning Workshop&lt;/h2&gt;

&lt;h3 id=&quot;gaussian-process-behavior-of-wide-and-deep-neural-networks&quot;&gt;Gaussian Process Behavior of Wide and Deep Neural Networks&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper has been around for almost 2 years now&lt;/li&gt;
  &lt;li&gt;Lots of forward work – along with an extended paper on arxiv today along with code&lt;/li&gt;
  &lt;li&gt;Data efficiency is a serious problem for deep RL&lt;/li&gt;
  &lt;li&gt;Prior and weights are typically very difficult to interpret
    &lt;ul&gt;
      &lt;li&gt;Why do we expect good performance?&lt;/li&gt;
      &lt;li&gt;Possible what we are doing inference with a terrible prior&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seminal results of the paper
    &lt;ul&gt;
      &lt;li&gt;1994 - showed that a single MLP with K hidden units, with a carefully scaled prior
        &lt;ul&gt;
          &lt;li&gt;scaling outgoing weights by 1/K – as you take the limit as k -&amp;gt; inf
            &lt;ul&gt;
              &lt;li&gt;the vector converged to distribution multivariate with mean 0 and unit variance&lt;/li&gt;
              &lt;li&gt;some form of gaussian quadrature&lt;/li&gt;
              &lt;li&gt;proves this with standard multivariate central limit theorem&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Central Limit Theorem
    &lt;ul&gt;
      &lt;li&gt;1 dimenstional CLT there are some interesting things&lt;/li&gt;
      &lt;li&gt;Random variables converges to CDF at all points where the CDF is continuous&lt;/li&gt;
      &lt;li&gt;CLT says that if we consider IID rv with mean 0 and unit variance&lt;/li&gt;
      &lt;li&gt;Some sublties
        &lt;ul&gt;
          &lt;li&gt;Consider an IID sequence of 2 possibilities [-1, 1] with P(0.5) has mean 0 variance 1&lt;/li&gt;
          &lt;li&gt;We can define a set A
            &lt;ul&gt;
              &lt;li&gt;Then for all n where A has probability zero under N(0,1)&lt;/li&gt;
              &lt;li&gt;This set has 0 probability under this distribution
                &lt;ul&gt;
                  &lt;li&gt;be careful with what convergence of distribution actually means&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What does this mean for a stochiastic process to converge in distribution
    &lt;ul&gt;
      &lt;li&gt;carefully scaling the prior&lt;/li&gt;
      &lt;li&gt;weights coming out of these layers will have 1/k_1 and 1/k_2 respectively&lt;/li&gt;
      &lt;li&gt;c_2 is a normal quadrature is defined in terms of the covariance of the previous layer making it a recursive kernel definition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Deep Neural Networks as Gaussian Process
    &lt;ul&gt;
      &lt;li&gt;Released same day and accepted as same confernece&lt;/li&gt;
      &lt;li&gt;Check this paper out as well &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Rigorous proof provided&lt;/li&gt;
  &lt;li&gt;Why would we expect a CLT here at all with multiple hidden layers
    &lt;ul&gt;
      &lt;li&gt;Radford Neil
        &lt;ul&gt;
          &lt;li&gt;Feeding a single data point through and we can look at the f_1 units - each will converge independent of other variables&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Multiple input data points
        &lt;ul&gt;
          &lt;li&gt;there is a correlated normal vector at each f^(1)
            &lt;ul&gt;
              &lt;li&gt;at some point, increasingly independent vectors converge to a correlated normal vector&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Problem with the argument&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Preliminaries
    &lt;ul&gt;
      &lt;li&gt;Need a convergent non-linearity
        &lt;ul&gt;
          &lt;li&gt;Draw a bounding envelope on any point around the non-linearity
            &lt;ul&gt;
              &lt;li&gt;we might get something that might not be defined if we don’t, it effectively stabilizes everything&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Think about the network as an infinite sequence of network
        &lt;ul&gt;
          &lt;li&gt;The hidden layers may grow at different rates as long as they all tend toward infinity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Formal statement of the theorem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Proof sketch
    &lt;ul&gt;
      &lt;li&gt;proceed through the network and by induction starting to closest data&lt;/li&gt;
      &lt;li&gt;at each layer, reduce the problem to the convergence of any finite linear project of data and units&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Exchangability
    &lt;ul&gt;
      &lt;li&gt;An infinite sequence is exchangable if any finite permutation leaves its distribution invariant&lt;/li&gt;
      &lt;li&gt;de Finetti’s theorem
        &lt;ul&gt;
          &lt;li&gt;an infinite sequence of random variables is exchangable iff ti’s IID conditional on some random variable&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Exchangable CLT &lt;a href=&quot;&quot;&gt;slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;applies to triangular arrays&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Experiments in the paper are relatively small data with low dimensionality &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;In the majority of cases considered, the agreement is very close&lt;/li&gt;
      &lt;li&gt;one can’t tell the difference between the GP and 3 layer NN&lt;/li&gt;
      &lt;li&gt;Slide shows, empirically, there seems to be little difference between a standard GP and a DNN with 3 hidden layers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Limitations of Kernel Methods &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;This property might not be a good thing&lt;/li&gt;
      &lt;li&gt;Kernel methods are affine transformations of the training outputs&lt;/li&gt;
      &lt;li&gt;This limits the rperesentation that we can learn&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Deep GP’s
    &lt;ul&gt;
      &lt;li&gt;Not marginal GP’s because they have finite restrictions in the norm&lt;/li&gt;
      &lt;li&gt;This prevents the onset of the CLT&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Subsequent work &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;CNN’s also converge to GP’s&lt;/li&gt;
      &lt;li&gt;Neural Tangent Kernel considers not what just happens for the initial distribution of the NN, but also what happens when we apply gradient descent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-natural-neural-tangent-kernel&quot;&gt;The Natural Neural Tangent Kernel&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;
&lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Background
    &lt;ul&gt;
      &lt;li&gt;Vectrorize the output of the NN’s into an n x k vector&lt;/li&gt;
      &lt;li&gt;we know that the application that we have done will handle 1D output&lt;/li&gt;
      &lt;li&gt;All theoretical results apply to multi-outputs&lt;/li&gt;
      &lt;li&gt;We know that NN outputs are a function of the parameters which in turn are a function of time (think evolution of gradient descent)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Natural GD
    &lt;ul&gt;
      &lt;li&gt;appealing because it has convergence, covariance, and invariance under reparameterization&lt;/li&gt;
      &lt;li&gt;Fisher Information Matrix allows GD to take the curvature of the distribution space into account
        &lt;ul&gt;
          &lt;li&gt;Small changes in parameters can effect the training dynamics&lt;/li&gt;
          &lt;li&gt;Inverse Fisher allows us to take into account this space’s information geometry&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Concatenated Fisher Information
    &lt;ul&gt;
      &lt;li&gt;we can condition the FIM on a single data point x&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Training dynamics under natural gradient descent
    &lt;ul&gt;
      &lt;li&gt;Natural Nerual Tangent Kernel includes the fisher information matrix which includes the distribition geometry into account&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Assumptions
    &lt;ol&gt;
      &lt;li&gt;Network overparameterization&lt;/li&gt;
      &lt;li&gt;Positive definiteness
        &lt;ul&gt;
          &lt;li&gt;Implications&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Computing the NTK yields an interesting result&lt;/li&gt;
  &lt;li&gt;Bound on prediction discrepancy &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Empirical results
    &lt;ul&gt;
      &lt;li&gt;Symthetic data &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Theoreitcal bound is meant to be tight&lt;/li&gt;
      &lt;li&gt;The values increase further away from data – see tails of the plot&lt;/li&gt;
      &lt;li&gt;Comparing the predictive distribution – see slides&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Future Direction
    &lt;ul&gt;
      &lt;li&gt;Approximate inference&lt;/li&gt;
      &lt;li&gt;scaling to larger datasets&lt;/li&gt;
      &lt;li&gt;Classification tasks&lt;/li&gt;
      &lt;li&gt;Generalization analysis&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;on-estimating-epistemic-uncertainty&quot;&gt;On Estimating Epistemic Uncertainty&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;There is huge interest in the intersection between Neural Networks and Bayesian Believers&lt;/li&gt;
  &lt;li&gt;epistemic estimation is REALLY important for areas with high risk
    &lt;ul&gt;
      &lt;li&gt;bayesian or not there is a really great potential to healthcare and autonomous driving&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Type of Uncertainty &lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Epistemic uncertainty “how much do I believe this coin is fair?”
        &lt;ul&gt;
          &lt;li&gt;models’ belief after seeing the population&lt;/li&gt;
          &lt;li&gt;reduces when we have more data&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Aleatoric Uncertainty - “What’s the nest coin flip outcome?”
        &lt;ul&gt;
          &lt;li&gt;Individual experiment outcome&lt;/li&gt;
          &lt;li&gt;non-reducible&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Distribution Shift - “Am I still flipping the same coin?”
        &lt;ul&gt;
          &lt;li&gt;Indicating a change of the underlying quantity of interesting&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Quick intro to BNN’s &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;instead of learning point updates, let’s put a distribution in place here over the parameters&lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;in practice $p(w&lt;/td&gt;
              &lt;td&gt;D)$ is intractable&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
        &lt;ul&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;Find an approximation $q(W) \approx P(W&lt;/td&gt;
                  &lt;td&gt;D)$&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Weight space uncertainty is less interesting
    &lt;ul&gt;
      &lt;li&gt;in many cases NN’s weights are NOT scientific parameters we’re interested in&lt;/li&gt;
      &lt;li&gt;symmetries/invariance in parameterization
        &lt;ul&gt;
          &lt;li&gt;exmaples like swapping nodes and scaling of weights, we’re still approximating the same function&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;This introduces vagueness &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;sample weights from the Q distribution&lt;/li&gt;
      &lt;li&gt;folklore belief for function-space (or output-space) uncertainty:&lt;/li&gt;
      &lt;li&gt;“Epistemic uncertainty should be high when new input is less similar to observed inputs”&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;What do “high uncertainty” and “less similar” mean qualitatively?&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;This is typically “eye-balled”, leaving it to be subjective by definition&lt;/li&gt;
          &lt;li&gt;There is really no agreeable diescription of where and by how much it should be higher&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluating by comparing to references &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;BNN’s performance relies on a approximate posterior&lt;/li&gt;
      &lt;li&gt;Evaluating inference:
        &lt;ul&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;computes some distance metric between q(W) and p(W&lt;/td&gt;
                  &lt;td&gt;D)&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Function space “reference posterior” for BNN regression:
        &lt;ul&gt;
          &lt;li&gt;some hope in function space&lt;/li&gt;
          &lt;li&gt;wide BNN has GP limit (under certain conditions)&lt;/li&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;for regression problems $p_{GP}(f&lt;/td&gt;
                  &lt;td&gt;D)$ is tractable&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-big-problem-with-meta-learning-and-how-bayesians-can-fix-it&quot;&gt;The big problem with meta-learning and how bayesians can fix it&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How do we accomplish learning from scratch or from &lt;em&gt;very&lt;/em&gt; small amount of data
    &lt;ul&gt;
      &lt;li&gt;Modeling image formation
        &lt;ul&gt;
          &lt;li&gt;geometry of the image&lt;/li&gt;
          &lt;li&gt;SIFT features, HOG features, etc.&lt;/li&gt;
          &lt;li&gt;Fine tuning from ImageNet features&lt;/li&gt;
          &lt;li&gt;Domain adaptation from other painters&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Fewer human priors as we move down the list above&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Can we explicitly &lt;strong&gt;learn priors from previous experience&lt;/strong&gt;?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Brief Overview
    &lt;ul&gt;
      &lt;li&gt;Given 1 example of 5 classes :
        &lt;ul&gt;
          &lt;li&gt;classify new examples&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How does meta-learning work?
    &lt;ul&gt;
      &lt;li&gt;One approach : parameterize learner by a neural network&lt;/li&gt;
      &lt;li&gt;Another approach : embed optimization into the learning process&lt;/li&gt;
      &lt;li&gt;The Bayesian perspective : learn priors of a Bayesian model that we can use for posterior inference&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The problem
    &lt;ul&gt;
      &lt;li&gt;How we construct tasks&lt;/li&gt;
      &lt;li&gt;What if label order is consistent?
        &lt;ul&gt;
          &lt;li&gt;A single functional can solve all the tasks&lt;/li&gt;
          &lt;li&gt;The network can simply learn to classify inputs, irrespective of the data distribution&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Meta-training to “close the box”
    &lt;ul&gt;
      &lt;li&gt;If you tell the robot the task goal, the robot can &lt;strong&gt;ignore&lt;/strong&gt; the trials&lt;/li&gt;
      &lt;li&gt;another example : pose estimation and object position
        &lt;ul&gt;
          &lt;li&gt;memorize the post and orientation of the meta-training set&lt;/li&gt;
          &lt;li&gt;at meta-test time, without knowing the canonical orientation, we don’t be able to accurate predict the orientation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What can we do about this?
    &lt;ul&gt;
      &lt;li&gt;If we had a proper bayesiaan meta-learning algorithm that was learning a proper posterior, we might not have this problem&lt;/li&gt;
      &lt;li&gt;However, I’m not sure if we have the tools to create a proper meta-learning algorithm&lt;/li&gt;
      &lt;li&gt;If the tasks are mutually excluse, a single function cannot solve all the tasks (due to label shufflinf, etc.)&lt;/li&gt;
      &lt;li&gt;If tasks are &lt;em&gt;non-mutually exclusive&lt;/em&gt;, a single function can solve all tasks
        &lt;ul&gt;
          &lt;li&gt;multiple solutions to the meta-learning problem&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Meta-regularization
    &lt;ul&gt;
      &lt;li&gt;Control the information flow such that we can do zero-shot learning from the data
        &lt;ul&gt;
          &lt;li&gt;minimize the meta-training loss and the information contained within the parameters of the model&lt;/li&gt;
          &lt;li&gt;regularizing the weights forces the model to use information from the data as opposed&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Can combine this with a favorite meta-learning algorithm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Does meta-regularization lead to better generalization?
    &lt;ul&gt;
      &lt;li&gt;arbitrary distribution over $\theta$ that doesn’t depend on the meta-training data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Meta-world benchmark&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;high-dimensional-bayesian-optimization-using-low-dimensional-feature-spaces&quot;&gt;High Dimensional Bayesian optimization using low-dimensional feature spaces&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Motivation
    &lt;ul&gt;
      &lt;li&gt;Experimental design problems that can be cast a a global optimization over some parameter space&lt;/li&gt;
      &lt;li&gt;optimizing on non-linear projections&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;function-space-priors-in-bayesian-deep-learning&quot;&gt;Function Space Priors in Bayesian Deep Learning&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Why do we care about function space priors?&lt;/li&gt;
  &lt;li&gt;Lots of testing methods for bayesian approaches
    &lt;ul&gt;
      &lt;li&gt;see slides&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;But these all have non-Bayesian approaches that are competitive&lt;/li&gt;
  &lt;li&gt;Three X’s
    &lt;ul&gt;
      &lt;li&gt;Exploration&lt;/li&gt;
      &lt;li&gt;Explanation&lt;/li&gt;
      &lt;li&gt;Extrapolation&lt;/li&gt;
      &lt;li&gt;These cases all depend crucially on having good priors that reflect thr structure of the underlying distribution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Compositional GP Kernels
    &lt;ul&gt;
      &lt;li&gt;GP’s are distributions over functions parameterized by kernels.&lt;/li&gt;
      &lt;li&gt;Primitive Kernels&lt;/li&gt;
      &lt;li&gt;Composite kernels
        &lt;ul&gt;
          &lt;li&gt;taking products of kernels
            &lt;ul&gt;
              &lt;li&gt;This can express things like periodic structure that gradually changes over time&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;No need to specify structure in advanced and can be inferred online during training&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Structured Priors and Deep Learning
    &lt;ul&gt;
      &lt;li&gt;Demonstrates the power and flexibility of function space priors&lt;/li&gt;
      &lt;li&gt;Problems
        &lt;ul&gt;
          &lt;li&gt;Requires a discrete search over the space of kernels for each candidate structure&lt;/li&gt;
          &lt;li&gt;Need to re-fit the kernel hyperparameters&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Differentiable Compositional Kernel Learning for Gaussian Processes
    &lt;ul&gt;
      &lt;li&gt;Neural Kernel Network
        &lt;ul&gt;
          &lt;li&gt;represents a kernel&lt;/li&gt;
          &lt;li&gt;inputs are 2 input locations&lt;/li&gt;
          &lt;li&gt;output is the value between them&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;try-depth-instead-of-weight-correlations&quot;&gt;Try depth instead of weight correlations&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Challenge the assumption
    &lt;ul&gt;
      &lt;li&gt;ASsumptions that the approximate posterior that we use to model our BNN, ought to have correlations between the weights&lt;/li&gt;
      &lt;li&gt;Mean-field assumption that our weight distributions are independent of eachother because we’re avoiding intractability&lt;/li&gt;
      &lt;li&gt;This is less true as our neural network gets much deeper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Why might our approximate posterior need to have correlation between weights?
    &lt;ul&gt;
      &lt;li&gt;Maybe the true posterior does?&lt;/li&gt;
      &lt;li&gt;A lot of intuitions we have come from this small interpretable single layer 4 neuron model
        &lt;ul&gt;
          &lt;li&gt;What we think is that alot of these effects disappear as we get deeper and deeper networks&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;With depth, we can induce rich correlation over our output distribution with mean-field weights
    &lt;ul&gt;
      &lt;li&gt;one way to do this is to have covariance between $\theta_{1}$ and $\theta_{2}$&lt;/li&gt;
      &lt;li&gt;As we get a deep network, we can get richer covariance structures&lt;/li&gt;
      &lt;li&gt;2 inputs and 2 outputs with a simple weight layer w
        &lt;ul&gt;
          &lt;li&gt;assuming linearity&lt;/li&gt;
          &lt;li&gt;mean-field approximation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Lesson from the linear case
        &lt;ul&gt;
          &lt;li&gt;3+ mean-field layers can approximate one full-covariance layer&lt;/li&gt;
          &lt;li&gt;More layers allow a richer approximation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Measuring the price of this mean-field approximation in NN’s that &lt;em&gt;do&lt;/em&gt; have non-linearities
        &lt;ul&gt;
          &lt;li&gt;HMC true posterior&lt;/li&gt;
          &lt;li&gt;fit a full-covariance gaussian&lt;/li&gt;
          &lt;li&gt;fit a diagonal covariance gaussian&lt;/li&gt;
          &lt;li&gt;measure the difference between them, and it should give us an understanding of how costly the extra assumption of diagonality is&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Measuring the ‘price’ of the mean-field approximation &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;hold parameters model throughout this testing&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What are the implications here?
    &lt;ul&gt;
      &lt;li&gt;Rely less on UCI evaluation with a single hidden layer&lt;/li&gt;
      &lt;li&gt;More research into &lt;strong&gt;other&lt;/strong&gt; problems with Mean-Field Variational Inference
        &lt;ul&gt;
          &lt;li&gt;E.g. sampling properties of high-dimensional gaussian (“Radial BNN’s”)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Less research into &lt;strong&gt;structured covariance variational inference&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bayesian-nueral-network-priors&quot;&gt;Bayesian Nueral Network Priors&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In bayesian statistics, priors are meant to represent our knowledge about the domain&lt;/li&gt;
  &lt;li&gt;Mapping domain knowledge to neural networks is hard&lt;/li&gt;
  &lt;li&gt;Controlled Directed Effect
    &lt;ul&gt;
      &lt;li&gt;Measure sensitivity of an outcome vaiarble to changes in a set of variables while all other factors are held fixed&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Types of CDE Priors : Monotonicity and Invariance
    &lt;ul&gt;
      &lt;li&gt;Need to translate domainknowledge into expectations about CDEs for transition x -&amp;gt; x’&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Guiding Functions
    &lt;ul&gt;
      &lt;li&gt;One way to think about input transoformations at every point x \in R, pick a direction \Deltax \in R^{D}
 to push x&lt;/li&gt;
      &lt;li&gt;think of this guiding functions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Translating the CE into a prior
    &lt;ul&gt;
      &lt;li&gt;CDE is expensive to compute, but can apprixmate it using gradients, and ignore scale&lt;/li&gt;
      &lt;li&gt;Define an error function for local invariance and monotonicity&lt;/li&gt;
      &lt;li&gt;Ipose a gaussian prior over this Error function above for a BNN
        &lt;ul&gt;
          &lt;li&gt;can be used for mini-batch variational inference&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Contribution is proposing a framework for applying these priors above
    &lt;ul&gt;
      &lt;li&gt;toy examples
        &lt;ul&gt;
          &lt;li&gt;in 1D - sampling from a NN - assuming independent gaussian priors for each weight – the functions depend a lot on&lt;/li&gt;
          &lt;li&gt;important to understand this is a local constraint&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;We can impose a prior that it increases with&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Consider invariance case instead of monotonic
    &lt;ul&gt;
      &lt;li&gt;2D manifold where the values of f and g are equal
        &lt;ul&gt;
          &lt;li&gt;not clear if we should be following f or g
            &lt;ul&gt;
              &lt;li&gt;predictions are independent of changes in g
                &lt;ul&gt;
                  &lt;li&gt;significantly reduces error&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Invariance priors on COMPAS
    &lt;ul&gt;
      &lt;li&gt;First trained model g(x) to predict defendant’s race, then trained a second model f(x) to predic recidivism w/ local invariance to g(x)
        &lt;ul&gt;
          &lt;li&gt;without loss of accuracy, we can close the gap between false negative and false positive rates&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Thresholding schemes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;This si a building block for translating domain knowledge into a prior&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deep-generative-models-for-biological-sequences&quot;&gt;Deep Generative Models for Biological Sequences&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predicting the effect of human genetic variation from sequences alone&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Problems we saw in a number of areas dealing with the language of biological data&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;genotype to phenotype
    &lt;ul&gt;
      &lt;li&gt;if we want to change the phenotype, we want to understand the interaction of the environment&lt;/li&gt;
      &lt;li&gt;we also want to design biological sequences&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;10 billion people
    &lt;ul&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;1000 billion genomes&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;Important to understand models and analysis we have are based in the 80’s and 90’s&lt;/li&gt;
      &lt;li&gt;Potential sequences that are functional
        &lt;ul&gt;
          &lt;li&gt;potential sequences that are functional are much much larger than that&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;we might want to predict this in expectation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Why do we need better prediction and design in biology
    &lt;ul&gt;
      &lt;li&gt;uncertainty for medical decision making&lt;/li&gt;
      &lt;li&gt;molecular biology that impacts human health&lt;/li&gt;
      &lt;li&gt;predicting how pathogens will mutate&lt;/li&gt;
      &lt;li&gt;synthetic biology for designing theripeutic impact&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What does this sequence look like under constraint?
    &lt;ul&gt;
      &lt;li&gt;don’t even have benchmark datasets ready for people to play with these environments&lt;/li&gt;
      &lt;li&gt;main thing to get across that the estimation of uncertainty really matters&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Can’t we just measure the effects of all genetic variation
    &lt;ul&gt;
      &lt;li&gt;mutation effect prediction is hard
        &lt;ul&gt;
          &lt;li&gt;mutation effect prediction lacks
            &lt;ul&gt;
              &lt;li&gt;sparsity sampling&lt;/li&gt;
              &lt;li&gt;noisy&lt;/li&gt;
              &lt;li&gt;changing 1 position in the DNA, it’s not just thinking about that position but all of it’s impacts and confounders&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;propr art:
            &lt;ul&gt;
              &lt;li&gt;compute what’s conserved across evolution
                &lt;ul&gt;
                  &lt;li&gt;sequence alignment and preservation&lt;/li&gt;
                  &lt;li&gt;the way way we regard these sequences are the result of billions of experiments run on the human species&lt;/li&gt;
                  &lt;li&gt;not accurate to look at one column because of dependency on positions&lt;/li&gt;
                  &lt;li&gt;capturing the dependence between sequences
                    &lt;ul&gt;
                      &lt;li&gt;using pariwise factors are powerful
                        &lt;ul&gt;
                          &lt;li&gt;psuedo likelihood because we can’t calculate the partition function&lt;/li&gt;
                        &lt;/ul&gt;
                      &lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;capture these complex dependencies
                &lt;ul&gt;
                  &lt;li&gt;we can’t keep adding terms to likelihood models&lt;/li&gt;
                  &lt;li&gt;mutation prediction with a variational autoencoder
                    &lt;ul&gt;
                      &lt;li&gt;infer a generative model of the family&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;estimate how probably sequences are&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;A &lt;strong&gt;doubly variational autoencoder&lt;/strong&gt; on decoder weights prevents overfitting&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;biological constraints included in the model
            &lt;ul&gt;
              &lt;li&gt;latent variables are generated for each sequence in alignment&lt;/li&gt;
              &lt;li&gt;showing that the latent space seems to be capturing some structure &lt;a href=&quot;&quot;&gt;slide&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;we want to predict genetic variation
            &lt;ul&gt;
              &lt;li&gt;how are we going to know if we’re right?&lt;/li&gt;
              &lt;li&gt;DeepSequence captures mutation effects better than state of the art&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;But P(X) has been dependent on alignments…
        &lt;ul&gt;
          &lt;li&gt;“alignments” used by every branch of biology, genetics, clinical decisions – these are all methods from ~ 20 years ago&lt;/li&gt;
          &lt;li&gt;all heuristics&lt;/li&gt;
          &lt;li&gt;challenge is to build models that don’t depend on these alignments
            &lt;ul&gt;
              &lt;li&gt;alignment uncertainty&lt;/li&gt;
              &lt;li&gt;insertions and deletions&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Reinterpret our methods in terms of structured noise distributions&lt;/li&gt;
          &lt;li&gt;New Seq2Seq regression model : intuition
            &lt;ul&gt;
              &lt;li&gt;conditioned on the initial sequence X, predict sequence Y
                &lt;ul&gt;
                  &lt;li&gt;can change letters in X and have the capacity to delete them&lt;/li&gt;
                  &lt;li&gt;developed and explored simple seq2seq model
                    &lt;ul&gt;
                      &lt;li&gt;used categorical distribution over nucleotides, etc.&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;sample W from the prior over variables-size&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This generalizes past algorithms and models
        &lt;ul&gt;
          &lt;li&gt;Hierachical latent alignment HMM
            &lt;ul&gt;
              &lt;li&gt;Sample latent x from a population&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;properties that make it really easy to use in BNN methods&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This is an unsolved problem for HMM’s which have been used in biological sequencing
        &lt;ul&gt;
          &lt;li&gt;marginal is a smooth function of x and \theta which allows for automatic differentiation&lt;/li&gt;
          &lt;li&gt;inference method is SGD&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Inference methods
        &lt;ul&gt;
          &lt;li&gt;alignment HMM on the encoder side&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Results &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Summary &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;have done this on several families of protiens&lt;/li&gt;
      &lt;li&gt;ALignment uncertainty Example&lt;/li&gt;
      &lt;li&gt;Latent representation from PCA models reflect the underlying biolog of VDJ recombination&lt;/li&gt;
      &lt;li&gt;Flu Virus evolution &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;We can see the evolution across the latent space&lt;/li&gt;
          &lt;li&gt;we might be able to predict sequences&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intuitive-physics-for-robotic-manipulation-of-liquids&quot;&gt;Intuitive Physics for Robotic Manipulation of Liquids&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;
&lt;a href=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Interaction with liquids happens every day
    &lt;ul&gt;
      &lt;li&gt;Specific containers and specialised tools to manipulate these liquids&lt;/li&gt;
      &lt;li&gt;We can approximate the way these things will behave&lt;/li&gt;
      &lt;li&gt;The shape of the continaer has causal influence over the way that liquids interact with it&lt;/li&gt;
      &lt;li&gt;Viscosity of the liquid has intersting causal properties&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Thinking about this from a robotics perspective
    &lt;ul&gt;
      &lt;li&gt;Some of the things very natural to us are hard for robots
        &lt;ul&gt;
          &lt;li&gt;the complex properties of liquids makes this hard for robots&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What is it that we, as humans, do to help this manipulation
    &lt;ul&gt;
      &lt;li&gt;CogSci theories
        &lt;ol&gt;
          &lt;li&gt;We have some approx simulation in our heads that enable these predictions&lt;/li&gt;
          &lt;li&gt;People have shown that we can invert this simulator in our head and make predictions about properties in our heads&lt;/li&gt;
          &lt;li&gt;Different types of interactions can give us different cues about viscosity&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;We need some sort fo fast approxiate like thsi for embedding in robots&lt;/li&gt;
      &lt;li&gt;We don’t need exteme accuracy but rather representing these objects in a more approximate and efficient way&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Intuition as approcimate simluation
    &lt;ul&gt;
      &lt;li&gt;NVIDIA Flex
        &lt;ul&gt;
          &lt;li&gt;Position based dynamics&lt;/li&gt;
          &lt;li&gt;As with any simulation we use, we have a reality gap
            &lt;ul&gt;
              &lt;li&gt;This is discrepancy between observation in the real world and simulation environments&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Sources of error
            &lt;ul&gt;
              &lt;li&gt;model approximation – not much we can do here&lt;/li&gt;
              &lt;li&gt;parameterization – we have to set the parameters of the model and without correct settings we’ll get variance in our predictions&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Sim2real discrepancy is what we’re trying to track in this&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Two stage process
    &lt;ol&gt;
      &lt;li&gt;Estimate parameters &amp;amp; learn to pour
        &lt;ul&gt;
          &lt;li&gt;we want generative models to enable adaptatoin to dynamics of the environment&lt;/li&gt;
          &lt;li&gt;even though it’s the same experiment, we want to minimize spillage, but at the same time we want it to spill a bit because it’s informative&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Learning how to pour
    &lt;ul&gt;
      &lt;li&gt;How to use the sim here
        &lt;ul&gt;
          &lt;li&gt;action and observation spaces are as follows&lt;/li&gt;
          &lt;li&gt;count the number of particles that fall outside of the container&lt;/li&gt;
          &lt;li&gt;measure the spillage with a scale, and noramlize such that we have a % spillage to compare between the two domains&lt;/li&gt;
          &lt;li&gt;Find the relative distance between source and target container while measuring how fast it’s being filled&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The way we do this is to model this as a Gaussian Process
        &lt;ul&gt;
          &lt;li&gt;pour N times (37 in paper though 15 should be enough)&lt;/li&gt;
          &lt;li&gt;learning combinations of velocity and relative spillage&lt;/li&gt;
          &lt;li&gt;after learning this we transfer it right to the robot&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Approximate fluid simulation is useful
        &lt;ul&gt;
          &lt;li&gt;geometry of the container causes high spillage!&lt;/li&gt;
          &lt;li&gt;initialization of policy with simulation works best&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;To stir or not to stir
    &lt;ul&gt;
      &lt;li&gt;calibration to properties of the liquid through perception&lt;/li&gt;
      &lt;li&gt;The way we calibrate is to perform, in a synchronous way&lt;/li&gt;
      &lt;li&gt;Cohesion models the best the change in viscosity in the real world
        &lt;ul&gt;
          &lt;li&gt;the condition is the thing that is being modeled&lt;/li&gt;
          &lt;li&gt;simulator cannot model adhesion
            &lt;ul&gt;
              &lt;li&gt;these characteristics cannot be simulated&lt;/li&gt;
              &lt;li&gt;is there a way we can model this friction coefficient that might be present in specific liquids?&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;perception-and-action-from-generative-models-of-physics&quot;&gt;Perception and action from generative models of physics&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Goal of this research is to study generative models of physics from a cognitive science perpsective
    &lt;ul&gt;
      &lt;li&gt;Hemholtzian idea of perception as inverse optics&lt;/li&gt;
      &lt;li&gt;Some uderlying true state of the world
        &lt;ul&gt;
          &lt;li&gt;but we don’t have access ot that&lt;/li&gt;
          &lt;li&gt;we only have access to retinal images&lt;/li&gt;
          &lt;li&gt;there is some lawful set there
            &lt;ul&gt;
              &lt;li&gt;can we invert this image, knowing what we know from optics, to derive information about the world&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The world changes over time and gives rise to a sequence of images that we see
        &lt;ul&gt;
          &lt;li&gt;these changes happen in lawful ways such as dynamics
            &lt;ul&gt;
              &lt;li&gt;We don’t want to treat these observations as IID&lt;/li&gt;
              &lt;li&gt;We can use this to constrain our inferences&lt;/li&gt;
              &lt;li&gt;Perception is constrained by dynamics&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;People’s judgements about the slant of a ramp given the visual state of the ramp
            &lt;ul&gt;
              &lt;li&gt;as our perception of the ramp changes, if affects how we perceive the world&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What are these dynamics in the world and how do we capture that?
    &lt;ul&gt;
      &lt;li&gt;Intuitive Physics ENgine
        &lt;ul&gt;
          &lt;li&gt;The generative models we have in our heads are based on object baed representation
            &lt;ul&gt;
              &lt;li&gt;Some probability distribution presents a range of world state&lt;/li&gt;
              &lt;li&gt;This gives us a range of possible ways the world might unfold
                &lt;ul&gt;
                  &lt;li&gt;We run out model forward and count up the number of blocks&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Important features
            &lt;ul&gt;
              &lt;li&gt;object based
                &lt;ul&gt;
                  &lt;li&gt;shows object based importance in early human development&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;probabilistic model
                &lt;ul&gt;
                  &lt;li&gt;Not just one possible future, but  range that we can make predictions over&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;We don’t need a veridical model of physics but one good enough to action plan&lt;/li&gt;
              &lt;li&gt;This physics engine should favor speed and efficiency over precision&lt;/li&gt;
              &lt;li&gt;MOdel is generalizable in that we don’t need to learn separate physics models for all situations&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;How do we do this?
            &lt;ul&gt;
              &lt;li&gt;Predict - have a generative model of the world, ask what happens next, run out the model and observe&lt;/li&gt;
              &lt;li&gt;Probabilistic framework unlocks a lot of additional capabilities for perception&lt;/li&gt;
              &lt;li&gt;Perceive causality – remove A from simulation&lt;/li&gt;
              &lt;li&gt;Make plans and choose actions based on these model run outs&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Physics in the loop of perception
    &lt;ul&gt;
      &lt;li&gt;Perceiving what is in the world
        &lt;ul&gt;
          &lt;li&gt;seeing occluded objects &lt;a href=&quot;&quot;&gt;Papers&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;seeing surprising events &lt;a href=&quot;&quot;&gt;Papers&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Understanding actions in the world&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seeing Occluded objects with generative models in the loop
    &lt;ul&gt;
      &lt;li&gt;If we have a set of objects that have cloth draped over them, we can infer what object might be under that cover&lt;/li&gt;
      &lt;li&gt;We need some sort of generative model that allows us to internally ask “what would this look like with a cloth over it?”&lt;/li&gt;
      &lt;li&gt;See slides for how to model this occlusion phenomenon
        &lt;ul&gt;
          &lt;li&gt;use dynamics and physics of cloth to find a draped cloth geometry&lt;/li&gt;
          &lt;li&gt;Inference with Bayesian Optimization is key here&lt;/li&gt;
          &lt;li&gt;Understanding &lt;em&gt;How&lt;/em&gt; that cloth might drape is important for understanding what something occluded with cloth might look like&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seeing Surpriving Events like an infant
    &lt;ul&gt;
      &lt;li&gt;Detecting violations of expected dynamics&lt;/li&gt;
      &lt;li&gt;Permenance
        &lt;ul&gt;
          &lt;li&gt;objects can’t teleport&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Solidity&lt;/li&gt;
      &lt;li&gt;COntinuity
        &lt;ul&gt;
          &lt;li&gt;when objects violate these properties of how objects work, then they can update their model of the world&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What do we need to build into an agent such that it can percieve the world but then update their understanding of the world according to some surprise factor
    &lt;ul&gt;
      &lt;li&gt;Perceive violations of these principle drives learning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ADEPT Model &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Given an image - we first extract object information
        &lt;ul&gt;
          &lt;li&gt;approximate de-renderer&lt;/li&gt;
          &lt;li&gt;this object has attributes has understanding of position, velocity, etc.
            &lt;ul&gt;
              &lt;li&gt;shape information is thrown away&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;propose object masks
        &lt;ul&gt;
          &lt;li&gt;feed through renderer gets object properties&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Internal scene representation -&amp;gt; physics observations
        &lt;ul&gt;
          &lt;li&gt;objects are moving at certain velocity and objects interact, they don’t move through eachother&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;We want to match the above observations against a “ground truth”
        &lt;ul&gt;
          &lt;li&gt;this isn’t matching in pixel space, but rather matching wrt objects&lt;/li&gt;
          &lt;li&gt;we also have to gracefully deal with unexpected events
            &lt;ul&gt;
              &lt;li&gt;disappears and we want to handle it by saying this is something weird that happened, but this is my new normal and I no longer need to track it&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Measuring Surprise
        &lt;ul&gt;
          &lt;li&gt;violation of expectations (from psychology)&lt;/li&gt;
          &lt;li&gt;creation of a bunch of physics based violation types
            &lt;ul&gt;
              &lt;li&gt;these match to infant understanding principles&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Infants don’t see non-physical events
    &lt;ul&gt;
      &lt;li&gt;this allows us to constrain our space of potential evaluation&lt;/li&gt;
      &lt;li&gt;objects in shapenet&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Alternate Theory
    &lt;ul&gt;
      &lt;li&gt;Bootstrap these princples above&lt;/li&gt;
      &lt;li&gt;Can we learn this from enough data?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Rapid trial and error (repuposing of objects)
    &lt;ul&gt;
      &lt;li&gt;example of a stake and a tent
        &lt;ul&gt;
          &lt;li&gt;rule out branch, pinecone&lt;/li&gt;
          &lt;li&gt;pick rock&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;finding representations of the properties of these objects is inherent to planning in these situations&lt;/li&gt;
      &lt;li&gt;this seems to be a core feature for people&lt;/li&gt;
      &lt;li&gt;PHYRE benchmark
        &lt;ul&gt;
          &lt;li&gt;Focused on model-free RL from balanced datasets&lt;/li&gt;
          &lt;li&gt;learn generative model of the dynamics of the envornment&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Visual foresight for learning to push objects with tools
        &lt;ul&gt;
          &lt;li&gt;from vision required many samples + demonstrations&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SSUP Framework
    &lt;ul&gt;
      &lt;li&gt;sample, simulate, update
        &lt;ol&gt;
          &lt;li&gt;Prior&lt;/li&gt;
          &lt;li&gt;Internal simulator&lt;/li&gt;
          &lt;li&gt;Learning mechanism&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Conclusions
    &lt;ul&gt;
      &lt;li&gt;Causal models of dynamics are important for perception and action&lt;/li&gt;
      &lt;li&gt;Types of representations &amp;amp; dynamics are crucial
        &lt;ul&gt;
          &lt;li&gt;object-based, approximate world models&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Just generative models is not enough – requires additional information&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;###&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Neural Netwoks and CONVNETS are super dense
    &lt;ul&gt;
      &lt;li&gt;we’re grabbing much of background context, etc that don’t necessarily matter&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hierarchical compositionality
    &lt;ul&gt;
      &lt;li&gt;Way fewer parameters
        &lt;ul&gt;
          &lt;li&gt;the whole model was quite interpretable ane debuggable&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;each unit was a node in a graph – allowing representations of images in graphs&lt;/li&gt;
      &lt;li&gt;inference was done in a very hacky way&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AI Today
    &lt;ul&gt;
      &lt;li&gt;AI for simulation&lt;/li&gt;
      &lt;li&gt;Simulation needs a lot more learning involved&lt;/li&gt;
      &lt;li&gt;Open Problems
        &lt;ul&gt;
          &lt;li&gt;3D Envornments / Scenes&lt;/li&gt;
          &lt;li&gt;3D Objects&lt;/li&gt;
          &lt;li&gt;Activities&lt;/li&gt;
          &lt;li&gt;Behavior&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Scalability, realism, diversity : Learn how to simulate!&lt;/li&gt;
      &lt;li&gt;Scene composition
        &lt;ul&gt;
          &lt;li&gt;making this a little more scalable&lt;/li&gt;
          &lt;li&gt;In gaming, worlds are build using sort of probabilistic&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Meta-SIM&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;learning-spacial-invariant-object-properties&quot;&gt;Learning spacial invariant object properties&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Cross-bite challenge
    &lt;ul&gt;
      &lt;li&gt;Building Machine That Learn and Think Like People&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Unsupervised Object Tracking
    &lt;ul&gt;
      &lt;li&gt;Training (no annotations!)
        &lt;ul&gt;
          &lt;li&gt;find donstruction of videos in terms of moving objects&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Testing
        &lt;ul&gt;
          &lt;li&gt;new set of images from the same distribution and eval performance same as supervised learning&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Sequential Attend, Infer, Repeat (SQAIR) &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;Unsupervised object tracking
            &lt;ul&gt;
              &lt;li&gt;Variational autoencoder&lt;/li&gt;
              &lt;li&gt;trained by maximizing the ELBO
                &lt;ul&gt;
                  &lt;li&gt;hopes to learn the dynamics of the objects&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Spatially Invariant, Label-Free Object Tracking (SILOT)
        &lt;ul&gt;
          &lt;li&gt;new architecture&lt;/li&gt;
          &lt;li&gt;includes features to help it scale up&lt;/li&gt;
          &lt;li&gt;allows objects to condition and coordinate on eachother
            &lt;ul&gt;
              &lt;li&gt;we can sidestep the require sequential structure&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;artificial-and-biological-reinforcement-learning&quot;&gt;Artificial and Biological Reinforcement Learning&lt;/h2&gt;

&lt;h3 id=&quot;jeff-clune&quot;&gt;Jeff Clune&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Let’s let machine learning figure out the catastrphic forgetting problem
    &lt;ul&gt;
      &lt;li&gt;Framing the problem up as a meta-learning problem&lt;/li&gt;
      &lt;li&gt;This is called “meta-training”&lt;/li&gt;
      &lt;li&gt;Once this training is done, we take the meta-vector and evaluate on all T tasks that have been learned&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Online aware meta-learning &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;doesn’t suffer from catastrphic forgetting&lt;/li&gt;
      &lt;li&gt;learns to induce a sparsity in it’s representation
        &lt;ul&gt;
          &lt;li&gt;activates fewer neurons – ie. most of them&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Gets a lot right, but it’s still ultimately subjective to SGD
        &lt;ul&gt;
          &lt;li&gt;hard problem of finding representation once SGD gets applied to it&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;We allow control over SGD “neuromodulation”
        &lt;ul&gt;
          &lt;li&gt;directly modulated activations&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ANML (Neuralmodulated Meta-Learning Algorithm)
    &lt;ul&gt;
      &lt;li&gt;neuromodulatory network can gate the DNN that will also gate the backward pass
        &lt;ul&gt;
          &lt;li&gt;selective activation&lt;/li&gt;
          &lt;li&gt;selective plasticity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Omniglot, following OML
    &lt;ul&gt;
      &lt;li&gt;each character type is a class/task&lt;/li&gt;
      &lt;li&gt;differentiate through 600 tasks
        &lt;ul&gt;
          &lt;li&gt;evaluate on all 600 tasks – this is &lt;em&gt;WAY&lt;/em&gt; too unstable for today’s SGD methods (like 9000 steps)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Learn sequentially on one class in the inner loop&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Continual Learning is Hard
    &lt;ul&gt;
      &lt;li&gt;Normal deep learning
        &lt;ul&gt;
          &lt;li&gt;IID sampling (no catastrophic forgetting)&lt;/li&gt;
          &lt;li&gt;multiple passes through data&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Sequential Learning
*ANML might be leading to an overall solution to catastrophic forgetting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;human-learning-and-decision-making&quot;&gt;Human Learning and Decision Making&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Repeated Decisions with Imperfectly Known Consequences
    &lt;ul&gt;
      &lt;li&gt;Brain science – they frame this as a multi-bandit problem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Experimental Setup
    &lt;ul&gt;
      &lt;li&gt;four arm bandit tasks&lt;/li&gt;
      &lt;li&gt;4 conditions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;context-and-compositionality--in-biological-and-artifical-systems&quot;&gt;Context and Compositionality  in Biological and Artifical Systems&lt;/h2&gt;

&lt;h3 id=&quot;deep-understanding--the-next-challenge-for-ai&quot;&gt;Deep Understanding : The next challenge for AI&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Deep Understanding vs Shallow Understanding
    &lt;ul&gt;
      &lt;li&gt;Responding (frequently) in behaviorally appropriate ways without really getting the overal picture
        &lt;ul&gt;
          &lt;li&gt;look up Eliza
            &lt;ul&gt;
              &lt;li&gt;reveals the gulliability gap&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Keyword matches are used all the way through to 2014
        &lt;ul&gt;
          &lt;li&gt;Goostman (won some version of the Turing test)&lt;/li&gt;
          &lt;li&gt;Doesn’t represent real progress&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;GPT-2 seems fluid
        &lt;ul&gt;
          &lt;li&gt;long way from early generations&lt;/li&gt;
          &lt;li&gt;not actually coherent&lt;/li&gt;
          &lt;li&gt;Often plausible for a few sentences of text of surrealist fiction, where there are no facts of the matter&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Prediction at the world level != prediction at the world level&lt;/li&gt;
      &lt;li&gt;“Local coherency; global gibberish” - Dan Brickley&lt;/li&gt;
      &lt;li&gt;Adversarial NLI : A new benchmark for Natural Language Understanding
        &lt;ul&gt;
          &lt;li&gt;State of the art models learn to exploit spurious correlations in the data – we see this in the visual perception field as well&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What is deep understanding?
    &lt;ul&gt;
      &lt;li&gt;Deep Understanding is being able to
        &lt;ul&gt;
          &lt;li&gt;construct an internal model of what is said/depicted in a story/article/movie/etc&lt;/li&gt;
          &lt;li&gt;perform every day inferences about what is left unsaid&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;“What do I think of Western civilization? I think it would be a very good idea.”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Arguably the closes to deep understanding of the oft-misaligned CYC
    &lt;ul&gt;
      &lt;li&gt;Can make nuanced inferences about character motivations&lt;/li&gt;
      &lt;li&gt;But : system doesn’t have a natural langauge front end (you cna’t just feed Romeo &amp;amp; Juliet in)&lt;/li&gt;
      &lt;li&gt;Relies on human experts to encode each problem&lt;/li&gt;
      &lt;li&gt;there are also serious issues of coverage, sealing with uncertainty, etc.&lt;/li&gt;
      &lt;li&gt;MOve this out of it’s domain, it would fail completely
        &lt;ul&gt;
          &lt;li&gt;in some interesting ways it’s the closest thing we have&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Shallow prediction vs deep parser
    &lt;ul&gt;
      &lt;li&gt;there are lots of tools out there that are useful
        &lt;ul&gt;
          &lt;li&gt;lots of coverage issues&lt;/li&gt;
          &lt;li&gt;parse sentence into units and do symbolic computation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How might we get to deeper understanding : Two ways of thinking about that moving forward&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Benchmarks don’t encourage out-of-the-box thinking&lt;/li&gt;
  &lt;li&gt;Benchmarks can and are often easily gamed&lt;/li&gt;
  &lt;li&gt;The Kaggle Effect
    &lt;ul&gt;
      &lt;li&gt;optimizing for a single metric leads to tradeoffs and shortcuts which make you over specialized&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Benchmarks take a lot of time to develop&lt;/li&gt;
  &lt;li&gt;Benchmarks are prepackaged; humans experience rarely is
    &lt;ul&gt;
      &lt;li&gt;kids don’t get to download datasets and test&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We shouldn’t, in princple, expect any single benchmark to suffice
    &lt;ul&gt;
      &lt;li&gt;no one thing should be measured because the mind is not one thing&lt;/li&gt;
      &lt;li&gt;intelligence is clearly multidimensional&lt;/li&gt;
      &lt;li&gt;involves &lt;em&gt;manY&lt;/em&gt; vectors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Advice to young scholars
    &lt;ul&gt;
      &lt;li&gt;don’t just look to what the ML community is publishing&lt;/li&gt;
      &lt;li&gt;lots of extent data in other fields involving the brain that might be useful&lt;/li&gt;
      &lt;li&gt;plenty of work suggesting other challenges as well&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Children’s over-regularization errors
    &lt;ul&gt;
      &lt;li&gt;1992&lt;/li&gt;
      &lt;li&gt;widely modeled throughout the 90s&lt;/li&gt;
      &lt;li&gt;lots of people modeled this data, didn’t need to be on kaggle, but people tried to figure it out&lt;/li&gt;
      &lt;li&gt;not packaged nearly and nicely – we need to go find this data for our use&lt;/li&gt;
      &lt;li&gt;All models out there cheated relative to what a child does
        &lt;ul&gt;
          &lt;li&gt;list of stems in past tense forms as data but kids don’t have this available to them directly&lt;/li&gt;
          &lt;li&gt;They’re able to map grammar structures without the spoonfeeding of the field&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Marcus et al 1990
    &lt;ul&gt;
      &lt;li&gt;couldn’t use transitional probabilities because of the way they structured the grammar&lt;/li&gt;
      &lt;li&gt;data is still there, not in benchmark form&lt;/li&gt;
      &lt;li&gt;kids only had 2 minutes of data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Infant Learning Rule
    &lt;ul&gt;
      &lt;li&gt;many models proposed in 1999&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adult generalization of inflection to foreign phenomenon
    &lt;ul&gt;
      &lt;li&gt;Hebrew speakers could generalize to sounds in English though they’d never seen it before&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Universally quantified 1:1 mapping
    &lt;ul&gt;
      &lt;li&gt;All these are examples of free generaliation of universally&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Even today there are challenges in learning UQOTMS in systems that lack operations ovre variables&lt;/li&gt;
  &lt;li&gt;Only now is the importance of this issue started to become recognized
    &lt;ul&gt;
      &lt;li&gt;OOD generalization&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Comprehension challenge&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Toward a benchmark for Dynamic Understanding
        &lt;ul&gt;
          &lt;li&gt;develop internal models about what is happening&lt;/li&gt;
          &lt;li&gt;Distinguished from static understanding
            &lt;ul&gt;
              &lt;li&gt;conventional knowledge about what happens in general/generic/ordinary undertanding&lt;/li&gt;
              &lt;li&gt;dynamic understanding is keeping track over time in some situation&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Caveats
        &lt;ul&gt;
          &lt;li&gt;Not claiming sufficiency capturing all aspects of NLU&lt;/li&gt;
          &lt;li&gt;Not claiming this is the only way to improve NLU benchmarks&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We do think that &lt;em&gt;too few existing tasks&lt;/em&gt; look directly at dynamic understanding&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Two for static understanding&lt;/li&gt;
      &lt;li&gt;Four for dynamic understanding&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The dix tasks are illustrative not exhaustive&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Static task 1 : Conventional knowledge
        &lt;ul&gt;
          &lt;li&gt;tests understanding of every dat factual knowledge
            &lt;ul&gt;
              &lt;li&gt;eg. the part of a fish that gives it’s body rigidity is…&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Static task 2  : transformations
        &lt;ul&gt;
          &lt;li&gt;tests understanding of processes and actions that are either plausible or implausible
            &lt;ul&gt;
              &lt;li&gt;Making a salad out of a polyester shirt&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dynamic Task 2 : Atypical Consequences
        &lt;ul&gt;
          &lt;li&gt;What happens when something unusual happens&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dynamic Task 3 : Entity Tracking
        &lt;ul&gt;
          &lt;li&gt;A reader must keep track of entities in written text but this could also be applied in the computer vision side of the world&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dynamic Task 4 : QUantity Tracking&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pilot
    &lt;ul&gt;
      &lt;li&gt;setup:
        &lt;ul&gt;
          &lt;li&gt;40 question answer pairs per task (after removing instances containing errors), via crowdsourcing;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Future Evaluations : Recurrent entity networks
        &lt;ul&gt;
          &lt;li&gt;not fully compatible as it’s geared around specific tasks&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Deep Understanding is hard
    &lt;ul&gt;
      &lt;li&gt;We shouldn’t confuse progress on superficial understanding for real progress&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We can keep building things into the systems that give the innate properties (such as Convolution in CNN’s)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;understanding-neural-processes--beyond-where-and-when-to-how&quot;&gt;Understanding Neural Processes : Beyond WHere and When, to How&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Using brain imaging to study all kinds of cognitive processes in the brain
    &lt;ul&gt;
      &lt;li&gt;reflection bring frustration in that more information has been discovered such as where in the brain or when in the brain is the neural activity
        &lt;ul&gt;
          &lt;li&gt;less concentration on the “how” – this is a bit obvious as it’s easier to use these techniques to ask where and when&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Once we understand the brain, what will be the form of the answer?
    &lt;ul&gt;
      &lt;li&gt;Design principles used wide in the brain
        &lt;ul&gt;
          &lt;li&gt;will vary in levels of detail – and we will surely have a description of how the brain computes&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Whether we might be on the verge of a time when we can take a new approach to studying the question of “how” in the brain&lt;/li&gt;
      &lt;li&gt;Recent dramatic progress in the NN community where we’re gone from computers being blind, deaf, and dumb
        &lt;ul&gt;
          &lt;li&gt;We can now do many of these functions on machines&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Are we at a point where we can now take advantage of these NN models for things like vision and language and use them as hypoethesis about how to brain does these same things.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Predicting fMRI output given people reading words
    &lt;ul&gt;
      &lt;li&gt;hand designed vector embedding by co-occurence with 25 verbs
        &lt;ul&gt;
          &lt;li&gt;predicting where in the brain we would find neural activity as a function of the input word stimulus&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;this studies where in the brain&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Gustatory cortex activity is associated with activity related to co-occurences of words with words like “eat”
    &lt;ul&gt;
      &lt;li&gt;suggestions that the semantics of words are often grounded in parts of the brains who’s functions are affiliated with those words&lt;/li&gt;
      &lt;li&gt;saying “peach” caused activation in certain parts of human brains&lt;/li&gt;
      &lt;li&gt;Our analysis is not asnwering the question “how”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We can look at “when”
    &lt;ul&gt;
      &lt;li&gt;What information si encoded in space and time in the MEG video being shown&lt;/li&gt;
      &lt;li&gt;Is the encoding of the semantics a function of time or is it a discrete process?&lt;/li&gt;
      &lt;li&gt;Trained ~ 1,000,000 classifiers to predict activation in certain brain regions – the classifier was “decoding” the activity into words
        &lt;ul&gt;
          &lt;li&gt;most didn’t predict anything&lt;/li&gt;
          &lt;li&gt;some did
            &lt;ul&gt;
              &lt;li&gt;during the first 50 ms there was nothing to decode&lt;/li&gt;
              &lt;li&gt;next 50ms perceptual features could be decoded
                &lt;ul&gt;
                  &lt;li&gt;we could get gross features of the line drawing as well&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;200 ms, we have a semantic feature&lt;/li&gt;
              &lt;li&gt;250 ms, is it hollow?&lt;/li&gt;
              &lt;li&gt;400 ms even more&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This is the kind of analysis that we can do on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;When and Where&lt;/code&gt; details&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;At 50ms time intervals how accurately can we decode words from activity patterns captured through fMRI
    &lt;ul&gt;
      &lt;li&gt;decodability of feature “wordlength” (peak decodability 100-150ms)&lt;/li&gt;
      &lt;li&gt;this information doesn’t first appear “here” and then move
        &lt;ul&gt;
          &lt;li&gt;it can be decoded simultaneously&lt;/li&gt;
          &lt;li&gt;there’s a synchrony that occurs between these disparate parts of the brain at the same time
            &lt;ul&gt;
              &lt;li&gt;This allows us to look at when&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Maybe these 6 regions work together to figure this out?
        &lt;ul&gt;
          &lt;li&gt;maybe not; maybe something else&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How does the brain compute nueral representations?
    &lt;ul&gt;
      &lt;li&gt;Paradigm for studying “how”
        &lt;ul&gt;
          &lt;li&gt;stimulus input to both models and the brain - compare the learned mappings - and measure the output of both systems&lt;/li&gt;
          &lt;li&gt;our program is an example of “how”
            &lt;ul&gt;
              &lt;li&gt;if we have 10 models, we can ask other questions like “does it allow us to explain, predict, the observed neural activity than the previous model?”&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;AN example of what this paradigm implies
        &lt;ul&gt;
          &lt;li&gt;each point on the slide is a hypothesis, the model obvs being the hypothesis
            &lt;ul&gt;
              &lt;li&gt;the more accurate the model is at recognizing the objects in this image
                &lt;ul&gt;
                  &lt;li&gt;the better it is at predicting the neural activity in humans&lt;/li&gt;
                  &lt;li&gt;correlation between the two models’ performance&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;CNN IT Alignment (Yamins et al 2014) &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;CNN v4 alignment
            &lt;ul&gt;
              &lt;li&gt;penultimate layer – both predict more accurately than the output layer&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How? : Language Processing
    &lt;ul&gt;
      &lt;li&gt;Same concept as the CNN example above, this work was done using computation language models
        &lt;ul&gt;
          &lt;li&gt;BERT&lt;/li&gt;
          &lt;li&gt;ELMo&lt;/li&gt;
          &lt;li&gt;etc.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;MEG scanner and showed the patients a new word every 500ms
        &lt;ul&gt;
          &lt;li&gt;Sentence mean MEG activity&lt;/li&gt;
          &lt;li&gt;184 different sentences in passive and active voice&lt;/li&gt;
          &lt;li&gt;Used the above language models above and for every sentence they constructed each prefix of the sentence and fed it into the model
            &lt;ul&gt;
              &lt;li&gt;linear regression used to predict the neural activity&lt;/li&gt;
              &lt;li&gt;predicted the 500ms neural activity&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Which of these models works best/
        &lt;ul&gt;
          &lt;li&gt;brain actibity prediction accuracy*
            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;?&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;if we consider these models as hypothesis we can now rank them&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Will this paradigm really work? referencing the alignment approach
    &lt;ul&gt;
      &lt;li&gt;these studies have empirical evidence&lt;/li&gt;
      &lt;li&gt;Is this helpful?&lt;/li&gt;
      &lt;li&gt;Limits:
        &lt;ul&gt;
          &lt;li&gt;mismatch between sequential computer processing vs. oscillatory, parallel neural activity&lt;/li&gt;
          &lt;li&gt;there’s a mismatch of constant activity in deep nets vs spiking in the brain&lt;/li&gt;
          &lt;li&gt;mismatch in what we’re even measuring using these experiments
            &lt;ul&gt;
              &lt;li&gt;bloog oxygen, fluctuations, etc. and actual neural activity&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Important questions:
        &lt;ol&gt;
          &lt;li&gt;Does observed neural activity represent neural data representations, or &lt;em&gt;processes that alter&lt;/em&gt; neural representations? (e.g. predictive coding : activity reflects energy being expended to update representations)
            &lt;ul&gt;
              &lt;li&gt;word by word neural activity while reading - reading word number 4 doesn’t mean we can decode the first word
                &lt;ul&gt;
                  &lt;li&gt;we can’t find it in the neural activity - we could when it appeared on the screen
                    &lt;ul&gt;
                      &lt;li&gt;is this measuring a delta or the representation of the stimulus?&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;What are brains truly doing/&lt;/li&gt;
          &lt;li&gt;How does context influence?&lt;/li&gt;
          &lt;li&gt;Should we care if we model only part of it? (BERT doesn’t model word &lt;em&gt;perception&lt;/em&gt;)&lt;/li&gt;
          &lt;li&gt;If we can’t interpret representations in deep nets, does it help explain brain activity in terms of these?&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Alisnging activity bween DNNs and neural activity
        &lt;ul&gt;
          &lt;li&gt;we can write down computation hypothesis and try to align these&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;towards-compositional-understanding-of-the-world-by-agent-based-deep-learning&quot;&gt;Towards Compositional Understanding of the world by agent-based deep learning&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Semantic defn – connected to language in that somehow through language we communicate a representation of the world through these high level variables
    &lt;ul&gt;
      &lt;li&gt;this is closely associated to the idea that we might be able to find these&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Another connection one is trying to make is through that of agency – we are agents that act on the world and we cause changes in the world which induces distributional shifts&lt;/li&gt;
  &lt;li&gt;We need to figure out the OOD generalization problem
    &lt;ul&gt;
      &lt;li&gt;is reality compositional in that i can build a symbolic approximation of certain properties of objects such as roundness for wheels and balls and redness for heat, etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Compositionality is usually associated with linguistics&lt;/li&gt;
  &lt;li&gt;distributed represetations already exist in the idea of DL – and we can think of this compositionally
    &lt;ul&gt;
      &lt;li&gt;this has been intuiitively understood since the 80’s but now we can see why these forms of compositionality bring us up with exponential advantages&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Compositionality works because some assumption about the world can be exploited
    &lt;ul&gt;
      &lt;li&gt;assumption is that I can learn about these features somewhat independently
        &lt;ul&gt;
          &lt;li&gt;glasses independent of if that person is wearing shoes or not
            &lt;ul&gt;
              &lt;li&gt;we don’t need to see all combinations of these things to generalize&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Systematic generalization&lt;/li&gt;
  &lt;li&gt;Dynamically recombining representations of objects
    &lt;ul&gt;
      &lt;li&gt;even when new combinations have 0 probability under training distribution
        &lt;ul&gt;
          &lt;li&gt;science fiction scenarios&lt;/li&gt;
          &lt;li&gt;Driving in an unknown city&lt;/li&gt;
          &lt;li&gt;attempting to exploit the regularity that is in the world&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Closure
    &lt;ul&gt;
      &lt;li&gt;Expressions in novel contexts&lt;/li&gt;
      &lt;li&gt;Assessing systematic generalization of CLEVR models (ARXIV) &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Matching referring expressions (see slides)
        &lt;ul&gt;
          &lt;li&gt;qualifier (brown cube)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;7 Tests
        &lt;ul&gt;
          &lt;li&gt;see slides&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Current SoTA
        &lt;ul&gt;
          &lt;li&gt;Struggles on extension to CLEVR&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Contrasting with the Symbolic AI Program&lt;/li&gt;
  &lt;li&gt;Choices that are happening within the mind aren’t an active process
    &lt;ul&gt;
      &lt;li&gt;This system 1 computation in that it is intuitive and performs a selection of things that are relative to the situation&lt;/li&gt;
      &lt;li&gt;This is a reason why we need to put together the disiderata of the two fields of Symbolic and DNN approaches&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Building block for conscious processing is attention
    &lt;ul&gt;
      &lt;li&gt;focus on one or a few elements at a time&lt;/li&gt;
      &lt;li&gt;content based soft-attention is concenient, can brkprop to learn where to atend&lt;/li&gt;
      &lt;li&gt;attention is an internal action&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Attention is also a key to something also very important
    &lt;ul&gt;
      &lt;li&gt;memory&lt;/li&gt;
      &lt;li&gt;credit assignment&lt;/li&gt;
      &lt;li&gt;vanishing gradients come up in training NN’s&lt;/li&gt;
      &lt;li&gt;unreasonable to assume brains are doing anything like BBTT&lt;/li&gt;
      &lt;li&gt;Alternative to this introduces at the last NeurIPS
        &lt;ul&gt;
          &lt;li&gt;exploting memory – and we get this effect in things like transformers&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Credit assignment so we don’t make the same mistake multiple times&lt;/li&gt;
      &lt;li&gt;Sparse Attentive Backtracking
        &lt;ul&gt;
          &lt;li&gt;dynamically building a graph that can relate the past to the present through many steps&lt;/li&gt;
          &lt;li&gt;On the fly we can create connections to the past and the present&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;eliminating the exponential loss of gradients problem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Attention really forces NN’s to develop a form of representation for indirect references
    &lt;ul&gt;
      &lt;li&gt;why is this coming up?&lt;/li&gt;
      &lt;li&gt;attention mechanisms
        &lt;ul&gt;
          &lt;li&gt;there are many inputs “fighting” for attention and the module that receives the weighted sum and it sin’t able to understand which modules contributed to the weights&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;this allows us to think of NN”s as set transformation machines&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Global Workspace Theory
    &lt;ul&gt;
      &lt;li&gt;Baars++ 1988, Dehaene 2003++&lt;/li&gt;
      &lt;li&gt;bottleneck of sonscious processing&lt;/li&gt;
      &lt;li&gt;selected item in broadcast stored in short-term memory&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Long term goal is to have ane nvironment where learning agents are faced with gradually more difficult tasks
    &lt;ul&gt;
      &lt;li&gt;where humans are in the loop, helping the agents to figure out how it works and communicate with humans&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Affordances, options, exploration &amp;amp; controllable factors
    &lt;ul&gt;
      &lt;li&gt;affordances : concepts / aspects of the environment which can be changed by the agent&lt;/li&gt;
      &lt;li&gt;temporal abstractions : options, super-actions, macros, or prcedures, which can be more complext procedures&lt;/li&gt;
      &lt;li&gt;controllable factors
        &lt;ul&gt;
          &lt;li&gt;jointly learn a set of (policy, factor) such that the policy can control the factor and maximize the mutual information between policues (Bengio et al 2017) &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Consciousness Prior :
    &lt;ul&gt;
      &lt;li&gt;high level variables have a joint distribution, and are not independent which we can manipulate with language&lt;/li&gt;
      &lt;li&gt;graph that represents the joint is a sparse factor graph
        &lt;ul&gt;
          &lt;li&gt;each of the factors in a factor graph corrrespond to a dependency between a group of variables&lt;/li&gt;
          &lt;li&gt;it’s making a statement that links these 3 variables
            &lt;ul&gt;
              &lt;li&gt;each statement as one possible sentence in natural language.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;What’s the connection?
        &lt;ul&gt;
          &lt;li&gt;inference in a graphical model such as this allows us to exploit the sparsity of the graph and we sould visit the the nodes in this graph and it would require we only look at a few neighbors
            &lt;ul&gt;
              &lt;li&gt;selecting these variables from a large set, at lteast the in&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The brain is performing inference on this factor graph&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What &lt;strong&gt;causes&lt;/strong&gt; changes in distributions
    &lt;ul&gt;
      &lt;li&gt;the changes in these distributions are about agents doing things and causing these shifts in the world&lt;/li&gt;
      &lt;li&gt;actions are localized in space and time
        &lt;ul&gt;
          &lt;li&gt;these changes could be explained by just a few variables in the right model
            &lt;ul&gt;
              &lt;li&gt;videos – pixels at timesteps, we’re dead in the water&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;consequences of an intervention on few causes or mechanisms&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How to factorize a joint distribution means uncovering this cause and effect structure
    &lt;ul&gt;
      &lt;li&gt;Bengio et al arxiv : 1901.10912&lt;/li&gt;
      &lt;li&gt;We can recover from a change in distribution faster&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Disentangling the causes:
    &lt;ul&gt;
      &lt;li&gt;A meta-transwer objective for learning to disentangle causal mechanisms&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Doing inference on the Intervention
    &lt;ul&gt;
      &lt;li&gt;Learning causal models from unknown interventions
        &lt;ul&gt;
          &lt;li&gt;learning small causal graphs, avoid exponential explosions of # of fraphs by parameterizing factorized distributions over graphs&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Inference over intervention&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;composition-is-the-core-driver-of-the-human-language-system&quot;&gt;Composition is the core driver of the human language system&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The human language network
    &lt;ul&gt;
      &lt;li&gt;This workshop, but more generally, what people call language seems way beyond what language actually is&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;stable structure that spans across people and all brains&lt;/li&gt;
  &lt;li&gt;A stronger response to sentences than lists of unconnected words&lt;/li&gt;
  &lt;li&gt;Why is the sentence the preferred stimulus
    &lt;ul&gt;
      &lt;li&gt;structure&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What features of linguistic simuli and what associated computations drive neural responses in the human language system?&lt;/li&gt;
  &lt;li&gt;Abstract structure
    &lt;ul&gt;
      &lt;li&gt;domain general syntactic processnig&lt;/li&gt;
      &lt;li&gt;some argue about key hierarchical structure&lt;/li&gt;
      &lt;li&gt;share that all computations behind language processing are highly abstract&lt;/li&gt;
      &lt;li&gt;Overlapping structures in numberical cognition and language and music and language&lt;/li&gt;
      &lt;li&gt;data suggest that this region of our brain is used as much when solving math as when looking at a blank screen
        &lt;ul&gt;
          &lt;li&gt;effectively not at all&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Spacial and mentalization&lt;/li&gt;
      &lt;li&gt;All of these aspects don’t engage regions that handle language for us&lt;/li&gt;
      &lt;li&gt;When processing computer langauges – we had people read snippets of code the critical condition is code comprehension
        &lt;ul&gt;
          &lt;li&gt;understanding coding problems DID NOT elicit a response in the language network&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Rules out this abstract syntactical structural processor&lt;/li&gt;
      &lt;li&gt;Puts a damper on modeling language in a really abstract way&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Meaningful event / event comprehension
    &lt;ul&gt;
      &lt;li&gt;can this representation and activation be linked to sound or story, etc.&lt;/li&gt;
      &lt;li&gt;presented participants with sentences and pictures of certain events and asked them to perform hard tasks&lt;/li&gt;
      &lt;li&gt;semantic conditions elicit a non-trivial amount of repsonse but still lower than the sentence condition&lt;/li&gt;
      &lt;li&gt;Language regions may engage in processing non-verbal representations
        &lt;ul&gt;
          &lt;li&gt;evidence of people with brain damage that language cortex isn’t required for abstract concept mangement, or some such&lt;/li&gt;
          &lt;li&gt;what features are necessary and sufficient to elicit neural responses in face-selective cells / brain areas?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Motivation - vision research&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Syntactic frame
    &lt;ul&gt;
      &lt;li&gt;language specific meaning-independent syntactic processing&lt;/li&gt;
      &lt;li&gt;what is a syntactic frame?: word order, function words, functional morphology&lt;/li&gt;
      &lt;li&gt;sentences elicit the strongest response, word list is 2 or more times lower&lt;/li&gt;
      &lt;li&gt;jabberwonky is even lower&lt;/li&gt;
      &lt;li&gt;a syntactic frame on it’s own elicits a low response in the language specific cortex&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Syntactic frame + meaning
    &lt;ul&gt;
      &lt;li&gt;Grammatrical word order / word-order-based, prediction&lt;/li&gt;
      &lt;li&gt;combinatorially (semantic + syntactic) of words / composition&lt;/li&gt;
      &lt;li&gt;Reasons to facor composition as the core driver :
        &lt;ul&gt;
          &lt;li&gt;combinability of words in the nearby context seems to be a true universal property of our lingual systems
            &lt;ol&gt;
              &lt;li&gt;compositional&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Destroying word order while preserving local combinability
        &lt;ul&gt;
          &lt;li&gt;colors for no reason than to show manipulations&lt;/li&gt;
          &lt;li&gt;made local word swaps&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Estimating local combinabiliy:
    &lt;ul&gt;
      &lt;li&gt;using PMI - does a reasonable job of measuring how dependent two words are on eachother&lt;/li&gt;
      &lt;li&gt;this measures a little bit more bias toward semantics because it weights down certain words&lt;/li&gt;
      &lt;li&gt;fMRI Results
        &lt;ul&gt;
          &lt;li&gt;one of many examples where I wasn’t predicting the results and the results blew my mind&lt;/li&gt;
          &lt;li&gt;the response doesn’t drop &lt;em&gt;AT ALL&lt;/em&gt; with the swapping of the words&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;has been reproduced multiple times&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Locality
    &lt;ul&gt;
      &lt;li&gt;Is it important?&lt;/li&gt;
      &lt;li&gt;Prior reasons to suspect that it is:
        &lt;ol&gt;
          &lt;li&gt;the language network doesn’t care about structure above clause/sentence level;&lt;/li&gt;
          &lt;li&gt;most dependencies in natural language are local (Futrell et al 2015)&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Destroying word order and minimizing (local) combinabiity
    &lt;ul&gt;
      &lt;li&gt;shuffling this causes a drop in the results that coincides with random word order list&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;“Local coherence, global gibberish”
    &lt;ul&gt;
      &lt;li&gt;human language system is all about local sentence coherence&lt;/li&gt;
      &lt;li&gt;span where humans can track is ~ 6 to 7 words&lt;/li&gt;
      &lt;li&gt;6 words is the beginning of how much activation correlates given any length of input, it seems like it’s the lower bound&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Take home message
    &lt;ul&gt;
      &lt;li&gt;Linguistic composition is the overall driver of the language system&lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;robotics-workshop&quot;&gt;Robotics Workshop&lt;/h2&gt;

&lt;h3 id=&quot;challenges-in-robot-learning&quot;&gt;Challenges in Robot Learning&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Automatic adaptation in robotics –&amp;gt; Learning&lt;/li&gt;
  &lt;li&gt;Practical constraints –&amp;gt; data efficiency&lt;/li&gt;
  &lt;li&gt;Models are useful for data-efficient learning in robotics&lt;/li&gt;
  &lt;li&gt;3 Models
    &lt;ol&gt;
      &lt;li&gt;Probabilistic models
        &lt;ul&gt;
          &lt;li&gt;fast RL&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hierarchical Models&lt;/li&gt;
      &lt;li&gt;Physically meaningful models
        &lt;ul&gt;
          &lt;li&gt;encode real world constaints to help move learning along&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Probabilistic Models
    &lt;ul&gt;
      &lt;li&gt;PILCO Framework :
        &lt;ul&gt;
          &lt;li&gt;Probabilistic model for transitiion function
            &lt;ul&gt;
              &lt;li&gt;system identification&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Compute a long term state evolution&lt;/li&gt;
          &lt;li&gt;Policy improvement&lt;/li&gt;
          &lt;li&gt;Apply controller&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Why probabilistic models?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;* we need to find functions that allow us to capture the uncertainty about the world
	* How do we plan and make decisions using the output of a regression model?
	* Instead of picking a single function, we can posit a distribution over all functions
		* I&apos;m much more robust to modeling any of those functions that are within the bounds of the function
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Hierarchical Problems
    &lt;ul&gt;
      &lt;li&gt;Generalize knowledge from knwon tasks to new (related tasks)&lt;/li&gt;
      &lt;li&gt;Re-use experience gathered so far to generalize learning to new dynamics&lt;/li&gt;
      &lt;li&gt;Separate global and task specific properties&lt;/li&gt;
      &lt;li&gt;Shared global parameters&lt;/li&gt;
      &lt;li&gt;GP captures global properties of the dynamics
        &lt;ul&gt;
          &lt;li&gt;latent variables $h_{p}$&lt;/li&gt;
          &lt;li&gt;Variational inference&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Modified cart-pole
        &lt;ul&gt;
          &lt;li&gt;modify length and weight of the pendulum&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data efficiency and interpretability
    &lt;ul&gt;
      &lt;li&gt;can we use model sfrom physics to encode more structure into the problems&lt;/li&gt;
      &lt;li&gt;Starting point is lagrangian mechanics&lt;/li&gt;
      &lt;li&gt;Lagrangian : encodes “type” of physics
        &lt;ul&gt;
          &lt;li&gt;helps us talk about symmetries and conservation laws&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hamilton’s principle
        &lt;ul&gt;
          &lt;li&gt;Learn L instead of learning the dynamics directly&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Euler-Lagrange Equations
        &lt;ul&gt;
          &lt;li&gt;How do we discretize these things?&lt;/li&gt;
          &lt;li&gt;Naively, the errors build up and it becomes completely unphysical&lt;/li&gt;
          &lt;li&gt;Variational Integrators
            &lt;ul&gt;
              &lt;li&gt;preserve the physics as they discretize the space&lt;/li&gt;
              &lt;li&gt;momentum preserving&lt;/li&gt;
              &lt;li&gt;symplectic&lt;/li&gt;
              &lt;li&gt;bounded energy behavior&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Discretize it in a way that preserves the physics&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Variational Integrator Networks &lt;a href=&quot;&quot;&gt;Paper&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Slide&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;Write down the parameterized Lagrangian&lt;/li&gt;
          &lt;li&gt;Derive explicit variational integrator&lt;/li&gt;
          &lt;li&gt;Define the network architecture
            &lt;ul&gt;
              &lt;li&gt;“just a whole big network”&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ed Henry</name></author><summary type="html">NeurIPS 2019</summary></entry><entry><title type="html">ML in the Wild</title><link href="http://localhost:4000/2019/04/18/ML-in-the-wild/" rel="alternate" type="text/html" title="ML in the Wild" /><published>2019-04-18T00:00:00-07:00</published><updated>2019-04-18T00:00:00-07:00</updated><id>http://localhost:4000/2019/04/18/ML-in-the-wild</id><content type="html" xml:base="http://localhost:4000/2019/04/18/ML-in-the-wild/">&lt;h1 id=&quot;machine-learning-in-the-wild&quot;&gt;Machine Learning in the Wild&lt;/h1&gt;

&lt;p&gt;I won’t be covering anything purely technical in this post, but I wanted to get some thoughts out there on what it takes to bring Machine Learning into production,&lt;/p&gt;

&lt;p&gt;“Any sufficiently advanced technology is indistinguishable from magic.” - Arthur C. Clarke&lt;/p&gt;

&lt;p&gt;This quote rings true today as much as the day that it was written. Especially when it comes to Machine Learning. I work with customers every day who are curious what this new magic called Machine Learning(ML) is and how they can apply it to a problem they’re facing. There’s no denying that ML is something that we should all be paying attention to but as we start to wade into the waters of ML, and discussing the process of framing the problem, testing our hypotheses, and bringing a system through to production we need to understand that this requires a bit of a shift in our traditional engineering process. In this post we will outline the general process that I’ve followed while helping customers move from idea/MVP to production.&lt;/p&gt;

&lt;h2 id=&quot;dont-start-with-machine-learning&quot;&gt;Don’t start with Machine Learning&lt;/h2&gt;

&lt;p&gt;ML in undoubtedly changing the way we approach solving problems in the world today. More importantly, however, is knowing what problem it is that you’re trying to solve. Like many sciences and engineering discplines practitioners are looking to understand a problem domain in an effort to guide decision making processes. It’s this decision making process that is what we think about when approaching a problem. I want to highlight a few key questions one should ask about the problem at hand before rummaging through their toolboxes for an overpowered approach. Some of these key questions are as follows.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What decision are we trying to make?&lt;/li&gt;
  &lt;li&gt;Is there an existing decision making mechanism in place?&lt;/li&gt;
  &lt;li&gt;Are we trying to replace this decision making mechanism?&lt;/li&gt;
  &lt;li&gt;Who is this decision impacting?&lt;/li&gt;
  &lt;li&gt;What will the potential outcomes of this decision be?&lt;/li&gt;
  &lt;li&gt;What properties of the system am I trying to capture?&lt;/li&gt;
  &lt;li&gt;Do we have domain experts involved?&lt;/li&gt;
  &lt;li&gt;Do we have the &lt;em&gt;right&lt;/em&gt; domain experts invoved?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;None of the questions I’ve provided have anything to do with Machine Learning directly. Rather, they’re asked to help guide the process of applying ML and measuring it’s utility in a given problem domain. These types of questions will help you scope the problem you’re working on and provide a certain acceptance criteria.&lt;/p&gt;

&lt;h2 id=&quot;data-and-the-system-generating-it&quot;&gt;Data and the system generating it&lt;/h2&gt;

&lt;p&gt;Once we have a thorough understanding of the problem that we’re trying to apply ML to, and we understand what decision it is that we’re trying to make / replace, we can start to investigate what data that system generates. Many of the customers I’ve worked with think about this process as &lt;em&gt;just&lt;/em&gt; the ML oriented questions around the types of features, what types of random variables they are, what classes we may want to define for a supervised learning problem, etc. We also need to understand questions not directly related to the data generating system, itself. Questions around data collection, storage, access, governance, provenance, etc. Questions like :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How is the data being collected?&lt;/li&gt;
  &lt;li&gt;What steps are being taken to validate the data collection mechanisms?&lt;/li&gt;
  &lt;li&gt;How reliable are the measurements being collected?&lt;/li&gt;
  &lt;li&gt;Where is the data being persisted?&lt;/li&gt;
  &lt;li&gt;What controls are in place to manage access to this data?&lt;/li&gt;
  &lt;li&gt;How is this data being versioned?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These questions will influence the success of your ML project, overall. Without data, we’re left without the ability to use this powerful new technology.&lt;/p&gt;

&lt;h2 id=&quot;deliverying-production-grade-software&quot;&gt;Deliverying Production Grade Software&lt;/h2&gt;

&lt;p&gt;The next step in the adoption of ML is understanding not just what software is, how to write it, and how to use an SCM system to manage releases, but one also needs to understand what running software in production entails. Anyone who has been part of the industry for any length of time in the last 5 to 7 years has heard the term DevOps before. This term is just a blend of the terms Development and Operations and the concept of blending the two words captures the idea of minimizing the distance between the two general concepts. What it means to be a developer on a production level system requires a thorough understanding of not only the code base, but the properties and characteristics of our production grade systems and what the upper and lower bounds are on the performance of our systems.&lt;/p&gt;

&lt;p&gt;You may have also heard the term &lt;strong&gt;machine learning engineer&lt;/strong&gt; used within industry, as well. This new title and role is a result of the differences, yet seemingly similar, approaches needed to move from experimentation to production in ML systems. Some of the things to think about involve both the data acquisition, and machine learning (training and serving) pipelines.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What does testing look like for our pipelines, end to end?&lt;/li&gt;
  &lt;li&gt;How do we perform validation of performance of our system (not just the model)?&lt;/li&gt;
  &lt;li&gt;How can we provide tooling to measure for concept drift?&lt;/li&gt;
  &lt;li&gt;How can we qualify acceptable throughput of our system, end to end?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;now-for-machine-learning&quot;&gt;Now for Machine Learning&lt;/h2&gt;

&lt;p&gt;Now that we have a thorough understanding of the problem domain, use case, data generating system, and all of the software required to stand a system up in production we can start to loop back to the opening thoughts of this post. We need to understand what methods we might be able to use to describe the phenomenon that we’re trying to capture. Typically in Machine Learning by describe, we mean capturing the variance of the overall system in a way that we can use to ultimately make decisions.&lt;/p&gt;

&lt;p&gt;In order to understand how we can apply ML, in production, we need to understand everything outlined above because it will impact the choices we make from a modeling perspective. Anecdotally we don’t want to make the decision of using a non-parametric model in a given problem domain where the datasets might be growing rapidly. A concrete example of a use case that I’ve run into in this effect has been modeling data networking traffic characteristics. The rate at which data is generated and collected depends on the number of devices sending information over a network. With the types of connectivity we see today this can quickly become a show stopper from moving a model into production, especially if we have to layer feature engineering into the pipeline, on the fly, as well. A non-parametric model will quickly run out of resources in terms of computational and/or time, depending on the problem domain.&lt;/p&gt;

&lt;p&gt;Understanding the use case, the decisions we’re trying to make, what mechanisms are in place to collect and persist the data that our system is generating, and the software tooling and ecosystems required to put pipelines into production are imperative to providing a seamless experience of applying Machine Learning in the real world.&lt;/p&gt;

&lt;h2 id=&quot;end-to-end-throughput&quot;&gt;End-to-end Throughput&lt;/h2&gt;

&lt;p&gt;Last but not least after all of the steps outlined above are thoroughly understood we can start to provide the engineering guarantees we’re used to in the technology world. Anyone who has heard the term speeds and feeds understand that we’re talking about the end-to-end throughput of an entire tech stack, from start to finish. Once we are able to effectively measure all of the components of our ML system we can then identify bottle necks and work to alleviate them in a measureable and defensible way.&lt;/p&gt;

&lt;p&gt;Overall, deploying Machine Learning in production may start out as feeling orthogonal to the traditional software engineering methodologies, but once an organization works through a few proof of concept or minimum viable product efforts, they will then understand what it takes to provide a meaningful end-to-end experience for using this new magic called Machine Learning.&lt;/p&gt;</content><author><name>Ed Henry</name></author><summary type="html">Machine Learning in the Wild</summary></entry><entry><title type="html">Machine Learning and Artificial Intelligence</title><link href="http://localhost:4000/2018/06/08/Machine-Learning-and-Artificial-Intelligence/" rel="alternate" type="text/html" title="Machine Learning and Artificial Intelligence" /><published>2018-06-08T00:00:00-07:00</published><updated>2018-06-08T00:00:00-07:00</updated><id>http://localhost:4000/2018/06/08/Machine-Learning-and-Artificial-Intelligence</id><content type="html" xml:base="http://localhost:4000/2018/06/08/Machine-Learning-and-Artificial-Intelligence/">&lt;h1 id=&quot;machine-learning-and-artificial-intelligence&quot;&gt;Machine Learning and Artificial Intelligence&lt;/h1&gt;

&lt;p&gt;There is a seemingly common thread right now in the tech industry around the confluence of terminology that can be used when addressing the broader practice of studying and applying machine learning to interesting problems. For some value of interesting.&lt;/p&gt;

&lt;p&gt;First I want to start with a history of the term &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artificial intelligence&lt;/code&gt;. The term was coined by John McCarthy for the famous conference at Dartmouth that was held in 1956, hosted by that of Marvin Minksy, and Claude Shannon, as well. The conference’s aim was to study the idea that every aspect of learning or other feature of intelligence can, in principle, be so precisely described that a machine can be made to simulate it. Said differently the goal of the conference was to investigate the plausibility of a machine being able to emulate, at least at first perceptual, problems that were previously reserved for the domain of humans.&lt;/p&gt;

&lt;h2 id=&quot;definitions&quot;&gt;Definitions&lt;/h2&gt;

&lt;p&gt;I want to start this post with some definitions from some of the major literature in the field to normalize what is meant when using different words and phrases to describe the application of science to quantify and/or qualify some dataset.&lt;/p&gt;

&lt;p&gt;The first term I will address is Machine Learning and I will decompose the phrase into its constituent components. Both machine, and learning.&lt;/p&gt;

&lt;h3 id=&quot;machine&quot;&gt;Machine&lt;/h3&gt;

&lt;p&gt;Depending on your choice of common English dictionaries the definition of the word machine can vary. We will utilize the Oxford Dictionary which defines the term &lt;a href=&quot;https://en.oxforddictionaries.com/definition/machine&quot;&gt;machine&lt;/a&gt; as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;An apparatus using mechanical power and having several parts, each with a definite function and together performing a particular task.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The definition fits that of a modern computer. Most modern consumer computers follow the &lt;a href=&quot;https://en.wikipedia.org/wiki/Von_Neumann_architecture&quot;&gt;Von Neumann architecture&lt;/a&gt; in that there are disparate components working together to perform a particular task. Mainly a Central Processing Unit, and a Memory Unit that work in orchestra to take as input some value, and produce another value as output. This is the definition that I will apply to the word machine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/510px-Von_Neumann_Architecture.svg.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;learning&quot;&gt;Learning&lt;/h3&gt;

&lt;p&gt;We will also appeal to the Oxford Dictionary for the definition of the term &lt;a href=&quot;https://en.oxforddictionaries.com/definition/learning&quot;&gt;learning&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The acquisition of knowledge or skills through study, experience, or being taught.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This definition is in line with something that is intuitive but can sometimes become lost in the noise of the every day higher level interactions we’re having with the world around us. We are, in real time, learning on many levels of abstraction that are presented to us through out cognitive faculties. Consciously learning the fundamental theory of algebra is a seemingly active exercise in which we study material to learn the theorem and how to apply it. However separate from that conscious learning, we are also subconsciously learning from many inputs we are receiving. Suppose we decide to stop studying our material on algebra and instead decide that we want to go for a jog. As we begin our journey things are going smoothly and when we aren’t paying attention we stumble on an obstruction in the middle of the pathway. As we stumble our brain is subconsciously using many inputs from our sensors contained within our system called the human body to right our trajectory to ensure we don’t fall. Using a seemingly more concrete example would be a gymnast performing a routine that they have repeatedly practiced until they are satisfied. A similar analogy could be made for the increase and decrease in requirement of oxygen within the body as we are burning more energy throughout the process of exercise. As our heart rate increases our respiration rate increases to compensate for the increase in oxygen required for metabolism.&lt;/p&gt;

&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h2&gt;

&lt;p&gt;I want to formalize the definition of machine learning in the way that the research and industry tend to apply them.&lt;/p&gt;

&lt;p&gt;I think about it in terms of Tom Mitchell’s definition, in his book &lt;a href=&quot;https://www.amazon.com/Learning-McGraw-Hill-International-Editions-Computer/dp/0071154671/ref=asap_bc?ie=UTF8&quot;&gt;Machine Learning&lt;/a&gt;, which offers a formal definition in the bounds by which science and engineering can work.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A computer program is said to &lt;strong&gt;learn&lt;/strong&gt; from &lt;em&gt;experience&lt;/em&gt; &lt;strong&gt;E&lt;/strong&gt; with respect to some class of &lt;em&gt;task&lt;/em&gt; &lt;strong&gt;T&lt;/strong&gt; and &lt;em&gt;performance&lt;/em&gt; measure &lt;strong&gt;P&lt;/strong&gt;, if its performance measure &lt;strong&gt;P&lt;/strong&gt; at task &lt;strong&gt;T&lt;/strong&gt; as measured by &lt;strong&gt;P&lt;/strong&gt;, improves with experience.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This definition also captures the fundamental areas of research and industry application that exist within machine learning.&lt;/p&gt;

&lt;p&gt;Above, when referencing emulation of tasks that are normally performed by other systems that exist in the world,  I mean that these systems can be a product of biological or human engineering efforts. There are many tasks that biological systems, such as humans and animals, perform which can be emulated using this process called machine learning. Actions that we perform such as recognizing objects around us, to understanding the approximate trajectory of an object, such as a ball, and being able to intercept that ball to catch it. Along with other processes such as understanding what someone is saying through the combination of speech and gesture recognition while communicating.&lt;/p&gt;

&lt;p&gt;There are also other, external to the human psyche, tasks that we can use machine learning for as well. We may lack the biological sensors to measure many of the systems around us but we can build sensors for these systems and then use machine learning to have computers “learn” about these systems. Systems like the weather, astronomical objects, search engines, etc.&lt;/p&gt;

&lt;h2 id=&quot;artificial-intelligence&quot;&gt;Artificial Intelligence&lt;/h2&gt;

&lt;p&gt;Now I want to address the term artificial intelligence in the same way that I had addressed machine learning. By decomposing it into its constituent words, defining them, and attempting to define what the combination of the two terms, means.&lt;/p&gt;

&lt;h3 id=&quot;artificial&quot;&gt;Artificial&lt;/h3&gt;

&lt;p&gt;The term &lt;a href=&quot;https://en.oxforddictionaries.com/definition/artificial&quot;&gt;artificial&lt;/a&gt; is defined by the Oxford Dictionary as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Made or produced by human beings rather than occurring naturally, especially as a copy of something natural.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This term is a bit more broad in its definition in that many of the objects we see around us are an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artificial&lt;/code&gt; representation of something naturally occurring. Things like artificial flowers, or artificial limbs that enable individuals perform tasks that might otherwise not be possible. The key interpretation here is the fact that it is the creation of something that seemingly isn’t naturally occurring. Notwithstanding the logical argument that could be made that there is some hierarchical interpretation to the idea of something being created by something that was created naturally, humans, ergo whatever was created could be interpreted as something naturally occurring.&lt;/p&gt;

&lt;h3 id=&quot;intelligence&quot;&gt;Intelligence&lt;/h3&gt;

&lt;p&gt;Now we come to a seemingly ill-defined term that exist in the world of science and engineering. That of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;intelligence&lt;/code&gt;. When we look at the Oxford definition of the word we can see just how general the interpretation is:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The ability to acquire and apply knowledge and skills.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The ability to apply knowledge and skills is interestingly broad in its definition. As with the logical argument that could be made above about what really &lt;em&gt;is&lt;/em&gt; artificial and what isn’t, a similar logical argument could be made in that if we create a machine that embodies some sort of skills or abilities that we as humans have acquired, are we creating an intelligent system? Or is the system itself required to acquire the referenced &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;knowledge&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;skills&lt;/code&gt;. We might have to go one rabbit hole deeper in order to make this definition a bit more concrete.&lt;/p&gt;

&lt;p&gt;Knowledge is defined as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Yet again we’re up against the wall with some of the lingual abstractions present in this definition. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Facts&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;information&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;skills&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;experience&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;education&lt;/code&gt;, etc. all contain some sort of implicit definitions in which we tend to take for granted. Rather than looking into the definitions and etymologies of words used to describe a phenomenon that we are observing, we can appeal to a more rigorous definition of what intelligence may be. Referencing the work Legg and Hutter we can find a working definition of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;machine intelligence&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Legg and Hutter start with an analysis of 70 or so definitions of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;intelligence&lt;/code&gt; from different areas of academia including researchers in artificial intelligence and psychologists. There are a few salient definitions from both backgrounds that I would like to reference.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Intelligence is a general factor that runs through all types of performance.” A. Jensen&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I quite like this definition because it affords us a general interpretation in that many of the systems that we build, deploy, and label as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;intelligent&lt;/code&gt; can logically satisfy this definition. All systems have performance measures used to justify whether or not that system is able to perform better than previously, due to some mechanism contributing to the idea. There are also others that are seemingly more philosophically intriguing as well:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The capacity for knowledge, and knowledge possessed.” V. A. C. Henmon&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This eludes to the idea that there is some form of consciousness that needs to exist, a self awareness of ones own capacity for knowledge. This is less concrete in the way of mathematical definition, but I do enjoy at least entertaining the idea if for nothing more than thought exercise.&lt;/p&gt;

&lt;p&gt;Legg and Hutter distill these definitions down to something more general as their definition seems to capture many of the special case interpretations of the 70 odd quotes:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Intelligence measures an agent’s ability to achieve goals in a wide range of environments.” S. Legg and M. Hutter&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As they note in their paper this definition has implicit in it many of the abilities an agent should have to define it as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;intelligent&lt;/code&gt;, abilities such as learning, adapting, and understanding.&lt;/p&gt;

&lt;h2 id=&quot;artificial-intelligence-1&quot;&gt;Artificial Intelligence&lt;/h2&gt;

&lt;p&gt;Now that we’ve defined &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artificial&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;intelligence&lt;/code&gt;, we can define what the two words mean together. It is an agent that doesn’t occur naturally that can some how achieve goals in a wide range of environments.&lt;/p&gt;

&lt;p&gt;There is a more formal definition that Legg and Hutter have defined in [2], as well. That is left to the reader for investigation. For now we will leverage just the general linguistic definition of the term intelligence.&lt;/p&gt;

&lt;p&gt;There are what seem to be direct lines that can be drawn between artificial intelligence and reinforcement learning in that both definitions and the latter’s frameworks encompass the process of training an agent on a given environment to improve its performance over time to achieve whatever goals have been defined, and depending on the area of research there is also the research into the transferability of these agents between many different environments. Whether it be an already trained agent being exposed to a new environment or whether a particular methodology is applicable to more than one environment.&lt;/p&gt;

&lt;h2 id=&quot;normalizing-nomenclature&quot;&gt;Normalizing nomenclature&lt;/h2&gt;

&lt;p&gt;This leads me back to the reason for this writing. It is an attempt to normalize the nomenclature that we as an industry use when addressing the application of these technologies to problem spaces. There are many ways that these terms can become muddied and conflated and I want to ensure we’re all speaking the same language as we make the efforts to apply these technologies in new and interesting ways.&lt;/p&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;I also want to provide a concrete example of where these definitions can be used in our specific problem space of technology systems. Depending on the scale at which we are analyzing a given system, one could be analyzing a single computational device that is part of a larger cluster of computational devices that are meant to distribute computational operations or storing state in a persistent manner. In respective parlance, distributed systems and databases.&lt;/p&gt;

&lt;p&gt;When reasoning about the application of machine learning to systems such as these, there are many aspects of the system that we can attempt to model using methodologies that fall firmly in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;machine learning&lt;/code&gt; definition. A relatively simple example would be the application of some form of novelty detection with respect to the operation of the system. When collecting sensor data at times when the system is considered in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;steady-state&lt;/code&gt; operation, or nothing is currently &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wrong&lt;/code&gt; with the system, we can use novelty detection techniques to model either the data that has been collected itself, or the data generating distribution that we assume our data set has been produced from. Commonly referred to methodologies used to perform this are the application of autoencoders which can learn to reconstruct an input given some compressed representation of that input, or something like a variational autoencoder which attempts to model the parameters of the data generating distribution that produced our dataset that we’re analyzing.&lt;/p&gt;

&lt;p&gt;Where we can cross the line into the area of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artificial intelligence&lt;/code&gt; is when we start to use models to affect change on the system that we are reasoning about. When we think about this from a particular perspective of infrastructure operations, it would be the assumption that a system that is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artificially intelligent&lt;/code&gt; would be able to modify the configuration of a given distributed system to improve the operation of that system. This definition is more in line with that of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reinforcement learning&lt;/code&gt;, that I haven’t covered in this post. This will be covered in later posts.&lt;/p&gt;

&lt;p&gt;This may become part of a multi-post series in an effort to combat the “buzzwordyness”, for lack of a better term, of the industry side of the applications of these methodologies, and I will update posts accordingly.&lt;/p&gt;

&lt;p&gt;More to come…&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/0706.3639&quot;&gt;1 - A Collection of Definitions of Intelligence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://arxiv.org/abs/cs/0605024&quot;&gt;2 - A Formal Measure of Machine Intelligence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.vetta.org/documents/ui_ai50_poster.pdf&quot;&gt;3 - A Formal Measure of Machine Intelligence (Poster)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://courses.cs.washington.edu/courses/csep590/06au/projects/history-ai.pdf&quot;&gt;4 - The History of Artificial Intelligence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html&quot;&gt;5 - A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ed Henry</name></author><summary type="html">Machine Learning and Artificial Intelligence</summary></entry><entry><title type="html">New Year, New Position, Exciting Challenges</title><link href="http://localhost:4000/2017/12/10/New-Year-New-Position/" rel="alternate" type="text/html" title="New Year, New Position, Exciting Challenges" /><published>2017-12-10T00:00:00-08:00</published><updated>2017-12-10T00:00:00-08:00</updated><id>http://localhost:4000/2017/12/10/New-Year-New-Position</id><content type="html" xml:base="http://localhost:4000/2017/12/10/New-Year-New-Position/">&lt;p&gt;Anyone that was tracking the data networking industry’s movements over the last year, knows there was an announcement that Broadcom would be acquiring Brocade. This finally happened within the last 30 days, and then a subsequent acquisition of Ruckus by Arris has finalized the deal completely. With these announcements, I to have my own.&lt;/p&gt;

&lt;p&gt;For the last two years, I’d worked on all things data for the company’s product portfolio, along with the research and application of data science and machine learning to our product portfolios along with ongoing efforts within organizations like the Internet Research Task Force (IRTF), the research arm of the larger IETF. There were many projects that I’ve worked on and many ideas that I was able to test and apply to interesting problems in the infrastructure space but mostly I loved the people that I was working with and the constant challenge that was there to improve both my hard and soft skills in applying, and educating on the theory and application(s), of machine learning in the data networking and larger technology infrastructure space.&lt;/p&gt;

&lt;p&gt;As with most things in life though, seemingly especially good things, they come to an end.&lt;/p&gt;

&lt;p&gt;I wanted to reflect on what I’ve learned throughout my tenure at Brocade, in an attempt to sum up my takeaways. Here goes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I learned what impostor syndrome, and Dunning-Kruger, looked like and felt like. Lots of highs and lows.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I learned what teamwork looks and feels like in, what at the time, was one of the largest companies I’d ever worked for.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I learned what developing strategy, architecture, and following through with engineering those thoughts, really felt like.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I learned what impact a group of people who really believe in something can have on the larger picture of a company.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With that understanding, I am making the choice to leave my position within what is now Ruckus, an Arris Company. I’ve accepted a position within the Dell EMC Service Provider Solutions and Strategy group, under &lt;a href=&quot;https://twitter.com/kshatzka&quot;&gt;Kevin Shatzkamer&lt;/a&gt;, to work on what I’ve been working on the last 2+ years. The application of data science and machine learning in the service provider, and larger technology infrastructure, space. And I can’t be more excited!&lt;/p&gt;

&lt;p&gt;Thank you to everyone within Brocade who believed in me when I didn’t believe in myself.&lt;/p&gt;

&lt;p&gt;Here’s to 2018 and on!&lt;/p&gt;</content><author><name>Ed Henry</name></author><summary type="html">Anyone that was tracking the data networking industry’s movements over the last year, knows there was an announcement that Broadcom would be acquiring Brocade. This finally happened within the last 30 days, and then a subsequent acquisition of Ruckus by Arris has finalized the deal completely. With these announcements, I to have my own.</summary></entry><entry><title type="html">Summer of Machine Learning</title><link href="http://localhost:4000/2017/06/01/Summer-of-Machine-Learning/" rel="alternate" type="text/html" title="Summer of Machine Learning" /><published>2017-06-01T00:00:00-07:00</published><updated>2017-06-01T00:00:00-07:00</updated><id>http://localhost:4000/2017/06/01/Summer-of-Machine-Learning</id><content type="html" xml:base="http://localhost:4000/2017/06/01/Summer-of-Machine-Learning/">&lt;h1 id=&quot;disconnected&quot;&gt;Disconnected&lt;/h1&gt;

&lt;p&gt;Something has been bothering me over the last couple of years. As I’ve progressed in my career I subsequently feel as though I’ve almost entirely disconnected with what helped me launch this part of the career to begin with. Posting what I learn about online, in an effort to help bolster the amount of useful information that is available in the vast sea of garbage that is the internet.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/chrisalbon&quot;&gt;Chris Albon&lt;/a&gt; recently posted on his &lt;a href=&quot;https://chrisalbon.com/blog/summer_of_machine_learning.html&quot;&gt;blog&lt;/a&gt; about an effort he’s going to make this summer with respect to bettering himself both professionally and personally. This post really hit home for me because it’s something that I feel like I’ve wanted to do for quite some time now. But I always feel as though the stuff I may write about or the experiments that I may run somehow won’t be “up to snuff” with others in the machine learning world because I don’t have the proper pedigree of ivy league computer science education. This summer I am hoping to run these fears down, as I know I’ve produced many good works in my professional role, even though I couldn’t publicize them.&lt;/p&gt;

&lt;h1 id=&quot;community&quot;&gt;Community&lt;/h1&gt;

&lt;p&gt;There has also been quite the backlack on social media lately with respect to the requirement of a mathematical pedigree, see &lt;a href=&quot;https://twitter.com/quantombone/status/866002986350149632&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/math_rachel/status/866808228499275776&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;http://www.topbots.com/you-dont-need-phd-master-machine-deep-learning-data-science&quot;&gt;here&lt;/a&gt;, etc., in order to be effective in the understanding and application of machine learning. While I do believe that having a concrete understanding of the mathematics that underly much of the machine learning ideas and processes today, I don’t see it as an ultimately impossible field to get into if you have the drive and willingness to spend time staring at equations in hopes of maybe not understanding them, but rather getting to used to them, to paraphrase von Neumann.&lt;/p&gt;

&lt;p&gt;I’ve also recently enrolled in classes at the local community college in an effort to bolster my understanding of the mathematical landscape that is the underpinnings of the probability, statistics, linear algebra, calculus, etc. that are all required to get used to the tools and methods that are used in machine learning, and more specifically deep learning. I wasn’t able to afford college, and still cannot afford a large university’s tuition, when I was the typical age that most attend, but I’ve been fortunate enough to find myself, now, in a position to fund my own education and I am now doing just that. I used to think of this as a personal flaw, for quite some time, but now I see that it was truly one of the things in my life that helped me develop a certain drive that I believe was required to foster the skills to build a career in technology.&lt;/p&gt;

&lt;p&gt;I have a deep passion for communcation in general, as most of the career has been spent in the realm of information technology infrastructure, specifically in the areas of data networks and distributed systems, and I look to ideas in papers such as &lt;a href=&quot;https://papers.nips.cc/paper/6042-learning-to-communicate-with-deep-multi-agent-reinforcement-learning.pdf&quot;&gt;Learning to Communicate with Deep Multi-Agent Reinforcement Learning&lt;/a&gt; as inspiration for ways that I may be able to apply this research to what I know and love, as well.&lt;/p&gt;

&lt;p&gt;I really just hope to continue fostering and building the communities required to make all of these amazing ideas and technologies flourish.&lt;/p&gt;

&lt;h1 id=&quot;summed-up&quot;&gt;Summed up&lt;/h1&gt;

&lt;p&gt;All of this said, I’m going to follow in Chris’ footsteps and work toward not only bettering myself, but also giving back as much as I can to the rest of the world in the same way that the people whom I’ve learned from, have. Chris set goals in his post, and I think I’ll try to do the same.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Goals :
    &lt;ul&gt;
      &lt;li&gt;Work my way through, and complete the many false starts I’ve had with Christopher Bishop’s &lt;a href=&quot;https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738&quot;&gt;Pattern Rognition and Machine Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Same goes for the &lt;a href=&quot;https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=pd_lpo_sbs_14_t_0?_encoding=UTF8&amp;amp;psc=1&amp;amp;refRID=KRFJEVVCHZBXCW5QEYTT&quot;&gt;Deep Learning&lt;/a&gt; book from Goodfellow et. al.&lt;/li&gt;
      &lt;li&gt;Contribute as much as I can of my system’s background to the community (I’ll start with the Docker containers I’ve built for reusability and reproducability here &lt;a href=&quot;https://hub.docker.com/u/edhenry/&quot;&gt;Docker Images&lt;/a&gt;)&lt;/li&gt;
      &lt;li&gt;I’ve lost 80 lbs since last year through running, but it’s time to switch it up, so I’ll start a Freeletics regimen for supplement while cutting back on running&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Chris had more specific goals than I do, but I am intentionally leaving mine less concrete as I want them to be able to change and grow with me as I re-integrate back into the community as a whole, whether it be the machine learning community, or the one that I hold closest today, IT infrastructure, to be as general as possible.&lt;/p&gt;

&lt;p&gt;I hope this post wasn’t received as too “cheesy”, for lack of a better word, but I do feel like I want to start giving back again after a 2+ year haitus.&lt;/p&gt;

&lt;p&gt;I kinda ripped off the formatting of your spreadsheet Chris, I really hope you don’t mind. Thank you for being the inspiration that has finally pushed me start something more meaningful for myself and the community.&lt;/p&gt;

&lt;iframe style=&quot;width:100%; height:800px&quot; src=&quot;https://docs.google.com/spreadsheets/d/1gbEoi7NP9czCGWbddzN8arYtdqtJZTKx3IsRm7CBkbM/pubhtml?gid=0&amp;amp;single=true&amp;amp;widget=true&amp;amp;headers=false&quot;&gt;&lt;/iframe&gt;</content><author><name>Ed Henry</name></author><summary type="html">Disconnected</summary></entry><entry><title type="html">Algorithmic Toolbox - Week 2</title><link href="http://localhost:4000/2017/01/16/Algorithms-Toolbox-Week-2/" rel="alternate" type="text/html" title="Algorithmic Toolbox - Week 2" /><published>2017-01-16T00:00:00-08:00</published><updated>2017-01-16T00:00:00-08:00</updated><id>http://localhost:4000/2017/01/16/Algorithms-Toolbox-Week%202</id><content type="html" xml:base="http://localhost:4000/2017/01/16/Algorithms-Toolbox-Week-2/">&lt;h3 id=&quot;quick-intro&quot;&gt;Quick Intro&lt;/h3&gt;

&lt;p&gt;As a refresher, I’ve started working through the &lt;a href=&quot;https://www.coursera.org/learn/algorithmic-toolbox&quot;&gt;Algorithmic Toolbox&lt;/a&gt; course offered on &lt;a href=&quot;https://www.coursera.org/&quot;&gt;Coursera&lt;/a&gt;. It’s been a while since I’ve reviewed a lot of the basic algorithms and data structures fundamentals, so I figured I would work through the course to grease the bearings again, so to speak.&lt;/p&gt;

&lt;p&gt;That said, this is a notebook that covers some of the concepts and programming assignments in Week 2 of the course. I will try to post most of the stuff I review and examples I work through for anyone who may find it interesting and useful.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;timeit&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;bigo-notation&quot;&gt;BigO Notation&lt;/h4&gt;

&lt;p&gt;When working with algorithms, it’s typical to measure their “time” as, not a function of how long it takes an algorithm to run according to a wall clock, but rather as a function of the size of the input of the algorithm. This is called the &lt;strong&gt;rate of growth&lt;/strong&gt; of of the running time.&lt;/p&gt;

&lt;p&gt;When utilizing BigO notation we can distill the “most important” parts and cast out the less important parts. We can see this by looking at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ex_run_time&lt;/code&gt; function we’ve defined below. This imaginary algorithm runtime, \(6n^{2}+100n+300\), takes as many machine instruction to execute. Again, this is an example.&lt;/p&gt;

&lt;p&gt;In the example below, we’ve defined two functions that calculate this imaginary runtime according to a user defined input size. We’re going to use this illustration to show that the upper bound on this execution time for this algorithm is defined by the \(n^2\) portion of the imaginary runtime of \(6n_2 + 100n + 300\).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ex_run_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;rt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decomp_run_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coef_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coef_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ex_rt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ex_run_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;decomp_rt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decomp_run_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;line1_plt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ex_rt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Line 1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;line2_plt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decomp_rt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;b&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Line 2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;100n + 300&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;6n^2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/img/output_4_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Looking at the graph above, we can see that the runtime of the \(6n^2\) portion of the runtime dominates the total runtime of the algorithm, overall. Using this assumption, when working with BigO notation, we can drop the \(100n+300\) portion of the runtime complexity, as we’re working against the squared element of the overall runtime. Looking at the graph, we also see that the runtime complexity for the \(n^2\) term of our algorithm intersects the line for the other terms, as well. But the safe assumption here is that this algorithm’s complexity will be overall dominated by the squared term, in any reasonable size input.&lt;/p&gt;

&lt;p&gt;We can even scale the coefficients of the imaginary complexity to prove that this intersection won’t shift much and we’ll still be bounded by the squared term.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;scaled_ex_rt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ex_run_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scaled_decomp_rt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decomp_run_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;_scaled_line1_plt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaled_ex_rt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Line 1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_scaled_line2_plt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaled_decomp_rt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;b&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Line 2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;1000n + 3000&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;0.6n^2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/img/output_7_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Checking out the graph above, we see that the size of the input was able to be scaled pretty considerably. But we can also see that around the input size of 1650, we still end up losing our to the squared term in the runtime of out algorithm. Using this logic, for general purposes, for any reasonable input we can use define the runtime complexity of this algorithm as \(n^2\).&lt;/p&gt;

&lt;h4 id=&quot;generator-methods&quot;&gt;Generator methods&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    Generate a sequence of integers useful in testing the functions below
    &apos;&apos;&apos;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_integers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;programming-assignments&quot;&gt;Programming Assignments&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calc_fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    Task : Given n, find the last digit of the nth Fibonacci number F_n
    
    Input : Single integer n
    
    Constraints : 0 \ge n \ge 10**7
    
    Output : Last digit of F_n
    
    &apos;&apos;&apos;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;int_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;int_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fib_int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calc_fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calc_fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fib_int&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%s is out of range. Please try an integer between 0 and 45.&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;calc_fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CPU times: user 10 ms, sys: 0 ns, total: 10 ms
Wall time: 1.52 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_fibonacci_last_digit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    Task : Given n, find the last digit of the nth Fibonacci number F_n
    
    Input : Single integer n
    
    Constraints : 0 \ge n \ge 10**7
    
    Output : Last digit of F_n
    
    &apos;&apos;&apos;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fib_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%s is out of range. Please try an integer between 0 and 10,000,000.&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_fibonacci_last_digit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_fibonacci_last_digit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;331&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_fibonacci_last_digit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;327305&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CPU times: user 0 ns, sys: 0 ns, total: 0 ns
Wall time: 18.8 µs
2
9
5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;greatest-common-divisor&quot;&gt;Greatest common divisor&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;euclidean_gcd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a_prime&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;euclidean_gcd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;euclidean_gcd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;euclidean_gcd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28851538&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1183019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1
17657
CPU times: user 10 ms, sys: 0 ns, total: 10 ms
Wall time: 981 µs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;least-common-multiple&quot;&gt;Least common multiple&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lcm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;euclidean_gcd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;something is wrong&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lcm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lcm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28851538&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1183019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CPU times: user 0 ns, sys: 0 ns, total: 0 ns
Wall time: 15 µs
24
1933053046
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Ed Henry</name></author><category term="Python" /><category term="Algorithm" /><category term="Coursera" /><summary type="html">Quick Intro</summary></entry><entry><title type="html">Breadth First Search in Python</title><link href="http://localhost:4000/2017/01/06/Breadth-First-Search/" rel="alternate" type="text/html" title="Breadth First Search in Python" /><published>2017-01-06T00:00:00-08:00</published><updated>2017-01-06T00:00:00-08:00</updated><id>http://localhost:4000/2017/01/06/Breadth-First-Search</id><content type="html" xml:base="http://localhost:4000/2017/01/06/Breadth-First-Search/">&lt;h4 id=&quot;breadth-first-search&quot;&gt;Breadth First Search&lt;/h4&gt;

&lt;p&gt;In this notebook / blog post we will explore breadth first search, which is an algorithm for searching a given graph for the lowest cost path to a goal state \(G\).&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;cost&lt;/em&gt; is intentionally abstract as it can be defined as whatever you’d like it to be, whether it be the least amount of vertices traversed to get to \(G\) or whether it be the lowest sum of the weights of edges between a given state and the goal state, \(G\).&lt;/p&gt;

&lt;p&gt;Some quick notational and fundamental review of the definition of a graph is below :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Vertex
    &lt;ul&gt;
      &lt;li&gt;End state, also called a node, of a given path through a graph \(G\)&lt;/li&gt;
      &lt;li&gt;Can also house additional information known as a &lt;em&gt;payload&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Edge
    &lt;ul&gt;
      &lt;li&gt;Also called an arc, the element that connects two vertices within a graph&lt;/li&gt;
      &lt;li&gt;Can be either one way or two way; one way = &lt;strong&gt;directed graph&lt;/strong&gt; or &lt;strong&gt;digraph&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Weight
    &lt;ul&gt;
      &lt;li&gt;A value assigned to an edge to denote “cost” of traversing that edge between two vertices&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With these definitions we can formally define as a graph, \(G\) where \(G = (V,E)\).&lt;/p&gt;

&lt;p&gt;\(V\) is a set of vertices and \(E\) is a set of edges, respectively.&lt;/p&gt;

&lt;p&gt;Each edge is a tuple \((v,w)\) where \(w,v \in V\), adding \(w\) as a third component to represent the weight of that vertex.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Path
    &lt;ul&gt;
      &lt;li&gt;A sequence of edges that connect two vertices.&lt;/li&gt;
      &lt;li&gt;Formally defined as \(\{w_{1},w_{2},...,w_{n}\}\) such that \((w_{i},w_{i+1}) \in E \ \ \ \forall 1 \le i \le n-1\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are great libraries that provide Graph ADT’s, but in this example we’ll implement a Graph class ourselves. It will be useful in understanding a graph and how we can use it.&lt;/p&gt;

&lt;p&gt;We’ll define two classes to support this effort, a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vertex&lt;/code&gt; class, which will represent a given vertex being added to the graph, and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graph&lt;/code&gt; class which holds the master list of vertices.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# unique ID for vertex
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# dict of connected nodes
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connected_to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Add an entry to the connected_to dict with a given
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# weight 
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connected_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# override __str__ for printing
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos; connected to: &apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connected_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_connections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# return keys from connected_to dict
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connected_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# return vertex id&apos;s
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# return weights of edges connected to vertex
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connected_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# dictionary of vertices
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# vertex count
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_vertices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# increment counter when adding vertex
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_vertices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_vertices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_vertex&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_vertex&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# check if vertex exists, return if True
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__contains__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# override __contains__ to list all vertices in Graph object
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# add edge to graph; s = start node; e = end node
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_vertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# return keys of vertices in Graph
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__iter__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# override __iter__ to return iterable of vertices
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;node_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;&quot;D&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;E&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;F&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;&quot;G&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Instantiate graph object and add vertices
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# add a bunch of edges between vertices
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;A&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;C&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;C&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;D&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;D&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;F&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_connections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;(%s, %s)&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(A, B)
(C, E)
(B, E)
(B, C)
(E, F)
(E, D)
(D, B)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# list our vertices
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;A connected to: [&apos;B&apos;]
B connected to: [&apos;E&apos;, &apos;C&apos;]
C connected to: [&apos;E&apos;]
D connected to: [&apos;B&apos;]
E connected to: [&apos;F&apos;, &apos;D&apos;]
F connected to: []
G connected to: []
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deque&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;breadth_first_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;starting_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;goal_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;visited_nodes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deque&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;starting_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;visited_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;visited_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;goal_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connected_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;visited_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appendleft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;        
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;breadth_first_search&lt;/code&gt; implementation that we’ve written, above, we can then ask the graph is there exists a path between multiple nodes. Our function will return a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;True&lt;/code&gt; or a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;False&lt;/code&gt; accordingly.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;breadth_first_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;A&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;G&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;False
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Past creating our own Vertex and Graph objects that we can use to assemble our own graphs, we can use libraries like NetworkX to create graphs and implement algorithms, like breadth first search, over them.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;networkx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;A&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;C&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;C&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;D&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;D&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;F&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;B&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;E&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;networkx_graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networkx_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;networkx_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edges_from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;draw_networkx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/img/output_10_1.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But the library also has the added ability to generate random graphs for us. In this case, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dense_gnm_random_graph()&lt;/code&gt; will generate a random graph of \(G_{n,m}\) where \(n\) is the node count and \(m\) are the number of edges randomly distributed throughout the graph.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dense_gnm_random_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;draw_networkx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/img/output_12_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The networkx library tends to return iterators for each object within the graph context, such as the graph iteself, or the nodes within a graph or the neighbors of a particular node within the graph. This is useful because traversal algorithms such as breadth first search tend to operator in an iterative manner.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nodes&lt;/code&gt; returns an iterable for the nodes in a graph&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;all_neighbors&lt;/code&gt; returns an interable for all neighbors of a passed in graph and specific node&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# quick hack to traverse the iterables returned
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;neighbors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all_neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Node %s has neighbors : %s&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Node 0 has neighbors : [3]
Node 1 has neighbors : []
Node 2 has neighbors : [4, 6]
Node 3 has neighbors : [0, 9, 5]
Node 4 has neighbors : [9, 2]
Node 5 has neighbors : [3]
Node 6 has neighbors : [8, 2]
Node 7 has neighbors : [8, 9]
Node 8 has neighbors : [9, 6, 7]
Node 9 has neighbors : [8, 3, 4, 7]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Or just because, here’s a list comprehension that can do the same thing, that actually shows off a bit of Python’s nested list comprehension functionality. It is possible to also push the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;print&lt;/code&gt; function into the list comprehension below, but it only works in Python 3+ and but is not considered pythonic – so I’m only leaving it to return the nested arrays that a list comprehension normally would.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all_neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[3],
 [],
 [4, 6],
 [0, 9, 5],
 [9, 2],
 [3],
 [8, 2],
 [8, 9],
 [9, 6, 7],
 [8, 3, 4, 7]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The networkx library also includes many, many algorithm implementations already so we can utilize their built-in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;breadth_first_search&lt;/code&gt; algorithm, as we see below. We’re able to print a traversal of the graph starting at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;node 0&lt;/code&gt; and print the entire path taken through the graph.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bfs_edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(0, 3), (3, 9), (3, 5), (9, 8), (9, 4), (9, 7), (8, 6), (4, 2)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Much like we see above, the networkx library also has a built-in depth first search algorithm that will traverse the graph and return an unordered list of tuples of edges that are traversed. I will save a depth first search implementation over our custom Graph object for future posts.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dfs_edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networkx_graph_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(0, 3), (3, 9), (9, 8), (8, 6), (6, 2), (2, 4), (8, 7), (3, 5)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;references&quot;&gt;References&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;https://interactivepython.org/courselib/static/pythonds/index.html&quot;&gt;Problem Solving with Algorithms and Data Structures&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://networkx.readthedocs.io/en/networkx-1.11/index.html&quot;&gt;NetworkX Documentation&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Ed Henry</name></author><category term="Python" /><category term="Search" /><category term="Algorithm" /><category term="BFS" /><summary type="html">Breadth First Search</summary></entry><entry><title type="html">First Class Functions in Python</title><link href="http://localhost:4000/2016/12/21/First-Class-Functions/" rel="alternate" type="text/html" title="First Class Functions in Python" /><published>2016-12-21T00:00:00-08:00</published><updated>2016-12-21T00:00:00-08:00</updated><id>http://localhost:4000/2016/12/21/First-Class-Functions</id><content type="html" xml:base="http://localhost:4000/2016/12/21/First-Class-Functions/">&lt;h2 id=&quot;first-class-functions&quot;&gt;First Class Functions&lt;/h2&gt;

&lt;p&gt;Typically first class functions are defined as a programming entity that can be :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Created at runtime&lt;/li&gt;
  &lt;li&gt;Assigned to a variable or element in a data structure&lt;/li&gt;
  &lt;li&gt;Passed as an argument&lt;/li&gt;
  &lt;li&gt;Returned as the result of a function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By this definition, looking at how Python treats all functions, all functions are first class within Python.&lt;/p&gt;

&lt;p&gt;Below we’ll see examples of exactly how this looks.&lt;/p&gt;

&lt;h4 id=&quot;treating-a-function-like-an-object&quot;&gt;Treating a function like an object&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Returns n! or n(factorial)
    
    e.g 5! = 5 * 4 * 3 * 2
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;120
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;first-class-analysis&quot;&gt;First class analysis&lt;/h4&gt;

&lt;p&gt;We can show the first class nature of this function object using a few examples.&lt;/p&gt;

&lt;p&gt;We can assign the function to a variable, which will invoke the function when calling that variable.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fact&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorial&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;120
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can also use the map function, and pass our function as the first argument, allowing that function to be evaluated against the second argument, which is an iterable. Allowing this function to be applied in a successive fashion to all elements of this iterable.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;higher-order-functions&quot;&gt;Higher-Order Functions&lt;/h4&gt;

&lt;p&gt;A higher order function is a bit….meta. It can take, as an argument, a function and then returns a function as a result.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map()&lt;/code&gt; example used above is a great example of this.&lt;/p&gt;

&lt;p&gt;The built-in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sorted()&lt;/code&gt; function is another great example of this, within Python. We can pass it an iterable, along with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;key&lt;/code&gt; that can then be applied in succession to the items in the list.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;food&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;eggplant&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;carrots&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;celery&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;s&quot;&gt;&apos;potatoes&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;tomatoes&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;rhubarb&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&apos;strawberry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;blueberry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;raspberry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&apos;banana&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;cherry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;food&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[&apos;celery&apos;, &apos;banana&apos;, &apos;cherry&apos;, &apos;carrots&apos;, &apos;rhubarb&apos;, &apos;eggplant&apos;, &apos;potatoes&apos;, &apos;tomatoes&apos;, &apos;blueberry&apos;, &apos;raspberry&apos;, &apos;strawberry&apos;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Any single argument function can be used in the key argument of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sorted()&lt;/code&gt; method.&lt;/p&gt;

&lt;p&gt;as a trivial example, we may want to use the reversed order of the characters to sort of words, as this will cause certain clustering of character strings together, such as -berry, and -toes.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    Reverse the order of the letters in a given string
    &apos;&apos;&apos;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;food&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[&apos;banana&apos;, &apos;rhubarb&apos;, &apos;tomatoes&apos;, &apos;potatoes&apos;, &apos;carrots&apos;, &apos;eggplant&apos;, &apos;celery&apos;, &apos;blueberry&apos;, &apos;raspberry&apos;, &apos;strawberry&apos;, &apos;cherry&apos;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;replacements-for-map-and-filter&quot;&gt;Replacements for map and filter&lt;/h4&gt;

&lt;p&gt;Map, filter, and reduce are typically offered in functional languages as higher order functions. However, the introduction of list comprehensions and generator expressions have downplayed the value of the map and filter functions, as listcomp’s and genexp’s combine the job of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Build a list of factorials from 0! to 5!
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1, 1, 2, 6, 24, 120]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Build a list of factorials from 0! to 5!
# but using list comprehension
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1, 1, 2, 6, 24, 120]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Build a list of factorials of odd numbers up to 5!, using `map` and `filter`
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1, 6, 120]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see above that with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt; functions, we needed to use a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lambda&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;Using a list comprehension can remove this requirement, and concatenate the operations.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Build a list of factorials of odd numbers up to 5!, using list comprehension
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1, 6, 120]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;anonymous-functions&quot;&gt;Anonymous Functions&lt;/h4&gt;

&lt;p&gt;The example above, where we’ve utilized &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt; combined with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lambda&lt;/code&gt; function leads us into our next example.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lambda&lt;/code&gt; keyword created an anonymous function within a Python expression. However the syntax limits the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lambda&lt;/code&gt; to be pure expressions. This means that the body of a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lambda&lt;/code&gt; function can’t use other Python statements such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;while&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;try&lt;/code&gt;, etc.&lt;/p&gt;

&lt;p&gt;These are typically limited in their use because of the lack of the ability to use more complex control structures within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lambda&lt;/code&gt; functions. This can lead to unreadable or unworkable results.&lt;/p&gt;

&lt;p&gt;However, they can still prove useful in certain contexts, such as list arguments.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;food&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;eggplant&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;carrots&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;celery&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;s&quot;&gt;&apos;potatoes&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;tomatoes&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;rhubarb&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&apos;strawberry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;blueberry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;raspberry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&apos;banana&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;cherry&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;food&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[&apos;banana&apos;, &apos;rhubarb&apos;, &apos;tomatoes&apos;, &apos;potatoes&apos;, &apos;carrots&apos;, &apos;eggplant&apos;, &apos;celery&apos;, &apos;blueberry&apos;, &apos;raspberry&apos;, &apos;strawberry&apos;, &apos;cherry&apos;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Fluent Python, Ramalho &lt;a href=&quot;http://shop.oreilly.com/product/0636920032519.do&quot;&gt;Purchase Link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ed Henry</name></author><category term="Python" /><summary type="html">First Class Functions</summary></entry><entry><title type="html">Hashing in Python</title><link href="http://localhost:4000/2016/12/21/Hashing-in-Python/" rel="alternate" type="text/html" title="Hashing in Python" /><published>2016-12-21T00:00:00-08:00</published><updated>2016-12-21T00:00:00-08:00</updated><id>http://localhost:4000/2016/12/21/Hashing-in-Python</id><content type="html" xml:base="http://localhost:4000/2016/12/21/Hashing-in-Python/">&lt;h2 id=&quot;hashing&quot;&gt;Hashing&lt;/h2&gt;

&lt;p&gt;Hashing can be useful in speeding up the search process for a specific item that is part of a larger collection of items. Depending on the implementation of the hashing algorithm, this can turn the computational complexity of our search algorithm from \(O(n)\) to \(O(1)\). We do this by building a specific data structure, which we’ll dive into next.&lt;/p&gt;

&lt;h4 id=&quot;hash-table&quot;&gt;Hash Table&lt;/h4&gt;

&lt;p&gt;A hash table is a collection of items, stored in such a way as to make it easier to find them later. The table consists of &lt;strong&gt;slots&lt;/strong&gt; that hold items and are named by a specific integer value, starting with 0.&lt;/p&gt;

&lt;p&gt;Example of a hash table (sorry for the poor formatting because markdown :&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;0&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;3&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;4&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;5&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;6&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;7&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;8&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;9&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;10&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;None&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Each entry in this hash table, is currently set to a value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;None&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;A hash function is used when mapping values into the slots available within a Hash table. The hash function typically takes, as input, an item from a collection, and will return an integer in the range of slot names, between \(0\) and \(m-1\). There are many different hash functions, but the first we can discuss is the “remainder method” hash function.&lt;/p&gt;

&lt;h4 id=&quot;remainder-hash-function&quot;&gt;Remainder Hash Function&lt;/h4&gt;

&lt;p&gt;The remainder hash function takes an item from a collection, divides it by the table size, returning the remainder of it’s hash value \(h(item) = item \% \text{table_size}\). Typically modulo arithmetic is present in some form for all hash functions, as the result must be in the range of the total number of slots within the table.&lt;/p&gt;

&lt;p&gt;Assuming we have a set of integer items \(\{25,54,34,67,75,21,77,31\}\), we can use our hash function to find slots for our values, accordingly.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;67&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;77&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The hash for %s is %s&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hash_table&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Execute the hash function
# Create table with 11 entries to match example above
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hash_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Print the resulting hash table
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The hash for 25 is 3
The hash for 54 is 10
The hash for 34 is 1
The hash for 67 is 1
The hash for 75 is 9
The hash for 21 is 10
The hash for 77 is 0
The hash for 31 is 9
{0: 77, 1: 67, 2: None, 3: 25, 4: None, 5: None, 6: None, 7: None, 8: None, 9: 31, 10: 21}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the hash values have been computed, we inset each item into the hash table at the designated position(s). We can now see that there are entries with corresponding hash values stored in a python dictionary. This is obviously a very simple implementation of a hash table.&lt;/p&gt;

&lt;p&gt;There is something interesting to note here, though, when working through using a simple hashing algorithm like the remainder method. We have items, in our case integers, which hash to the same value. Specifically, we can see that there are 2 items that hash to each of the 1, 9, and 10 slots. These are what are known as &lt;strong&gt;collisions&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Clearly these collisions can cause problems, as out of the 8 initial items that we’d started with, we only have 5 items actually stored in our hash table. This leads us into the next section we’ll discuss, and that is hash functions that can help alleviate this collision problem.&lt;/p&gt;

&lt;h3 id=&quot;hash-functions&quot;&gt;Hash Functions&lt;/h3&gt;

&lt;p&gt;Hash functions that map, perfectly, every item into it’s own unique slot in a hash table is known as a &lt;strong&gt;perfect hash function&lt;/strong&gt;. If we knew the collection of items and that it would never change, it’s possible to construct a perfect hash function specific to this collection, but we know that the dynamics of the real world tend to not allow something so simple.&lt;/p&gt;

&lt;p&gt;Dynamically growing the hash table size so each possible item in the item range can be accomodated is one way to construct a perfect hash function. This guarantees each item will have it’s own slot. But this isn’t feasible, as something as simple as tracking social security numbers would require over one billion slots within the hash table. And if we’re only tracking a small subset of the full set of social security numbers, this would become horribly inefficient with respect to hardware resources available within the machine our code is running on.&lt;/p&gt;

&lt;p&gt;With the goal of constructing a hash function that will minimize the number of collisions, has low computational complexity, and evenly distributes our items within the hash table, we can take a look at some common ways to extend this remainder method.&lt;/p&gt;

&lt;h4 id=&quot;folding-method&quot;&gt;Folding Method&lt;/h4&gt;

&lt;p&gt;The folding method for hashing an item begins by diving the item into equal size pieces (though the last piece may not be of equal size to the rest). These pieces are then added together to create the resulting hash value. A good example of this is a phone number,such as 456-555-1234. We can break each pair of integers up into groups of 2, add them up, and use that resulting value as an input to our hashing function.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stringify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Method to convert integer values into array of component integers
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;string_items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;string_items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string_items&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;folding_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;
    Quick hack at a folding hash algorithm
    &apos;&apos;&apos;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hashes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;str_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;str_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;str_concat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;bifold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bifold&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;hashes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashes&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example phone numbers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phone_number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4565551234&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4565557714&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9871542544&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4365554601&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# String/Character-fy the phone numbers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_pn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stringify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phone_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Hash the phone numbers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folded_hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;folding_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_pn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Input values into hash table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folding_hash_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folded_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Print the results
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folding_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The hash for 210 is 1
The hash for 502 is 7
The hash for 758 is 10
The hash for 969 is 1
{0: None, 1: 969, 2: None, 3: None, 4: None, 5: None, 6: None, 7: 502, 8: None, 9: None, 10: 758}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;ordinal-hash&quot;&gt;Ordinal Hash&lt;/h4&gt;

&lt;p&gt;When dealing with strings, we can use the ordinal values of the constituent characters of a given word, to create a hash.&lt;/p&gt;

&lt;p&gt;It’s important to notice, however, that anagrams can produce hash collisions, as shown below.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cat&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tac&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;4
4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;weighted-ordinal-hashing&quot;&gt;Weighted ordinal hashing&lt;/h4&gt;

&lt;p&gt;In the case above, just using ordinal values can cause hash collisions. We can actually use the positional structure of the word to as a set of weights for generating a given hash. As seen below.&lt;/p&gt;

&lt;p&gt;A simple multiplication by the positional value of each character will cause anagrams to evaluate to different hash values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;weighted_ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# ord_hash
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cat&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# weighted_ord_hash
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weighted_ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tac&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;4
9
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;collision-resolution&quot;&gt;Collision Resolution&lt;/h2&gt;

&lt;p&gt;When there are hash collisions, like we’ve seen previously, it’s important to understand ways that we can alleviate the collisions.&lt;/p&gt;

&lt;p&gt;One simple way to handle the collision, should there already be an entry in our hash table with the same hash value, is to search sequentially through all slots near the original hash, for an empty slot. This may require us to circularly traverse the entire hash table to allow us to cover all possible slots. This process is known as &lt;strong&gt;open addressing&lt;/strong&gt; and the technique within this process that we’re using is called &lt;strong&gt;linear probing&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In the following code examples, we’ll reuse the simple remainder method hash function that we’ve defined above. Along with the original set of integers we were hashing, as there were some collisions that occured.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;67&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;77&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Execute the hash function
# Create table with 11 entries to match example above
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hash_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Print the resulting hash table
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The hash for 25 is 3
The hash for 54 is 10
The hash for 34 is 1
The hash for 67 is 1
The hash for 75 is 9
The hash for 21 is 10
The hash for 77 is 0
The hash for 31 is 9
{0: 77, 1: 67, 2: None, 3: 25, 4: None, 5: None, 6: None, 7: None, 8: None, 9: 31, 10: 21}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see there were multiple collisions within this dataset. Specifically hashes of 1, 9, and 10. And we can see in the resulting table that only the last computed hashes are stored in the respective table slots.&lt;/p&gt;

&lt;p&gt;Below we’ll implement an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lp_hash&lt;/code&gt; function that will perform linear probing over the slots available within the table for any collisions that occur.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;67&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;77&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rehash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oldhash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oldhash&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lp_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))])&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%s hashed == %s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Collision, attempting linear probe &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rehash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Setting next slot to %s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rehash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Next slot was not empty, trying next slot %s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lp_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;25 hashed == 3 

54 hashed == 10 

34 hashed == 1 

67 hashed == 1 

Collision, attempting linear probe 

Setting next slot to 2 

75 hashed == 9 

21 hashed == 10 

Collision, attempting linear probe 

Setting next slot to 0 

77 hashed == 0 

Collision, attempting linear probe 

Setting next slot to 1 

Next slot was not empty, trying next slot 2 

Next slot was not empty, trying next slot 3 

Next slot was not empty, trying next slot 4 

31 hashed == 9 

Collision, attempting linear probe 

Setting next slot to 10 

Next slot was not empty, trying next slot 0 

Next slot was not empty, trying next slot 1 

Next slot was not empty, trying next slot 2 

Next slot was not empty, trying next slot 3 

Next slot was not empty, trying next slot 4 

Next slot was not empty, trying next slot 5 

{0: 21, 1: 34, 2: 67, 3: 25, 4: 77, 5: 31, 6: None, 7: None, 8: None, 9: 75, 10: 54}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Used a little more interestingly, we can use the weighted ordinal hash function that we’ve defined above, combined with the lp_hash function that we’ve just defined, to store string(s) for later lookup.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;animal_items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cat&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;dog&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;goat&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
         &lt;span class=&quot;s&quot;&gt;&quot;chicken&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;pig&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;horse&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;ostrich&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;lion&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;puma&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rehash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oldhash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oldhash&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;weighted_ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hash_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lp_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))])&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weighted_ord_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%s hashed == %s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Collision, attempting linear probe &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rehash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Setting next slot to %s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rehash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Next slot was not empty, trying next slot %s &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_slot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lp_hash_table&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lp_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;animal_items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat hashed == 10 

dog hashed == 9 

goat hashed == 4 

chicken hashed == 4 

Collision, attempting linear probe 

Setting next slot to 5 

pig hashed == 3 

horse hashed == 10 

Collision, attempting linear probe 

Setting next slot to 0 

ostrich hashed == 6 

lion hashed == 8 

puma hashed == 10 

Collision, attempting linear probe 

Setting next slot to 0 

Next slot was not empty, trying next slot 1 

{0: &apos;horse&apos;, 1: &apos;puma&apos;, 2: None, 3: &apos;pig&apos;, 4: &apos;goat&apos;, 5: &apos;chicken&apos;, 6: &apos;ostrich&apos;, 7: None, 8: &apos;lion&apos;, 9: &apos;dog&apos;, 10: &apos;cat&apos;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;http://interactivepython.org/courselib/static/pythonds/SortSearch/Hashing.html#tbl-hashvalues1&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ed Henry</name></author><category term="Python" /><category term="Hashing" /><category term="Algorithm" /><summary type="html">Hashing</summary></entry><entry><title type="html">Netflow and word2vec -&amp;gt; flow2vec</title><link href="http://localhost:4000/2016/12/21/Netflow-flow2vec/" rel="alternate" type="text/html" title="Netflow and word2vec -&amp;gt; flow2vec" /><published>2016-12-21T00:00:00-08:00</published><updated>2016-12-21T00:00:00-08:00</updated><id>http://localhost:4000/2016/12/21/Netflow-flow2vec</id><content type="html" xml:base="http://localhost:4000/2016/12/21/Netflow-flow2vec/">&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#import pyhash
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gensim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mp&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;joblib&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delayed&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;concurrent.futures&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pprint&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pprint&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;mpld3&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.decomposition&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PCA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TruncatedSVD&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Enable mpld3 for notebook
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpld3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enable_notebook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Instantiate hasher object
#hasher = pyhash.city_64()
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Method to strip white test
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Method to set dataframe entries to integers
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;make_int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;    

&lt;span class=&quot;c1&quot;&gt;# Method to match IP against flow srcIP
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sort_ip_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# List to house flows when matches
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;flows_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Iterate over tcp_flows list
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tcp_flows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   
        &lt;span class=&quot;c1&quot;&gt;# Comparison logic - flow[1][3] corresponds to SrcIP in flow tuple
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;        
            &lt;span class=&quot;c1&quot;&gt;# Append match to flows_list
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;flows_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Return dictionary of IPs and flows
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flows_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Create hash of protocol
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;proto_hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;        
    &lt;span class=&quot;c1&quot;&gt;# Create hash of SrcIP
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;srcip_hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;        
    &lt;span class=&quot;c1&quot;&gt;# Create hash of Sport
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;srcprt_hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;# Create hash of DstIP
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dstip_hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Create hash of Dport
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dstprt_hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;# Cast flow entry as list for manipulation
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;flow_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;       
    &lt;span class=&quot;c1&quot;&gt;# Insert hashes as entry in tuple for each flow
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;flow_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proto_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srcip_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srcprt_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
                         &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dstip_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dstprt_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Re-cast flow entry as tuple w/ added hash tuple
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;single_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flow_hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flow_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flow_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Import netflow capture file(s)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cap_files&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;capture20110810.binetflow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;capture20110811.binetflow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;,&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ignore_index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Strip whitespace
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;subsample_cats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Proto&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;SrcAddr&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;DstAddr&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;Dport&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;subsample_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;subsample_cats_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Proto&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;SrcAddr&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;DstAddr&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;Dport&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;Label&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;flow2vec---co-occurence-idea-for-flow-data&quot;&gt;Flow2vec - co-occurence idea for flow data&lt;/h2&gt;

&lt;p&gt;Attempting to find some co-occurence patterns in the flow data according to how an algorithm like word2vec, in its skip-gram implementation specifically for this work, works. The idea is that flows, \(V_{f}\) for vector representation, that occur within a window \(W_{f}\), which can be modeled as “time” using timestamps from the capture. A visual representation of a single flow and window of flows can be seen below :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/flow_window_5.jpg&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;Windows of flows&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When we consider the conditional probabilities \(P(w\|f)\) with a given set of flow captures &lt;strong&gt;Captures&lt;/strong&gt; the goal is to set the parameters \(\theta\) of \(P(w\|f;\theta)\) so as to maximize the capture probability :&lt;/p&gt;

\[\underset{\theta}{\operatorname{argmax}} \underset{f \in Captures}{\operatorname{\prod}} \left[\underset{w \in W_{f}}{\operatorname{\prod}} P(w \vert f;\theta)\right]\]

&lt;p&gt;in this equation \(W_{f}\) is a set of surrounding flows of flow \(f\). Alternatively :&lt;/p&gt;

\[\underset{\theta}{\operatorname{argmax}} \underset{(f, w) \in D}{\operatorname{\prod}} P(w \vert f;\theta)\]

&lt;p&gt;Here \(D\) is the set of all flow and window pairs we extract from the text.&lt;/p&gt;

&lt;p&gt;The word2vec algorithm seems to capture an underlying phenomenon of written language that clusters words together according to their linguistic similarity, this can be seen in something like simple synonym analysis. The goal is to exploit this underlying “similarity” phenomenon with respect to co-occurence of flows in a given flow capture.&lt;/p&gt;

&lt;p&gt;Each “time step”, right now just being a subset of a given flow data set, is as a ‘sentence’ in the word2vec model. We should then be able to find flow “similarities” that exist within the context of flows. The idea is this “symilarity” will really just yield an occurence pattern over the flow data, much like word2vec does for written text.&lt;/p&gt;

&lt;p&gt;Another part of the idea is much like in written text there are word / context, \((w,c)\), patterns that are discovered and exploited when running the algorithm over a given set of written language. There are common occurences and patterns that can be yielded from flow data, much like the occurences and patterns that are yielded from written text.&lt;/p&gt;

&lt;p&gt;At the end of the embedding exercise we can use k-means to attempt to cluster flows, according to the embedding vectors that are produced through the word2vec algorithm. This should yield some sort of clustering of commonly occuring flows that have the same occurence measure in a given set of netflow captures. We can then use this data to measure against other, unseen, flows for future classification of “anamoly”. I use that word loosely as this is strictly expirimental.&lt;/p&gt;

&lt;h3 id=&quot;assumptions-&quot;&gt;Assumptions :&lt;/h3&gt;

&lt;h4 id=&quot;maximizing-the-objective-will-result-in-good-embeddings-v_f--forall-w-in-v&quot;&gt;Maximizing the objective will result in good embeddings \(v_{f}  \forall w \in V\)&lt;/h4&gt;

&lt;h5 id=&quot;it-is-important-to-note-with-the-above-statment-with-respect-to-time-is-the-assumption-that-the-data-i-am-operating-from-has-already-been-ordered-according-to-the-tooling-i-used-to-acquire-it_&quot;&gt;It is important to note with the above statment, with respect to time, is the assumption that the data I am operating from has already been ordered according to the tooling I used to acquire it_&lt;/h5&gt;

&lt;h2 id=&quot;skip-gram-negative-sampling&quot;&gt;Skip-gram Negative Sampling&lt;/h2&gt;

&lt;p&gt;One of the other portions of the word2vec algorithm that I will be testing in this experiment will be negative sampling.&lt;/p&gt;

&lt;p&gt;The objective of Skipgram with Negative Sampling is to maximize the the probability that \((f,w)\) came from the data \(D\). This can be modeled as a distribution such that \(P(D=1\|f,w)\) be the probability that \((f,w)\) came from the data and \(P(D=0\|f,w) = 1 - P(D=1\|f,w)\) the probability that \((f,w)\) did not.&lt;/p&gt;

&lt;p&gt;The distribution is modeled as :&lt;/p&gt;

\[P(D=1|f,w) = \sigma(\vec{f} \cdot \vec{w}) = \frac{1}{1+e^{-\vec{f} \cdot \vec{w}}}\]

&lt;p&gt;where \(\vec{f}\) and \(\vec{w}\), each a \(d\)-dimensional vector, are the model parameters to be learned.&lt;/p&gt;

&lt;p&gt;The negative sampling tries to maximize \(P(D=1\|f,w)\) for observed \((f,w)\) pairs while maximizing \(P(D=0\|f,w)\) for stochastically sampled “negative” examples, under the assumption that selecting a context for a given word is likely to result in an unobserved \((f,w)\) pair.&lt;/p&gt;

&lt;p&gt;SGNS’s objective for a single \((f,w)\) output observation is then:&lt;/p&gt;

\[E = \log \sigma(\vec{f} \cdot \vec{w}) + k \cdot \mathbb{E}_{w_{N} \sim P_{D}} [\log \sigma(\vec{-f} \cdot \vec{w}_N)]\]

&lt;p&gt;where \(k\) is the number of “negative” samples and \(w_{N}\) is the sampled window, drawn according to the empirical unigram distribution \(P_{D}(w) = \frac{\text{#}w}{\|D\|}\)&lt;/p&gt;

&lt;p&gt;Let’s disassemble this objective function into its respective terms and put it back together again :&lt;/p&gt;

&lt;p&gt;The term \(\log \sigma(\vec{f} \cdot \vec{w})\), from above, is used to model the&lt;/p&gt;

&lt;p&gt;This object is then trained in an online fashion using stochastic gradient updated over the observed pairs in the corpus \(D\). The goal objective then sums over the observed \((f,w)\) pairs in the corpus :&lt;/p&gt;

\[\ell = \Sigma_{f \in V_{f}} \Sigma_{w \in V_{w}} \#(f,w)(\log \sigma(\vec{f} \cdot \vec{w}) + k \cdot \mathbb{E}_{w_{N} \sim P_{D}} [\log \sigma(\vec{-f} \cdot \vec{w}_N)]\]

&lt;p&gt;Optimizing this objective groups flows that have similar embeddings, while scattering unobserved pairs.&lt;/p&gt;

&lt;h5 id=&quot;todo---further-exploration-&quot;&gt;TODO - further exploration :&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Running true tuples of SRCIP, DSTIP, DSTPORT, and PROTO&lt;/li&gt;
  &lt;li&gt;Label included for now, need to figure out how to persist through pipeline without skewing results - need to figure out how to match up labeling to flow after word2vec has been run&lt;/li&gt;
  &lt;li&gt;Implement timestamp window oriented ‘sentence’ creation, current implementation created same length flow ‘sentences’ for every \(f\) flow&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Method to slide window over dataframe of 
# flowdata and create &quot;sentences&quot;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataframe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corpus_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;corpora&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataframe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;corpora&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subsample_cats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;153333&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subsample_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;153333&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;corpora_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subsample_cats_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;153333&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Convert all tuples created by previous create_corpora function
# to strings for use with tokenization which is then used in the
# word2vec algorithm below 
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str_corpora&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;str_corpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;str_corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;utf-8&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;str_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;[&apos;94.44.127.113&apos;, &apos;147.32.84.59&apos;, &apos;6881&apos;, &apos;tcp&apos;]&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Here we train a model without using the negative sampling 
# hyperparameter. We will be using this for testing of 
# accuracy of model vs. using the negative sampling function
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flow_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                    &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                    &lt;span class=&quot;n&quot;&gt;min_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Here we train a model using the negative sampling which 
# we will then compare to the model above for the impact 
# that the negative sampling has on the clustering of flows
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flow_model_sgns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                         &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                         &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;preliminary-results---very-rough-no-real-hyperparameter-tunings--exploration-etc&quot;&gt;Preliminary results - very rough, no real hyperparameter tunings / exploration, etc.&lt;/h2&gt;

&lt;p&gt;We can see below the results may prove to be useful with respect to certain labels present in the dataset, but not others. This may have to do with the raw occurence rates of certain flow and window #\((f,w)\) combinations vs. others. I use labels lightly as well as this will ultimately become an exercise of semi-supervised learning as it can sometimes be impossible for humans to interpret the results of an unsupervised learning task without any type of contextual insight, as labels can provide. In the case of written language, the “insight” that is provided is the fact that we know what the meanings of words are within the language and if they’re clustering correctly, re: synonyms and antonyms, etc.&lt;/p&gt;

&lt;p&gt;We can tune for this using subsampling above in the SGNS model. Which will we do next.&lt;/p&gt;

&lt;h4 id=&quot;todo&quot;&gt;TODO:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;GridSearch for hyperparameters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here we see that there is indeed a clustering that has happened with respect to the “From-Botnet-V42-UDP-DNS”&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Test for flow similarity, preferrably a flow that has the botnet label
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flow_model_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most_similar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[&apos;147.32.84.165&apos;, &apos;192.33.4.12&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(&quot;[&apos;147.32.84.165&apos;, &apos;192.5.5.241&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9761667847633362),
 (&quot;[&apos;147.32.84.165&apos;, &apos;202.12.27.33&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9741541743278503),
 (&quot;[&apos;147.32.84.165&apos;, &apos;128.8.10.90&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.973616898059845),
 (&quot;[&apos;147.32.84.165&apos;, &apos;78.47.76.4&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9714504480361938),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.0.14.129&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9692395925521851),
 (&quot;[&apos;147.32.84.165&apos;, &apos;199.7.83.42&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9687032699584961),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.228.79.201&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9674479961395264),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.58.128.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9664252400398254),
 (&quot;[&apos;147.32.84.165&apos;, &apos;92.53.98.100&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9656703472137451),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.112.36.4&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9654155969619751),
 (&quot;[&apos;147.32.84.165&apos;, &apos;198.41.0.4&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9644977450370789),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.203.230.10&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9633801579475403),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.36.148.17&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9618400931358337),
 (&quot;[&apos;147.32.84.165&apos;, &apos;128.63.2.53&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.958657443523407),
 (&quot;[&apos;147.32.84.165&apos;, &apos;89.108.64.2&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9581812024116516),
 (&quot;[&apos;147.32.84.165&apos;, &apos;82.103.128.82&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9558319449424744),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.42.93.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9557339549064636),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.26.92.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9556182026863098),
 (&quot;[&apos;147.32.84.165&apos;, &apos;194.226.96.8&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9543852210044861),
 (&quot;[&apos;147.32.84.165&apos;, &apos;194.85.61.20&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.953228771686554),
 (&quot;[&apos;147.32.84.165&apos;, &apos;88.212.196.130&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9526883959770203),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.128.49.14&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9500119090080261),
 (&quot;[&apos;147.32.84.165&apos;, &apos;217.16.20.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9483109712600708),
 (&quot;[&apos;147.32.84.165&apos;, &apos;85.10.210.157&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9481122493743896),
 (&quot;[&apos;147.32.84.165&apos;, &apos;92.53.116.200&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9478355050086975),
 (&quot;[&apos;147.32.84.165&apos;, &apos;88.212.221.11&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9470769166946411),
 (&quot;[&apos;147.32.84.165&apos;, &apos;82.146.55.155&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9461535811424255),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.41.162.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9459192156791687),
 (&quot;[&apos;147.32.84.165&apos;, &apos;77.222.40.2&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9456772804260254),
 (&quot;[&apos;147.32.84.165&apos;, &apos;199.19.57.1&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.945094645023346),
 (&quot;[&apos;147.32.84.165&apos;, &apos;89.253.192.21&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9428556561470032),
 (&quot;[&apos;147.32.84.165&apos;, &apos;199.249.120.1&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9426734447479248),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.54.112.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9423930048942566),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.2.83.38&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9414822459220886),
 (&quot;[&apos;147.32.84.165&apos;, &apos;89.108.104.3&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9414548873901367),
 (&quot;[&apos;147.32.84.165&apos;, &apos;78.108.89.252&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9414442181587219),
 (&quot;[&apos;147.32.84.165&apos;, &apos;80.93.50.53&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9408544898033142),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.31.80.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9401237368583679),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.161.112.91&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.939973771572113),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.169.178.59&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9395020008087158),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.48.79.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9393561482429504),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.33.14.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9386749267578125),
 (&quot;[&apos;147.32.84.165&apos;, &apos;85.10.210.144&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9382632970809937),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.12.94.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9372074007987976),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.35.51.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9371063113212585),
 (&quot;[&apos;147.32.84.165&apos;, &apos;213.177.97.1&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9366581439971924),
 (&quot;[&apos;147.32.84.165&apos;, &apos;95.163.69.51&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9363342523574829),
 (&quot;[&apos;147.32.84.165&apos;, &apos;79.174.72.215&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.936087965965271),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.248.235.219&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9358514547348022),
 (&quot;[&apos;147.32.84.165&apos;, &apos;217.16.16.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9352473020553589),
 (&quot;[&apos;147.32.84.165&apos;, &apos;78.108.81.247&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9348022937774658),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.5.6.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.934520423412323),
 (&quot;[&apos;147.32.84.165&apos;, &apos;199.19.56.1&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.934291422367096),
 (&quot;[&apos;147.32.84.165&apos;, &apos;217.16.22.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9341065883636475),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.36.144.107&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9333975315093994),
 (&quot;[&apos;147.32.84.165&apos;, &apos;81.177.24.54&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9332102537155151),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.52.178.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9328247308731079),
 (&quot;[&apos;147.32.84.165&apos;, &apos;83.222.0.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9324507117271423),
 (&quot;[&apos;147.32.84.165&apos;, &apos;95.168.160.245&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9320420026779175),
 (&quot;[&apos;147.32.84.165&apos;, &apos;95.168.174.25&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9319052696228027),
 (&quot;[&apos;147.32.84.165&apos;, &apos;80.93.56.2&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9313104748725891),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.227.240.37&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9309282302856445),
 (&quot;[&apos;147.32.84.165&apos;, &apos;208.100.5.254&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9303311705589294),
 (&quot;[&apos;147.32.84.165&apos;, &apos;77.221.130.250&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9299085140228271),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.55.83.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9297108054161072),
 (&quot;[&apos;147.32.84.165&apos;, &apos;84.252.138.21&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9296650886535645),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.43.172.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.928945779800415),
 (&quot;[&apos;147.32.84.165&apos;, &apos;89.111.177.253&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9288318753242493),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.2.64.38&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9286403059959412),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.128.50.221&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9278726577758789),
 (&quot;[&apos;147.32.84.165&apos;, &apos;178.218.208.130&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9271195530891418),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.36.125.2&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9268661141395569),
 (&quot;[&apos;147.32.84.165&apos;, &apos;199.19.54.1&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9267032146453857),
 (&quot;[&apos;147.32.84.165&apos;, &apos;79.137.226.102&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9260225296020508),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.232.130.14&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9259271621704102),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.232.142.17&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9246711730957031),
 (&quot;[&apos;147.32.84.165&apos;, &apos;78.47.139.101&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.924452006816864),
 (&quot;[&apos;147.32.84.165&apos;, &apos;217.174.106.66&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9236003756523132),
 (&quot;[&apos;147.32.84.165&apos;, &apos;77.222.41.3&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9235631823539734),
 (&quot;[&apos;147.32.84.165&apos;, &apos;83.222.1.30&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9203209280967712),
 (&quot;[&apos;147.32.84.165&apos;, &apos;91.217.21.170&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9194321632385254),
 (&quot;[&apos;147.32.84.165&apos;, &apos;89.108.122.149&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.919041633605957),
 (&quot;[&apos;147.32.84.165&apos;, &apos;91.217.20.170&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9166457056999207),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.227.240.38&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9165226221084595),
 (&quot;[&apos;147.32.84.165&apos;, &apos;78.108.80.90&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9164752960205078),
 (&quot;[&apos;147.32.84.165&apos;, &apos;78.110.50.60&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.915980875492096),
 (&quot;[&apos;147.32.84.165&apos;, &apos;178.162.177.145&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9158682227134705),
 (&quot;[&apos;147.32.84.165&apos;, &apos;194.85.252.62&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.915434718132019),
 (&quot;[&apos;147.32.84.165&apos;, &apos;77.221.159.237&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9152796864509583),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.232.146.170&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9140732884407043),
 (&quot;[&apos;147.32.84.165&apos;, &apos;199.249.112.1&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9137414693832397),
 (&quot;[&apos;147.32.84.165&apos;, &apos;87.224.128.4&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9121522307395935),
 (&quot;[&apos;147.32.84.165&apos;, &apos;93.170.25.253&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9113649725914001),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.209.63.181&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9110352993011475),
 (&quot;[&apos;147.32.84.165&apos;, &apos;195.243.137.26&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9104222059249878),
 (&quot;[&apos;147.32.84.165&apos;, &apos;194.0.0.53&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9094029068946838),
 (&quot;[&apos;147.32.84.165&apos;, &apos;91.218.228.18&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9092046022415161),
 (&quot;[&apos;147.32.84.165&apos;, &apos;194.85.105.17&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9091553092002869),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.232.156.17&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9083877801895142),
 (&quot;[&apos;147.32.84.165&apos;, &apos;212.176.27.2&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  0.9074791669845581)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;flow_model_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most_similar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[&apos;147.32.84.165&apos;, &apos;60.190.223.75&apos;, &apos;888&apos;, &apos;tcp&apos;, &apos;flow=From-Botnet-V42-TCP-CC6-Plain-HTTP-Encrypted-Data&apos;]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(&quot;[&apos;217.66.146.105&apos;, &apos;147.32.84.229&apos;, &apos;443&apos;, &apos;tcp&apos;, &apos;flow=Background-TCP-Established&apos;]&quot;,
  0.970333993434906),
 (&quot;[&apos;188.26.176.163&apos;, &apos;147.32.84.229&apos;, &apos;13363&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  0.963600218296051),
 (&quot;[&apos;114.75.11.242&apos;, &apos;147.32.84.229&apos;, &apos;80&apos;, &apos;tcp&apos;, &apos;flow=Background-TCP-Established&apos;]&quot;,
  0.9627201557159424),
 (&quot;[&apos;147.32.86.96&apos;, &apos;147.32.87.29&apos;, &apos;0xb612&apos;, &apos;icmp&apos;, &apos;flow=Background&apos;]&quot;,
  0.9622609615325928),
 (&quot;[&apos;195.234.241.9&apos;, &apos;147.32.84.229&apos;, &apos;13363&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  0.9621870517730713),
 (&quot;[&apos;41.130.66.62&apos;, &apos;147.32.84.229&apos;, &apos;13363&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  0.9606925249099731),
 (&quot;[&apos;131.104.149.212&apos;, &apos;147.32.84.229&apos;, &apos;13363&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  0.9604771733283997),
 (&quot;[&apos;147.32.84.59&apos;, &apos;90.146.27.130&apos;, &apos;46356&apos;, &apos;udp&apos;, &apos;flow=Background-Attempt-cmpgw-CVUT&apos;]&quot;,
  0.9597481489181519),
 (&quot;[&apos;147.32.84.229&apos;, &apos;78.141.179.11&apos;, &apos;34046&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  0.9597265720367432),
 (&quot;[&apos;147.32.84.59&apos;, &apos;114.40.199.143&apos;, &apos;21323&apos;, &apos;udp&apos;, &apos;flow=Background-Established-cmpgw-CVUT&apos;]&quot;,
  0.9592392444610596)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;without-label-contained-in-the-dataset&quot;&gt;Without label contained in the dataset&lt;/h3&gt;

&lt;p&gt;Here we run the same hyperparameters for the word2vec algorith, this time ignoring the label and not adding it to the “word” representations.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;flow_model_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_corpora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;flow_model_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most_similar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[&apos;147.32.84.165&apos;, &apos;192.33.4.12&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(&quot;[&apos;147.32.84.165&apos;, &apos;192.112.36.4&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9759483337402344),
 (&quot;[&apos;147.32.84.165&apos;, &apos;193.0.14.129&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9724588394165039),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.5.5.241&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9721120595932007),
 (&quot;[&apos;147.32.84.165&apos;, &apos;128.8.10.90&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9712154865264893),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.58.128.30&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9697802662849426),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.36.148.17&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9674890041351318),
 (&quot;[&apos;147.32.84.165&apos;, &apos;198.41.0.4&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9672064185142517),
 (&quot;[&apos;147.32.84.165&apos;, &apos;199.7.83.42&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9657577872276306),
 (&quot;[&apos;147.32.84.165&apos;, &apos;202.12.27.33&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9610617160797119),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.203.230.10&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;, 0.9608649015426636)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;DstAddr&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;192.112.36.4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;na&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;StartTime&lt;/th&gt;
      &lt;th&gt;Dur&lt;/th&gt;
      &lt;th&gt;Proto&lt;/th&gt;
      &lt;th&gt;SrcAddr&lt;/th&gt;
      &lt;th&gt;Sport&lt;/th&gt;
      &lt;th&gt;Dir&lt;/th&gt;
      &lt;th&gt;DstAddr&lt;/th&gt;
      &lt;th&gt;Dport&lt;/th&gt;
      &lt;th&gt;State&lt;/th&gt;
      &lt;th&gt;sTos&lt;/th&gt;
      &lt;th&gt;dTos&lt;/th&gt;
      &lt;th&gt;TotPkts&lt;/th&gt;
      &lt;th&gt;TotBytes&lt;/th&gt;
      &lt;th&gt;SrcBytes&lt;/th&gt;
      &lt;th&gt;Label&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1264477&lt;/th&gt;
      &lt;td&gt;2011/08/10 12:29:05.687373&lt;/td&gt;
      &lt;td&gt;0.258197&lt;/td&gt;
      &lt;td&gt;udp&lt;/td&gt;
      &lt;td&gt;147.32.84.165&lt;/td&gt;
      &lt;td&gt;2077&lt;/td&gt;
      &lt;td&gt;&amp;lt;-&amp;gt;&lt;/td&gt;
      &lt;td&gt;192.112.36.4&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;CON&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;528&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;flow=From-Botnet-V42-UDP-DNS&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1264673&lt;/th&gt;
      &lt;td&gt;2011/08/10 12:29:06.093217&lt;/td&gt;
      &lt;td&gt;0.258987&lt;/td&gt;
      &lt;td&gt;udp&lt;/td&gt;
      &lt;td&gt;147.32.84.165&lt;/td&gt;
      &lt;td&gt;2077&lt;/td&gt;
      &lt;td&gt;&amp;lt;-&amp;gt;&lt;/td&gt;
      &lt;td&gt;192.112.36.4&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;CON&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;611&lt;/td&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;flow=From-Botnet-V42-UDP-DNS&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vocab_flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow_model_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;192.112.36.4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vocab_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vocab_flow&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(&quot;[&apos;147.32.84.165&apos;, &apos;192.112.36.4&apos;, &apos;53&apos;, &apos;udp&apos;]&quot;,
  &amp;lt;gensim.models.word2vec.Vocab at 0x7f808752a350&amp;gt;)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flowdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;DstAddr&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;192.5.5.241&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;na&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;StartTime&lt;/th&gt;
      &lt;th&gt;Dur&lt;/th&gt;
      &lt;th&gt;Proto&lt;/th&gt;
      &lt;th&gt;SrcAddr&lt;/th&gt;
      &lt;th&gt;Sport&lt;/th&gt;
      &lt;th&gt;Dir&lt;/th&gt;
      &lt;th&gt;DstAddr&lt;/th&gt;
      &lt;th&gt;Dport&lt;/th&gt;
      &lt;th&gt;State&lt;/th&gt;
      &lt;th&gt;sTos&lt;/th&gt;
      &lt;th&gt;dTos&lt;/th&gt;
      &lt;th&gt;TotPkts&lt;/th&gt;
      &lt;th&gt;TotBytes&lt;/th&gt;
      &lt;th&gt;SrcBytes&lt;/th&gt;
      &lt;th&gt;Label&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;401163&lt;/th&gt;
      &lt;td&gt;2011/08/10 10:24:11.577652&lt;/td&gt;
      &lt;td&gt;0.004420&lt;/td&gt;
      &lt;td&gt;udp&lt;/td&gt;
      &lt;td&gt;147.32.87.49&lt;/td&gt;
      &lt;td&gt;65174&lt;/td&gt;
      &lt;td&gt;&amp;lt;-&amp;gt;&lt;/td&gt;
      &lt;td&gt;192.5.5.241&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;CON&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;636&lt;/td&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;flow=Background-UDP-Established&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1265468&lt;/th&gt;
      &lt;td&gt;2011/08/10 12:29:12.214663&lt;/td&gt;
      &lt;td&gt;0.002282&lt;/td&gt;
      &lt;td&gt;udp&lt;/td&gt;
      &lt;td&gt;147.32.84.165&lt;/td&gt;
      &lt;td&gt;2077&lt;/td&gt;
      &lt;td&gt;&amp;lt;-&amp;gt;&lt;/td&gt;
      &lt;td&gt;192.5.5.241&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;CON&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;417&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;flow=From-Botnet-V42-UDP-DNS&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;aggregated-flows-equivalent-to-phrases&quot;&gt;Aggregated flows, equivalent to “phrases”&lt;/h3&gt;

&lt;p&gt;The word2vec algorithm can also learn embeddings for phrases as well as single words for written language. The ideas I have surrounding “phrases” would be learning the embeddings for given windows of flows, if they were to present themselves in certain capacities within the captures flow data.&lt;/p&gt;

&lt;p&gt;The current flow data that this notebook is based around are aggregated flows for bi-directional communication between endpoints. Exploiting something like capturing the ‘phrase’ of a flow, or thought another way, the bi-directional communication patterns that are contained within flow data might prove useful for application profiling, etc. through the use of application meta-data tracked through some sort of semi-supervised learning pipeline.&lt;/p&gt;

&lt;h1 id=&quot;clustering&quot;&gt;Clustering&lt;/h1&gt;

&lt;p&gt;Now that we have some vector representations of occurences of flows within the captures that we have, we can run a clustering algorithm over them to see if we can humanly identify some of the groupings that have taken place. For this, we’ll use kmeans within the scikit-learn package.&lt;/p&gt;

&lt;p&gt;Kmeans has an objective function that intends to partition \(n\) objects into \(k\) clusters in which each object, \(n\), belongs to the cluster with the nearest mean. This can be seen as :&lt;/p&gt;

\[J = \sum_{j=1}^{k}\sum_{i=1}^{n} \| x_{i}^{(j)} - c_{j}\|^2\]

&lt;p&gt;Where \(\| x_{i}^{(j)} - c_{j}\|^2\) is a chosen distance measure between a datapoint \(x^{j}_{i}\) and the cluster center \(c{j}\), is an indicator of the distance of the \(n\) datapoints from their respective cluster \(k\) centers. In this case, \(k\) is a hyperparameter that can be used within the model to define how many cluster centroids should be trained over.&lt;/p&gt;

&lt;h4 id=&quot;todo-&quot;&gt;TODO :&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Limitation for arrays larger than 16GB due to an underlying dependency that numpy has, need to investigate - this is why I’m only running kmeans on a subset of the overall model learned above&lt;/li&gt;
  &lt;li&gt;Dimensionality reduction of some kind over the data - 300 dimensional data isn’t crazy high but might have some improved performance here as well.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Set k (number of clusters) to be 1/5 of the &quot;vocabulary&quot; size
# or an average of flows per cluster, this is a hyperparameter
# in kmeans that we can tweak later on
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flow_vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow_model_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;syn0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow_vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize k-means object and use it to extract centroids
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kmeans_clustering&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KMeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;k-means++&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmeans_clustering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create a flow / Index dictionary, mapping &quot;vocabulary words&quot; to
# a cluster number
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flow_centroid_map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_model_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index2word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#Find some botnet labels to use for exploration of data
&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;operator&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sorted_clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_centroid_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itemgetter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;botnets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sorted_clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Botnet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;botnets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;n&quot;&gt;botnets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(&quot;[&apos;147.32.84.165&apos;, &apos;209.86.93.226&apos;, &apos;25&apos;, &apos;tcp&apos;, &apos;flow=From-Botnet-V43-TCP-Attempt-SPAM&apos;]&quot;,
  3),
 (&quot;[&apos;147.32.84.165&apos;, &apos;192.33.4.12&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  14),
 (&quot;[&apos;147.32.84.165&apos;, &apos;85.214.220.206&apos;, &apos;25&apos;, &apos;tcp&apos;, &apos;flow=From-Botnet-V42-TCP-Attempt-SPAM&apos;]&quot;,
  40),
 (&quot;[&apos;147.32.84.165&apos;, &apos;77.88.210.88&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  48),
 (&quot;[&apos;147.32.84.165&apos;, &apos;75.180.132.243&apos;, &apos;25&apos;, &apos;tcp&apos;, &apos;flow=From-Botnet-V42-TCP-Attempt-SPAM&apos;]&quot;,
  49),
 (&quot;[&apos;147.32.84.165&apos;, &apos;67.23.231.68&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-Attempt-DNS&apos;]&quot;,
  73),
 (&quot;[&apos;147.32.84.165&apos;, &apos;60.190.223.75&apos;, &apos;888&apos;, &apos;tcp&apos;, &apos;flow=From-Botnet-V42-TCP-CC6-Plain-HTTP-Encrypted-Data&apos;]&quot;,
  74),
 (&quot;[&apos;147.32.84.165&apos;, &apos;80.93.50.53&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-DNS&apos;]&quot;,
  89),
 (&quot;[&apos;147.32.84.165&apos;, &apos;94.100.176.20&apos;, &apos;25&apos;, &apos;tcp&apos;, &apos;flow=From-Botnet-V43-TCP-Attempt-SPAM&apos;]&quot;,
  91),
 (&quot;[&apos;147.32.84.165&apos;, &apos;74.125.159.27&apos;, &apos;25&apos;, &apos;tcp&apos;, &apos;flow=From-Botnet-V42-TCP-Attempt-SPAM&apos;]&quot;,
  99)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Look at members of clusters according to botnet memberships discovered above
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cluster_members&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sorted_clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;73&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cluster_members&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;n&quot;&gt;cluster_members&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(&quot;[&apos;147.32.84.59&apos;, &apos;72.21.210.129&apos;, &apos;80&apos;, &apos;tcp&apos;, &apos;flow=Background-Established-cmpgw-CVUT&apos;]&quot;,
  73),
 (&quot;[&apos;62.162.92.225&apos;, &apos;147.32.84.229&apos;, &apos;13363&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  73),
 (&quot;[&apos;147.32.84.59&apos;, &apos;208.88.186.10&apos;, &apos;34021&apos;, &apos;udp&apos;, &apos;flow=Background-Established-cmpgw-CVUT&apos;]&quot;,
  73),
 (&quot;[&apos;147.32.84.165&apos;, &apos;67.23.231.68&apos;, &apos;53&apos;, &apos;udp&apos;, &apos;flow=From-Botnet-V42-UDP-Attempt-DNS&apos;]&quot;,
  73),
 (&quot;[&apos;200.148.213.27&apos;, &apos;147.32.84.229&apos;, &apos;13363&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  73),
 (&quot;[&apos;187.75.138.219&apos;, &apos;147.32.84.229&apos;, &apos;13363&apos;, &apos;udp&apos;, &apos;flow=Background-UDP-Established&apos;]&quot;,
  73)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;cluster-visualization&quot;&gt;Cluster visualization&lt;/h2&gt;

&lt;p&gt;Raw flow vectors \(V_{f}\), created by word2vec, are embedded in dimensionality equivalent to the input layer of the shallow neural network that is used within the model. In our example we’re using&lt;/p&gt;

&lt;h3 id=&quot;t-sne-visualization&quot;&gt;t-SNE Visualization&lt;/h3&gt;

&lt;p&gt;Use t-SNE and matplotlib to visualize the clusters created using Word2Vec.&lt;/p&gt;

&lt;h4 id=&quot;todo--1&quot;&gt;TODO :&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Brief explanation of the tSNE algorithm and how it handles compressing higher dimensional data into 2 or 3 dimension for visualization&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;perform_tsne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#flow_model_reduced = TruncatedSVD(n_components=100, random_state=42).fit_transform(flow_model_1.syn0)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_tsne&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_model_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;syn0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot_kw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axisbg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;#EEEEEE&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_tsne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_tsne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mpld3_scatter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Blues&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;white&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;solid&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_model_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpld3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PointLabelTooltip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpld3_scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mpld3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot_kw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axisbg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;#EEEEEE&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;mpld3_scatter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsne_objs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tsne_objs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;white&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;solid&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#ax.set_title(&quot;Scatter Plot (with tooltips!)&quot;, size=20)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#labels = [v[0][0] for k,v in enumerate(sample)]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpld3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PointLabelTooltip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpld3_scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mpld3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frameon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yticks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots_adjust&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bottom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;wspace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hspace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_model_embedded_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow_model_embedded_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#for k,v in enumerate(flow_model.vocab.items()):
#    plt.annotate(v[0], flow_model_embedded_1[k])
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;test2.eps&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;eps&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dpi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;things-left-to-research--validate--test&quot;&gt;Things left to research / validate / test&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Tune hyperparameters of models for all algorithms – word2vec, kmeans, tSNE&lt;/li&gt;
  &lt;li&gt;Find fixes for limitations of larger datasets for tooling that has dependencies on numpy – kmeans, tSNE&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ed Henry</name></author><category term="Python" /><category term="Machine Learning" /><category term="word2vec" /><category term="netflow" /><summary type="html">```python import pandas as pd import numpy as np #import pyhash import gensim import multiprocessing as mp from joblib import Parallel, delayed import concurrent.futures from pprint import pprint import random import mpld3 import re import matplotlib.pyplot as plt from sklearn import cluster from sklearn import manifold from sklearn.decomposition import PCA, TruncatedSVD</summary></entry></feed>